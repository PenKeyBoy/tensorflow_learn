2018-09-15 23:32:58,227 - root - INFO - lr             :	0.02
2018-09-15 23:32:58,232 - root - INFO - dr             :	0.96
2018-09-15 23:32:58,232 - root - INFO - ds             :	100
2018-09-15 23:32:58,232 - root - INFO - edr            :	0.99
2018-09-15 23:32:58,232 - root - INFO - lp             :	0.3
2018-09-15 23:32:58,232 - root - INFO - bs             :	100
2018-09-15 23:32:58,232 - root - INFO - clip           :	5
2018-09-15 23:32:58,232 - root - INFO - epoch          :	20
2018-09-15 23:32:58,232 - root - INFO - layer1_units   :	50
2018-09-15 23:32:58,232 - root - INFO - layer2_units   :	100
2018-09-15 23:32:58,233 - root - INFO - input_dimension:	784
2018-09-15 23:32:58,233 - root - INFO - num_tags       :	10
2018-09-15 23:32:58,233 - root - INFO - opt            :	Adam
2018-09-15 23:32:58,877 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-15 23:32:59,036 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-15 23:32:59,036 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-15 23:33:00,309 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-15 23:33:00,314 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-15 23:33:00,590 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-15 23:33:05,051 - root - INFO - iteration 0: global_step=1; loss_value=28.789953
2018-09-15 23:33:05,069 - root - INFO - iteration 0: global_step=2; loss_value=18.158077
2018-09-15 23:33:05,075 - root - INFO - iteration 0: global_step=3; loss_value=11.501110
2018-09-15 23:33:05,081 - root - INFO - iteration 0: global_step=4; loss_value=7.879616
2018-09-15 23:33:05,086 - root - INFO - iteration 0: global_step=5; loss_value=7.007528
2018-09-15 23:33:05,091 - root - INFO - iteration 0: global_step=6; loss_value=6.394481
2018-09-15 23:33:05,096 - root - INFO - iteration 0: global_step=7; loss_value=6.589803
2018-09-15 23:33:05,104 - root - INFO - iteration 0: global_step=8; loss_value=6.439379
2018-09-15 23:33:05,109 - root - INFO - iteration 0: global_step=9; loss_value=6.125164
2018-09-15 23:33:05,114 - root - INFO - iteration 0: global_step=10; loss_value=5.722457
2018-09-15 23:33:05,122 - root - INFO - iteration 0: global_step=11; loss_value=5.345161
2018-09-15 23:33:05,126 - root - INFO - iteration 0: global_step=12; loss_value=5.004916
2018-09-15 23:33:05,133 - root - INFO - iteration 0: global_step=13; loss_value=4.697122
2018-09-15 23:33:05,142 - root - INFO - iteration 0: global_step=14; loss_value=4.377863
2018-09-15 23:33:05,151 - root - INFO - iteration 0: global_step=15; loss_value=4.295779
2018-09-15 23:33:05,156 - root - INFO - iteration 0: global_step=16; loss_value=4.328004
2018-09-15 23:33:05,162 - root - INFO - iteration 0: global_step=17; loss_value=4.240897
2018-09-15 23:33:05,173 - root - INFO - iteration 0: global_step=18; loss_value=4.256590
2018-09-15 23:33:05,176 - root - INFO - iteration 0: global_step=19; loss_value=4.238260
2018-09-15 23:33:05,181 - root - INFO - iteration 0: global_step=20; loss_value=4.158128
2018-09-15 23:33:05,186 - root - INFO - iteration 0: global_step=21; loss_value=3.982294
2018-09-15 23:33:05,189 - root - INFO - iteration 0: global_step=22; loss_value=3.773046
2018-09-15 23:33:05,195 - root - INFO - iteration 0: global_step=23; loss_value=3.690282
2018-09-15 23:33:05,200 - root - INFO - iteration 0: global_step=24; loss_value=3.444914
2018-09-15 23:33:05,206 - root - INFO - iteration 0: global_step=25; loss_value=3.406250
2018-09-15 23:33:05,224 - root - INFO - iteration 0: global_step=26; loss_value=3.182512
2018-09-15 23:33:05,228 - root - INFO - iteration 0: global_step=27; loss_value=3.225696
2018-09-15 23:33:05,233 - root - INFO - iteration 0: global_step=28; loss_value=3.141833
2018-09-15 23:33:05,240 - root - INFO - iteration 0: global_step=29; loss_value=3.133758
2018-09-15 23:33:05,245 - root - INFO - iteration 0: global_step=30; loss_value=3.107467
2018-09-15 23:33:05,250 - root - INFO - iteration 0: global_step=31; loss_value=3.098620
2018-09-15 23:33:05,257 - root - INFO - iteration 0: global_step=32; loss_value=3.154121
2018-09-15 23:33:05,264 - root - INFO - iteration 0: global_step=33; loss_value=2.927232
2018-09-15 23:33:05,271 - root - INFO - iteration 0: global_step=34; loss_value=3.067538
2018-09-15 23:33:05,274 - root - INFO - iteration 0: global_step=35; loss_value=2.956193
2018-09-15 23:33:05,282 - root - INFO - iteration 0: global_step=36; loss_value=2.924764
2018-09-15 23:33:05,288 - root - INFO - iteration 0: global_step=37; loss_value=2.858380
2018-09-15 23:33:05,293 - root - INFO - iteration 0: global_step=38; loss_value=2.965894
2018-09-15 23:33:05,300 - root - INFO - iteration 0: global_step=39; loss_value=2.855138
2018-09-15 23:33:05,308 - root - INFO - iteration 0: global_step=40; loss_value=2.795915
2018-09-15 23:33:05,311 - root - INFO - iteration 0: global_step=41; loss_value=2.819175
2018-09-15 23:33:05,319 - root - INFO - iteration 0: global_step=42; loss_value=2.831936
2018-09-15 23:33:05,323 - root - INFO - iteration 0: global_step=43; loss_value=2.847074
2018-09-15 23:33:05,331 - root - INFO - iteration 0: global_step=44; loss_value=2.756790
2018-09-15 23:33:05,340 - root - INFO - iteration 0: global_step=45; loss_value=2.782732
2018-09-15 23:33:05,344 - root - INFO - iteration 0: global_step=46; loss_value=2.800179
2018-09-15 23:33:05,350 - root - INFO - iteration 0: global_step=47; loss_value=2.742896
2018-09-15 23:33:05,360 - root - INFO - iteration 0: global_step=48; loss_value=2.731280
2018-09-15 23:33:05,366 - root - INFO - iteration 0: global_step=49; loss_value=2.678575
2018-09-15 23:33:05,373 - root - INFO - iteration 0: global_step=50; loss_value=2.584991
2018-09-15 23:33:05,378 - root - INFO - iteration 0: global_step=51; loss_value=2.678868
2018-09-15 23:33:05,384 - root - INFO - iteration 0: global_step=52; loss_value=2.638376
2018-09-15 23:33:05,387 - root - INFO - iteration 0: global_step=53; loss_value=2.791338
2018-09-15 23:33:05,393 - root - INFO - iteration 0: global_step=54; loss_value=2.645811
2018-09-15 23:33:05,398 - root - INFO - iteration 0: global_step=55; loss_value=2.599834
2018-09-15 23:33:05,407 - root - INFO - iteration 0: global_step=56; loss_value=2.760871
2018-09-15 23:33:05,410 - root - INFO - iteration 0: global_step=57; loss_value=2.621716
2018-09-15 23:33:05,417 - root - INFO - iteration 0: global_step=58; loss_value=2.674641
2018-09-15 23:33:05,423 - root - INFO - iteration 0: global_step=59; loss_value=2.565327
2018-09-15 23:33:05,427 - root - INFO - iteration 0: global_step=60; loss_value=2.616869
2018-09-15 23:33:05,433 - root - INFO - iteration 0: global_step=61; loss_value=2.616432
2018-09-15 23:33:05,440 - root - INFO - iteration 0: global_step=62; loss_value=2.570562
2018-09-15 23:33:05,444 - root - INFO - iteration 0: global_step=63; loss_value=2.582220
2018-09-15 23:33:05,451 - root - INFO - iteration 0: global_step=64; loss_value=2.582931
2018-09-15 23:33:05,457 - root - INFO - iteration 0: global_step=65; loss_value=2.632498
2018-09-15 23:33:05,466 - root - INFO - iteration 0: global_step=66; loss_value=2.628556
2018-09-15 23:33:05,473 - root - INFO - iteration 0: global_step=67; loss_value=2.683933
2018-09-15 23:33:05,479 - root - INFO - iteration 0: global_step=68; loss_value=2.626716
2018-09-15 23:33:05,489 - root - INFO - iteration 0: global_step=69; loss_value=2.563409
2018-09-15 23:33:05,496 - root - INFO - iteration 0: global_step=70; loss_value=2.451566
2018-09-15 23:33:05,499 - root - INFO - iteration 0: global_step=71; loss_value=2.627313
2018-09-15 23:33:05,508 - root - INFO - iteration 0: global_step=72; loss_value=2.588486
2018-09-15 23:33:05,515 - root - INFO - iteration 0: global_step=73; loss_value=2.465038
2018-09-15 23:33:05,524 - root - INFO - iteration 0: global_step=74; loss_value=2.675528
2018-09-15 23:33:05,526 - root - INFO - iteration 0: global_step=75; loss_value=2.572663
2018-09-15 23:33:05,536 - root - INFO - iteration 0: global_step=76; loss_value=2.485333
2018-09-15 23:33:05,540 - root - INFO - iteration 0: global_step=77; loss_value=2.521373
2018-09-15 23:33:05,548 - root - INFO - iteration 0: global_step=78; loss_value=2.683977
2018-09-15 23:33:05,551 - root - INFO - iteration 0: global_step=79; loss_value=2.625952
2018-09-15 23:33:05,555 - root - INFO - iteration 0: global_step=80; loss_value=2.583713
2018-09-15 23:33:05,561 - root - INFO - iteration 0: global_step=81; loss_value=2.515654
2018-09-15 23:33:05,567 - root - INFO - iteration 0: global_step=82; loss_value=2.520272
2018-09-15 23:33:05,573 - root - INFO - iteration 0: global_step=83; loss_value=2.602570
2018-09-15 23:33:05,578 - root - INFO - iteration 0: global_step=84; loss_value=2.579925
2018-09-15 23:33:05,584 - root - INFO - iteration 0: global_step=85; loss_value=2.503829
2018-09-15 23:33:05,590 - root - INFO - iteration 0: global_step=86; loss_value=2.533685
2018-09-15 23:33:05,600 - root - INFO - iteration 0: global_step=87; loss_value=2.525757
2018-09-15 23:33:05,603 - root - INFO - iteration 0: global_step=88; loss_value=2.553442
2018-09-15 23:33:05,610 - root - INFO - iteration 0: global_step=89; loss_value=2.546762
2018-09-15 23:33:05,612 - root - INFO - iteration 0: global_step=90; loss_value=2.530403
2018-09-15 23:33:05,619 - root - INFO - iteration 0: global_step=91; loss_value=2.445292
2018-09-15 23:33:05,626 - root - INFO - iteration 0: global_step=92; loss_value=2.509363
2018-09-15 23:33:05,633 - root - INFO - iteration 0: global_step=93; loss_value=2.580818
2018-09-15 23:33:05,639 - root - INFO - iteration 0: global_step=94; loss_value=2.522572
2018-09-15 23:33:05,645 - root - INFO - iteration 0: global_step=95; loss_value=2.482366
2018-09-15 23:33:05,647 - root - INFO - iteration 0: global_step=96; loss_value=2.642024
2018-09-15 23:33:05,659 - root - INFO - iteration 0: global_step=97; loss_value=2.573924
2018-09-15 23:33:05,662 - root - INFO - iteration 0: global_step=98; loss_value=2.551824
2018-09-15 23:33:05,672 - root - INFO - iteration 0: global_step=99; loss_value=2.664638
2018-09-15 23:33:05,674 - root - INFO - iteration 0: global_step=100; loss_value=2.543027
2018-09-15 23:45:16,223 - root - INFO - lr             :	0.02
2018-09-15 23:45:16,229 - root - INFO - dr             :	0.96
2018-09-15 23:45:16,229 - root - INFO - ds             :	100
2018-09-15 23:45:16,229 - root - INFO - edr            :	0.99
2018-09-15 23:45:16,229 - root - INFO - lp             :	0.3
2018-09-15 23:45:16,229 - root - INFO - bs             :	100
2018-09-15 23:45:16,229 - root - INFO - clip           :	5
2018-09-15 23:45:16,229 - root - INFO - epoch          :	20
2018-09-15 23:45:16,229 - root - INFO - layer1_units   :	50
2018-09-15 23:45:16,230 - root - INFO - layer2_units   :	100
2018-09-15 23:45:16,230 - root - INFO - input_dimension:	784
2018-09-15 23:45:16,230 - root - INFO - num_tags       :	10
2018-09-15 23:45:16,230 - root - INFO - opt            :	Adam
2018-09-15 23:45:16,721 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-15 23:45:16,874 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-15 23:45:16,881 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-15 23:45:17,291 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-15 23:45:17,299 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-15 23:45:17,435 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-15 23:45:19,154 - root - INFO - iteration 0: global_step=1; loss_value=28.704704
2018-09-15 23:45:19,164 - root - INFO - iteration 0: global_step=2; loss_value=18.323475
2018-09-15 23:45:19,170 - root - INFO - iteration 0: global_step=3; loss_value=11.650640
2018-09-15 23:45:19,175 - root - INFO - iteration 0: global_step=4; loss_value=8.110478
2018-09-15 23:45:19,184 - root - INFO - iteration 0: global_step=5; loss_value=6.788158
2018-09-15 23:45:19,187 - root - INFO - iteration 0: global_step=6; loss_value=6.615575
2018-09-15 23:45:19,193 - root - INFO - iteration 0: global_step=7; loss_value=6.567139
2018-09-15 23:45:19,198 - root - INFO - iteration 0: global_step=8; loss_value=6.322555
2018-09-15 23:45:19,208 - root - INFO - iteration 0: global_step=9; loss_value=6.265980
2018-09-15 23:45:19,216 - root - INFO - iteration 0: global_step=10; loss_value=5.871988
2018-09-15 23:45:19,223 - root - INFO - iteration 0: global_step=11; loss_value=5.325736
2018-09-15 23:45:19,232 - root - INFO - iteration 0: global_step=12; loss_value=4.989367
2018-09-15 23:45:19,240 - root - INFO - iteration 0: global_step=13; loss_value=4.650981
2018-09-15 23:45:19,250 - root - INFO - iteration 0: global_step=14; loss_value=4.371791
2018-09-15 23:45:19,256 - root - INFO - iteration 0: global_step=15; loss_value=4.276852
2018-09-15 23:45:19,263 - root - INFO - iteration 0: global_step=16; loss_value=4.333947
2018-09-15 23:45:19,272 - root - INFO - iteration 0: global_step=17; loss_value=4.290293
2018-09-15 23:45:19,280 - root - INFO - iteration 0: global_step=18; loss_value=4.276193
2018-09-15 23:45:19,288 - root - INFO - iteration 0: global_step=19; loss_value=4.333150
2018-09-15 23:45:19,292 - root - INFO - iteration 0: global_step=20; loss_value=4.132439
2018-09-15 23:45:19,297 - root - INFO - iteration 0: global_step=21; loss_value=3.996980
2018-09-15 23:45:19,305 - root - INFO - iteration 0: global_step=22; loss_value=3.859807
2018-09-15 23:45:19,311 - root - INFO - iteration 0: global_step=23; loss_value=3.639291
2018-09-15 23:45:19,316 - root - INFO - iteration 0: global_step=24; loss_value=3.528306
2018-09-15 23:45:19,321 - root - INFO - iteration 0: global_step=25; loss_value=3.397460
2018-09-15 23:45:19,331 - root - INFO - iteration 0: global_step=26; loss_value=3.168000
2018-09-15 23:45:19,339 - root - INFO - iteration 0: global_step=27; loss_value=3.288727
2018-09-15 23:45:19,350 - root - INFO - iteration 0: global_step=28; loss_value=3.056070
2018-09-15 23:45:19,355 - root - INFO - iteration 0: global_step=29; loss_value=3.198662
2018-09-15 23:45:19,360 - root - INFO - iteration 0: global_step=30; loss_value=3.131960
2018-09-15 23:45:19,366 - root - INFO - iteration 0: global_step=31; loss_value=3.099368
2018-09-15 23:45:19,373 - root - INFO - iteration 0: global_step=32; loss_value=3.196588
2018-09-15 23:45:19,375 - root - INFO - iteration 0: global_step=33; loss_value=3.132928
2018-09-15 23:45:19,382 - root - INFO - iteration 0: global_step=34; loss_value=3.045711
2018-09-15 23:45:19,388 - root - INFO - iteration 0: global_step=35; loss_value=3.134969
2018-09-15 23:45:19,390 - root - INFO - iteration 0: global_step=36; loss_value=3.039693
2018-09-15 23:45:19,398 - root - INFO - iteration 0: global_step=37; loss_value=3.022792
2018-09-15 23:45:19,404 - root - INFO - iteration 0: global_step=38; loss_value=2.941130
2018-09-15 23:45:19,411 - root - INFO - iteration 0: global_step=39; loss_value=2.846928
2018-09-15 23:45:19,419 - root - INFO - iteration 0: global_step=40; loss_value=2.947760
2018-09-15 23:45:19,427 - root - INFO - iteration 0: global_step=41; loss_value=2.894553
2018-09-15 23:45:19,432 - root - INFO - iteration 0: global_step=42; loss_value=2.813242
2018-09-15 23:45:19,442 - root - INFO - iteration 0: global_step=43; loss_value=2.831843
2018-09-15 23:45:19,448 - root - INFO - iteration 0: global_step=44; loss_value=2.850794
2018-09-15 23:45:19,457 - root - INFO - iteration 0: global_step=45; loss_value=2.856524
2018-09-15 23:45:19,464 - root - INFO - iteration 0: global_step=46; loss_value=2.705387
2018-09-15 23:45:19,466 - root - INFO - iteration 0: global_step=47; loss_value=2.747528
2018-09-15 23:45:19,477 - root - INFO - iteration 0: global_step=48; loss_value=2.732254
2018-09-15 23:45:19,485 - root - INFO - iteration 0: global_step=49; loss_value=2.724638
2018-09-15 23:45:19,487 - root - INFO - iteration 0: global_step=50; loss_value=2.685385
2018-09-15 23:45:19,493 - root - INFO - iteration 0: global_step=51; loss_value=2.667907
2018-09-15 23:45:19,498 - root - INFO - iteration 0: global_step=52; loss_value=2.561639
2018-09-15 23:45:19,504 - root - INFO - iteration 0: global_step=53; loss_value=2.582041
2018-09-15 23:45:19,510 - root - INFO - iteration 0: global_step=54; loss_value=2.715800
2018-09-15 23:45:19,515 - root - INFO - iteration 0: global_step=55; loss_value=2.757687
2018-09-15 23:45:19,522 - root - INFO - iteration 0: global_step=56; loss_value=2.690637
2018-09-15 23:45:19,526 - root - INFO - iteration 0: global_step=57; loss_value=2.634874
2018-09-15 23:45:19,532 - root - INFO - iteration 0: global_step=58; loss_value=2.683858
2018-09-15 23:45:19,540 - root - INFO - iteration 0: global_step=59; loss_value=2.673005
2018-09-15 23:45:19,549 - root - INFO - iteration 0: global_step=60; loss_value=2.590904
2018-09-15 23:45:19,556 - root - INFO - iteration 0: global_step=61; loss_value=2.555037
2018-09-15 23:45:19,564 - root - INFO - iteration 0: global_step=62; loss_value=2.670538
2018-09-15 23:45:19,567 - root - INFO - iteration 0: global_step=63; loss_value=2.707350
2018-09-15 23:45:19,569 - root - INFO - iteration 0: global_step=64; loss_value=2.665818
2018-09-15 23:45:19,575 - root - INFO - iteration 0: global_step=65; loss_value=2.623965
2018-09-15 23:45:19,584 - root - INFO - iteration 0: global_step=66; loss_value=2.637709
2018-09-15 23:45:19,592 - root - INFO - iteration 0: global_step=67; loss_value=2.599071
2018-09-15 23:45:19,596 - root - INFO - iteration 0: global_step=68; loss_value=2.590181
2018-09-15 23:45:19,602 - root - INFO - iteration 0: global_step=69; loss_value=2.658926
2018-09-15 23:45:19,610 - root - INFO - iteration 0: global_step=70; loss_value=2.550582
2018-09-15 23:45:19,615 - root - INFO - iteration 0: global_step=71; loss_value=2.642707
2018-09-15 23:45:19,623 - root - INFO - iteration 0: global_step=72; loss_value=2.596519
2018-09-15 23:45:19,630 - root - INFO - iteration 0: global_step=73; loss_value=2.626551
2018-09-15 23:45:19,634 - root - INFO - iteration 0: global_step=74; loss_value=2.517035
2018-09-15 23:45:19,642 - root - INFO - iteration 0: global_step=75; loss_value=2.625465
2018-09-15 23:45:19,648 - root - INFO - iteration 0: global_step=76; loss_value=2.560240
2018-09-15 23:45:19,652 - root - INFO - iteration 0: global_step=77; loss_value=2.533689
2018-09-15 23:45:19,661 - root - INFO - iteration 0: global_step=78; loss_value=2.627717
2018-09-15 23:45:19,671 - root - INFO - iteration 0: global_step=79; loss_value=2.534860
2018-09-15 23:45:19,677 - root - INFO - iteration 0: global_step=80; loss_value=2.648996
2018-09-15 23:45:19,688 - root - INFO - iteration 0: global_step=81; loss_value=2.522567
2018-09-15 23:45:19,692 - root - INFO - iteration 0: global_step=82; loss_value=2.581672
2018-09-15 23:45:19,698 - root - INFO - iteration 0: global_step=83; loss_value=2.600404
2018-09-15 23:45:19,704 - root - INFO - iteration 0: global_step=84; loss_value=2.581278
2018-09-15 23:45:19,707 - root - INFO - iteration 0: global_step=85; loss_value=2.408824
2018-09-15 23:45:19,713 - root - INFO - iteration 0: global_step=86; loss_value=2.574420
2018-09-15 23:45:19,715 - root - INFO - iteration 0: global_step=87; loss_value=2.517718
2018-09-15 23:45:19,724 - root - INFO - iteration 0: global_step=88; loss_value=2.498563
2018-09-15 23:45:19,732 - root - INFO - iteration 0: global_step=89; loss_value=2.468990
2018-09-15 23:45:19,734 - root - INFO - iteration 0: global_step=90; loss_value=2.518993
2018-09-15 23:45:19,740 - root - INFO - iteration 0: global_step=91; loss_value=2.552476
2018-09-15 23:45:19,748 - root - INFO - iteration 0: global_step=92; loss_value=2.423313
2018-09-15 23:45:19,754 - root - INFO - iteration 0: global_step=93; loss_value=2.437892
2018-09-15 23:45:19,763 - root - INFO - iteration 0: global_step=94; loss_value=2.533376
2018-09-15 23:45:19,772 - root - INFO - iteration 0: global_step=95; loss_value=2.524328
2018-09-15 23:45:19,782 - root - INFO - iteration 0: global_step=96; loss_value=2.577570
2018-09-15 23:45:19,787 - root - INFO - iteration 0: global_step=97; loss_value=2.487089
2018-09-15 23:45:19,793 - root - INFO - iteration 0: global_step=98; loss_value=2.527361
2018-09-15 23:45:19,799 - root - INFO - iteration 0: global_step=99; loss_value=2.522136
2018-09-15 23:45:19,804 - root - INFO - iteration 0: global_step=100; loss_value=2.465489
2018-09-15 23:45:23,052 - root - INFO - iteration 10: global_step=1001; loss_value=2.242987
2018-09-15 23:45:23,063 - root - INFO - iteration 10: global_step=1002; loss_value=2.237110
2018-09-15 23:45:23,068 - root - INFO - iteration 10: global_step=1003; loss_value=2.257974
2018-09-15 23:45:23,076 - root - INFO - iteration 10: global_step=1004; loss_value=2.233924
2018-09-15 23:45:23,080 - root - INFO - iteration 10: global_step=1005; loss_value=2.212268
2018-09-15 23:45:23,086 - root - INFO - iteration 10: global_step=1006; loss_value=2.266523
2018-09-15 23:45:23,092 - root - INFO - iteration 10: global_step=1007; loss_value=2.218953
2018-09-15 23:45:23,098 - root - INFO - iteration 10: global_step=1008; loss_value=2.239101
2018-09-15 23:45:23,104 - root - INFO - iteration 10: global_step=1009; loss_value=2.233440
2018-09-15 23:45:23,115 - root - INFO - iteration 10: global_step=1010; loss_value=2.230506
2018-09-15 23:45:23,119 - root - INFO - iteration 10: global_step=1011; loss_value=2.251508
2018-09-15 23:45:23,129 - root - INFO - iteration 10: global_step=1012; loss_value=2.271410
2018-09-15 23:45:23,137 - root - INFO - iteration 10: global_step=1013; loss_value=2.295331
2018-09-15 23:45:23,148 - root - INFO - iteration 10: global_step=1014; loss_value=2.251235
2018-09-15 23:45:23,154 - root - INFO - iteration 10: global_step=1015; loss_value=2.188692
2018-09-15 23:45:23,159 - root - INFO - iteration 10: global_step=1016; loss_value=2.281402
2018-09-15 23:45:23,164 - root - INFO - iteration 10: global_step=1017; loss_value=2.208406
2018-09-15 23:45:23,168 - root - INFO - iteration 10: global_step=1018; loss_value=2.216412
2018-09-15 23:45:23,172 - root - INFO - iteration 10: global_step=1019; loss_value=2.211270
2018-09-15 23:45:23,178 - root - INFO - iteration 10: global_step=1020; loss_value=2.287617
2018-09-15 23:45:23,180 - root - INFO - iteration 10: global_step=1021; loss_value=2.213045
2018-09-15 23:45:23,187 - root - INFO - iteration 10: global_step=1022; loss_value=2.187248
2018-09-15 23:45:23,193 - root - INFO - iteration 10: global_step=1023; loss_value=2.271627
2018-09-15 23:45:23,195 - root - INFO - iteration 10: global_step=1024; loss_value=2.183368
2018-09-15 23:45:23,201 - root - INFO - iteration 10: global_step=1025; loss_value=2.231268
2018-09-15 23:45:23,211 - root - INFO - iteration 10: global_step=1026; loss_value=2.226017
2018-09-15 23:45:23,215 - root - INFO - iteration 10: global_step=1027; loss_value=2.158753
2018-09-15 23:45:23,222 - root - INFO - iteration 10: global_step=1028; loss_value=2.188974
2018-09-15 23:45:23,227 - root - INFO - iteration 10: global_step=1029; loss_value=2.260441
2018-09-15 23:45:23,235 - root - INFO - iteration 10: global_step=1030; loss_value=2.156030
2018-09-15 23:45:23,240 - root - INFO - iteration 10: global_step=1031; loss_value=2.200163
2018-09-15 23:45:23,252 - root - INFO - iteration 10: global_step=1032; loss_value=2.215931
2018-09-15 23:45:23,255 - root - INFO - iteration 10: global_step=1033; loss_value=2.196678
2018-09-15 23:45:23,260 - root - INFO - iteration 10: global_step=1034; loss_value=2.256116
2018-09-15 23:45:23,266 - root - INFO - iteration 10: global_step=1035; loss_value=2.217383
2018-09-15 23:45:23,273 - root - INFO - iteration 10: global_step=1036; loss_value=2.174744
2018-09-15 23:45:23,276 - root - INFO - iteration 10: global_step=1037; loss_value=2.280346
2018-09-15 23:45:23,283 - root - INFO - iteration 10: global_step=1038; loss_value=2.168674
2018-09-15 23:45:23,286 - root - INFO - iteration 10: global_step=1039; loss_value=2.157192
2018-09-15 23:45:23,295 - root - INFO - iteration 10: global_step=1040; loss_value=2.181311
2018-09-15 23:45:23,303 - root - INFO - iteration 10: global_step=1041; loss_value=2.282562
2018-09-15 23:45:23,309 - root - INFO - iteration 10: global_step=1042; loss_value=2.191285
2018-09-15 23:45:23,313 - root - INFO - iteration 10: global_step=1043; loss_value=2.221931
2018-09-15 23:45:23,322 - root - INFO - iteration 10: global_step=1044; loss_value=2.191456
2018-09-15 23:45:23,327 - root - INFO - iteration 10: global_step=1045; loss_value=2.215322
2018-09-15 23:45:23,335 - root - INFO - iteration 10: global_step=1046; loss_value=2.241663
2018-09-15 23:45:23,346 - root - INFO - iteration 10: global_step=1047; loss_value=2.205453
2018-09-15 23:45:23,351 - root - INFO - iteration 10: global_step=1048; loss_value=2.296081
2018-09-15 23:45:23,357 - root - INFO - iteration 10: global_step=1049; loss_value=2.162890
2018-09-15 23:45:23,362 - root - INFO - iteration 10: global_step=1050; loss_value=2.155301
2018-09-15 23:45:23,368 - root - INFO - iteration 10: global_step=1051; loss_value=2.224291
2018-09-15 23:45:23,371 - root - INFO - iteration 10: global_step=1052; loss_value=2.231450
2018-09-15 23:45:23,378 - root - INFO - iteration 10: global_step=1053; loss_value=2.279746
2018-09-15 23:45:23,381 - root - INFO - iteration 10: global_step=1054; loss_value=2.266438
2018-09-15 23:45:23,387 - root - INFO - iteration 10: global_step=1055; loss_value=2.229112
2018-09-15 23:45:23,393 - root - INFO - iteration 10: global_step=1056; loss_value=2.205494
2018-09-15 23:45:23,396 - root - INFO - iteration 10: global_step=1057; loss_value=2.182431
2018-09-15 23:45:23,402 - root - INFO - iteration 10: global_step=1058; loss_value=2.141057
2018-09-15 23:45:23,408 - root - INFO - iteration 10: global_step=1059; loss_value=2.279377
2018-09-15 23:45:23,415 - root - INFO - iteration 10: global_step=1060; loss_value=2.190616
2018-09-15 23:45:23,420 - root - INFO - iteration 10: global_step=1061; loss_value=2.168257
2018-09-15 23:45:23,428 - root - INFO - iteration 10: global_step=1062; loss_value=2.266611
2018-09-15 23:45:23,433 - root - INFO - iteration 10: global_step=1063; loss_value=2.213113
2018-09-15 23:45:23,446 - root - INFO - iteration 10: global_step=1064; loss_value=2.285620
2018-09-15 23:45:23,453 - root - INFO - iteration 10: global_step=1065; loss_value=2.209005
2018-09-15 23:45:23,455 - root - INFO - iteration 10: global_step=1066; loss_value=2.255168
2018-09-15 23:45:23,462 - root - INFO - iteration 10: global_step=1067; loss_value=2.280882
2018-09-15 23:45:23,469 - root - INFO - iteration 10: global_step=1068; loss_value=2.186972
2018-09-15 23:45:23,476 - root - INFO - iteration 10: global_step=1069; loss_value=2.191745
2018-09-15 23:45:23,479 - root - INFO - iteration 10: global_step=1070; loss_value=2.239299
2018-09-15 23:45:23,487 - root - INFO - iteration 10: global_step=1071; loss_value=2.163383
2018-09-15 23:45:23,490 - root - INFO - iteration 10: global_step=1072; loss_value=2.186392
2018-09-15 23:45:23,496 - root - INFO - iteration 10: global_step=1073; loss_value=2.229612
2018-09-15 23:45:23,501 - root - INFO - iteration 10: global_step=1074; loss_value=2.193499
2018-09-15 23:45:23,506 - root - INFO - iteration 10: global_step=1075; loss_value=2.192049
2018-09-15 23:45:23,514 - root - INFO - iteration 10: global_step=1076; loss_value=2.167295
2018-09-15 23:45:23,516 - root - INFO - iteration 10: global_step=1077; loss_value=2.176816
2018-09-15 23:45:23,523 - root - INFO - iteration 10: global_step=1078; loss_value=2.199865
2018-09-15 23:45:23,529 - root - INFO - iteration 10: global_step=1079; loss_value=2.200998
2018-09-15 23:45:23,536 - root - INFO - iteration 10: global_step=1080; loss_value=2.129073
2018-09-15 23:45:23,546 - root - INFO - iteration 10: global_step=1081; loss_value=2.225353
2018-09-15 23:45:23,555 - root - INFO - iteration 10: global_step=1082; loss_value=2.208322
2018-09-15 23:45:23,568 - root - INFO - iteration 10: global_step=1083; loss_value=2.350505
2018-09-15 23:45:23,572 - root - INFO - iteration 10: global_step=1084; loss_value=2.227474
2018-09-15 23:45:23,578 - root - INFO - iteration 10: global_step=1085; loss_value=2.251415
2018-09-15 23:45:23,584 - root - INFO - iteration 10: global_step=1086; loss_value=2.238904
2018-09-15 23:45:23,588 - root - INFO - iteration 10: global_step=1087; loss_value=2.279505
2018-09-15 23:45:23,598 - root - INFO - iteration 10: global_step=1088; loss_value=2.321118
2018-09-15 23:45:23,603 - root - INFO - iteration 10: global_step=1089; loss_value=2.205845
2018-09-15 23:45:23,610 - root - INFO - iteration 10: global_step=1090; loss_value=2.213002
2018-09-15 23:45:23,617 - root - INFO - iteration 10: global_step=1091; loss_value=2.213984
2018-09-15 23:45:23,619 - root - INFO - iteration 10: global_step=1092; loss_value=2.221513
2018-09-15 23:45:23,625 - root - INFO - iteration 10: global_step=1093; loss_value=2.174973
2018-09-15 23:45:23,631 - root - INFO - iteration 10: global_step=1094; loss_value=2.163918
2018-09-15 23:45:23,637 - root - INFO - iteration 10: global_step=1095; loss_value=2.208515
2018-09-15 23:45:23,640 - root - INFO - iteration 10: global_step=1096; loss_value=2.241363
2018-09-15 23:45:23,647 - root - INFO - iteration 10: global_step=1097; loss_value=2.201923
2018-09-15 23:45:23,652 - root - INFO - iteration 10: global_step=1098; loss_value=2.202586
2018-09-15 23:45:23,657 - root - INFO - iteration 10: global_step=1099; loss_value=2.207308
2018-09-15 23:45:23,665 - root - INFO - iteration 10: global_step=1100; loss_value=2.182066
2018-09-15 23:49:02,769 - root - INFO - lr             :	0.02
2018-09-15 23:49:02,772 - root - INFO - dr             :	0.96
2018-09-15 23:49:02,772 - root - INFO - ds             :	100
2018-09-15 23:49:02,775 - root - INFO - edr            :	0.99
2018-09-15 23:49:02,775 - root - INFO - lp             :	0.3
2018-09-15 23:49:02,775 - root - INFO - bs             :	100
2018-09-15 23:49:02,775 - root - INFO - clip           :	5
2018-09-15 23:49:02,775 - root - INFO - epoch          :	20
2018-09-15 23:49:02,775 - root - INFO - layer1_units   :	50
2018-09-15 23:49:02,775 - root - INFO - layer2_units   :	100
2018-09-15 23:49:02,775 - root - INFO - input_dimension:	784
2018-09-15 23:49:02,775 - root - INFO - num_tags       :	10
2018-09-15 23:49:02,775 - root - INFO - opt            :	Adam
2018-09-15 23:49:03,299 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-15 23:49:03,455 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-15 23:49:03,461 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-15 23:49:03,889 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-15 23:49:03,899 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-15 23:49:04,041 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-15 23:49:05,937 - root - INFO - iteration 0: global_step=1; loss_value=29.045380
2018-09-15 23:49:05,946 - root - INFO - iteration 0: global_step=2; loss_value=18.574558
2018-09-15 23:49:05,953 - root - INFO - iteration 0: global_step=3; loss_value=11.853575
2018-09-15 23:49:05,955 - root - INFO - iteration 0: global_step=4; loss_value=8.195953
2018-09-15 23:49:05,962 - root - INFO - iteration 0: global_step=5; loss_value=6.864982
2018-09-15 23:49:05,972 - root - INFO - iteration 0: global_step=6; loss_value=6.412929
2018-09-15 23:49:05,975 - root - INFO - iteration 0: global_step=7; loss_value=6.609080
2018-09-15 23:49:05,983 - root - INFO - iteration 0: global_step=8; loss_value=6.433391
2018-09-15 23:49:05,992 - root - INFO - iteration 0: global_step=9; loss_value=6.177557
2018-09-15 23:49:05,997 - root - INFO - iteration 0: global_step=10; loss_value=5.760919
2018-09-15 23:49:06,003 - root - INFO - iteration 0: global_step=11; loss_value=5.417710
2018-09-15 23:49:06,007 - root - INFO - iteration 0: global_step=12; loss_value=4.950800
2018-09-15 23:49:06,015 - root - INFO - iteration 0: global_step=13; loss_value=4.521196
2018-09-15 23:49:06,020 - root - INFO - iteration 0: global_step=14; loss_value=4.361602
2018-09-15 23:49:06,027 - root - INFO - iteration 0: global_step=15; loss_value=4.247793
2018-09-15 23:49:06,035 - root - INFO - iteration 0: global_step=16; loss_value=4.320847
2018-09-15 23:49:06,038 - root - INFO - iteration 0: global_step=17; loss_value=4.239633
2018-09-15 23:49:06,043 - root - INFO - iteration 0: global_step=18; loss_value=4.298222
2018-09-15 23:49:06,049 - root - INFO - iteration 0: global_step=19; loss_value=4.250412
2018-09-15 23:49:06,054 - root - INFO - iteration 0: global_step=20; loss_value=4.262814
2018-09-15 23:49:06,060 - root - INFO - iteration 0: global_step=21; loss_value=3.985778
2018-09-15 23:49:06,068 - root - INFO - iteration 0: global_step=22; loss_value=3.768062
2018-09-15 23:49:06,073 - root - INFO - iteration 0: global_step=23; loss_value=3.710691
2018-09-15 23:49:06,080 - root - INFO - iteration 0: global_step=24; loss_value=3.518273
2018-09-15 23:49:06,083 - root - INFO - iteration 0: global_step=25; loss_value=3.199559
2018-09-15 23:49:06,091 - root - INFO - iteration 0: global_step=26; loss_value=3.182484
2018-09-15 23:49:06,098 - root - INFO - iteration 0: global_step=27; loss_value=3.220726
2018-09-15 23:49:06,102 - root - INFO - iteration 0: global_step=28; loss_value=3.069268
2018-09-15 23:49:06,110 - root - INFO - iteration 0: global_step=29; loss_value=3.095839
2018-09-15 23:49:06,121 - root - INFO - iteration 0: global_step=30; loss_value=3.119000
2018-09-15 23:49:06,128 - root - INFO - iteration 0: global_step=31; loss_value=3.023082
2018-09-15 23:49:06,136 - root - INFO - iteration 0: global_step=32; loss_value=3.089795
2018-09-15 23:49:06,141 - root - INFO - iteration 0: global_step=33; loss_value=2.974072
2018-09-15 23:49:06,147 - root - INFO - iteration 0: global_step=34; loss_value=2.844722
2018-09-15 23:49:06,154 - root - INFO - iteration 0: global_step=35; loss_value=2.952926
2018-09-15 23:49:06,158 - root - INFO - iteration 0: global_step=36; loss_value=2.807527
2018-09-15 23:49:06,168 - root - INFO - iteration 0: global_step=37; loss_value=2.874617
2018-09-15 23:49:06,170 - root - INFO - iteration 0: global_step=38; loss_value=2.906329
2018-09-15 23:49:06,173 - root - INFO - iteration 0: global_step=39; loss_value=2.850299
2018-09-15 23:49:06,181 - root - INFO - iteration 0: global_step=40; loss_value=2.746105
2018-09-15 23:49:06,188 - root - INFO - iteration 0: global_step=41; loss_value=2.782181
2018-09-15 23:49:06,198 - root - INFO - iteration 0: global_step=42; loss_value=2.838117
2018-09-15 23:49:06,209 - root - INFO - iteration 0: global_step=43; loss_value=2.889320
2018-09-15 23:49:06,219 - root - INFO - iteration 0: global_step=44; loss_value=2.732209
2018-09-15 23:49:06,224 - root - INFO - iteration 0: global_step=45; loss_value=2.737689
2018-09-15 23:49:06,228 - root - INFO - iteration 0: global_step=46; loss_value=2.636555
2018-09-15 23:49:06,236 - root - INFO - iteration 0: global_step=47; loss_value=2.661111
2018-09-15 23:49:06,238 - root - INFO - iteration 0: global_step=48; loss_value=2.696853
2018-09-15 23:49:06,244 - root - INFO - iteration 0: global_step=49; loss_value=2.696910
2018-09-15 23:49:06,253 - root - INFO - iteration 0: global_step=50; loss_value=2.692666
2018-09-15 23:49:06,256 - root - INFO - iteration 0: global_step=51; loss_value=2.716815
2018-09-15 23:49:06,260 - root - INFO - iteration 0: global_step=52; loss_value=2.595537
2018-09-15 23:49:06,269 - root - INFO - iteration 0: global_step=53; loss_value=2.735021
2018-09-15 23:49:06,276 - root - INFO - iteration 0: global_step=54; loss_value=2.596141
2018-09-15 23:49:06,284 - root - INFO - iteration 0: global_step=55; loss_value=2.684703
2018-09-15 23:49:06,286 - root - INFO - iteration 0: global_step=56; loss_value=2.623136
2018-09-15 23:49:06,294 - root - INFO - iteration 0: global_step=57; loss_value=2.636616
2018-09-15 23:49:06,300 - root - INFO - iteration 0: global_step=58; loss_value=2.639404
2018-09-15 23:49:06,305 - root - INFO - iteration 0: global_step=59; loss_value=2.693797
2018-09-15 23:49:06,310 - root - INFO - iteration 0: global_step=60; loss_value=2.613833
2018-09-15 23:49:06,320 - root - INFO - iteration 0: global_step=61; loss_value=2.687663
2018-09-15 23:49:06,326 - root - INFO - iteration 0: global_step=62; loss_value=2.661252
2018-09-15 23:49:06,332 - root - INFO - iteration 0: global_step=63; loss_value=2.609698
2018-09-15 23:49:06,339 - root - INFO - iteration 0: global_step=64; loss_value=2.586398
2018-09-15 23:49:06,345 - root - INFO - iteration 0: global_step=65; loss_value=2.685274
2018-09-15 23:49:06,353 - root - INFO - iteration 0: global_step=66; loss_value=2.629804
2018-09-15 23:49:06,356 - root - INFO - iteration 0: global_step=67; loss_value=2.592159
2018-09-15 23:49:06,363 - root - INFO - iteration 0: global_step=68; loss_value=2.582011
2018-09-15 23:49:06,372 - root - INFO - iteration 0: global_step=69; loss_value=2.613679
2018-09-15 23:49:06,374 - root - INFO - iteration 0: global_step=70; loss_value=2.716954
2018-09-15 23:49:06,381 - root - INFO - iteration 0: global_step=71; loss_value=2.456575
2018-09-15 23:49:06,384 - root - INFO - iteration 0: global_step=72; loss_value=2.592182
2018-09-15 23:49:06,391 - root - INFO - iteration 0: global_step=73; loss_value=2.699151
2018-09-15 23:49:06,397 - root - INFO - iteration 0: global_step=74; loss_value=2.630441
2018-09-15 23:49:06,401 - root - INFO - iteration 0: global_step=75; loss_value=2.642930
2018-09-15 23:49:06,408 - root - INFO - iteration 0: global_step=76; loss_value=2.569874
2018-09-15 23:49:06,417 - root - INFO - iteration 0: global_step=77; loss_value=2.570740
2018-09-15 23:49:06,422 - root - INFO - iteration 0: global_step=78; loss_value=2.520220
2018-09-15 23:49:06,427 - root - INFO - iteration 0: global_step=79; loss_value=2.544900
2018-09-15 23:49:06,438 - root - INFO - iteration 0: global_step=80; loss_value=2.523452
2018-09-15 23:49:06,443 - root - INFO - iteration 0: global_step=81; loss_value=2.577066
2018-09-15 23:49:06,448 - root - INFO - iteration 0: global_step=82; loss_value=2.507992
2018-09-15 23:49:06,453 - root - INFO - iteration 0: global_step=83; loss_value=2.539150
2018-09-15 23:49:06,460 - root - INFO - iteration 0: global_step=84; loss_value=2.566267
2018-09-15 23:49:06,470 - root - INFO - iteration 0: global_step=85; loss_value=2.575102
2018-09-15 23:49:06,476 - root - INFO - iteration 0: global_step=86; loss_value=2.488291
2018-09-15 23:49:06,479 - root - INFO - iteration 0: global_step=87; loss_value=2.530558
2018-09-15 23:49:06,485 - root - INFO - iteration 0: global_step=88; loss_value=2.538550
2018-09-15 23:49:06,491 - root - INFO - iteration 0: global_step=89; loss_value=2.508937
2018-09-15 23:49:06,501 - root - INFO - iteration 0: global_step=90; loss_value=2.505129
2018-09-15 23:49:06,503 - root - INFO - iteration 0: global_step=91; loss_value=2.487440
2018-09-15 23:49:06,512 - root - INFO - iteration 0: global_step=92; loss_value=2.628029
2018-09-15 23:49:06,516 - root - INFO - iteration 0: global_step=93; loss_value=2.531005
2018-09-15 23:49:06,523 - root - INFO - iteration 0: global_step=94; loss_value=2.398173
2018-09-15 23:49:06,530 - root - INFO - iteration 0: global_step=95; loss_value=2.538752
2018-09-15 23:49:06,537 - root - INFO - iteration 0: global_step=96; loss_value=2.525562
2018-09-15 23:49:06,544 - root - INFO - iteration 0: global_step=97; loss_value=2.472177
2018-09-15 23:49:06,550 - root - INFO - iteration 0: global_step=98; loss_value=2.481454
2018-09-15 23:49:06,556 - root - INFO - iteration 0: global_step=99; loss_value=2.485274
2018-09-15 23:49:06,570 - root - INFO - iteration 0: global_step=100; loss_value=2.477912
2018-09-15 23:49:09,901 - root - INFO - iteration 10: global_step=1001; loss_value=2.215188
2018-09-15 23:49:09,909 - root - INFO - iteration 10: global_step=1002; loss_value=2.172500
2018-09-15 23:49:09,918 - root - INFO - iteration 10: global_step=1003; loss_value=2.236604
2018-09-15 23:49:09,920 - root - INFO - iteration 10: global_step=1004; loss_value=2.235989
2018-09-15 23:49:09,924 - root - INFO - iteration 10: global_step=1005; loss_value=2.168676
2018-09-15 23:49:09,931 - root - INFO - iteration 10: global_step=1006; loss_value=2.159089
2018-09-15 23:49:09,935 - root - INFO - iteration 10: global_step=1007; loss_value=2.173114
2018-09-15 23:49:09,941 - root - INFO - iteration 10: global_step=1008; loss_value=2.117211
2018-09-15 23:49:09,946 - root - INFO - iteration 10: global_step=1009; loss_value=2.143332
2018-09-15 23:49:09,951 - root - INFO - iteration 10: global_step=1010; loss_value=2.154059
2018-09-15 23:49:09,956 - root - INFO - iteration 10: global_step=1011; loss_value=2.229210
2018-09-15 23:49:09,968 - root - INFO - iteration 10: global_step=1012; loss_value=2.235585
2018-09-15 23:49:09,978 - root - INFO - iteration 10: global_step=1013; loss_value=2.150160
2018-09-15 23:49:09,986 - root - INFO - iteration 10: global_step=1014; loss_value=2.221907
2018-09-15 23:49:09,993 - root - INFO - iteration 10: global_step=1015; loss_value=2.107545
2018-09-15 23:49:10,000 - root - INFO - iteration 10: global_step=1016; loss_value=2.146183
2018-09-15 23:49:10,003 - root - INFO - iteration 10: global_step=1017; loss_value=2.211776
2018-09-15 23:49:10,009 - root - INFO - iteration 10: global_step=1018; loss_value=2.171834
2018-09-15 23:49:10,014 - root - INFO - iteration 10: global_step=1019; loss_value=2.232971
2018-09-15 23:49:10,018 - root - INFO - iteration 10: global_step=1020; loss_value=2.295348
2018-09-15 23:49:10,026 - root - INFO - iteration 10: global_step=1021; loss_value=2.208981
2018-09-15 23:49:10,037 - root - INFO - iteration 10: global_step=1022; loss_value=2.241384
2018-09-15 23:49:10,042 - root - INFO - iteration 10: global_step=1023; loss_value=2.266214
2018-09-15 23:49:10,052 - root - INFO - iteration 10: global_step=1024; loss_value=2.226146
2018-09-15 23:49:10,068 - root - INFO - iteration 10: global_step=1025; loss_value=2.220311
2018-09-15 23:49:10,070 - root - INFO - iteration 10: global_step=1026; loss_value=2.310212
2018-09-15 23:49:10,076 - root - INFO - iteration 10: global_step=1027; loss_value=2.219292
2018-09-15 23:49:10,078 - root - INFO - iteration 10: global_step=1028; loss_value=2.223382
2018-09-15 23:49:10,085 - root - INFO - iteration 10: global_step=1029; loss_value=2.159232
2018-09-15 23:49:10,087 - root - INFO - iteration 10: global_step=1030; loss_value=2.227485
2018-09-15 23:49:10,095 - root - INFO - iteration 10: global_step=1031; loss_value=2.182718
2018-09-15 23:49:10,101 - root - INFO - iteration 10: global_step=1032; loss_value=2.180474
2018-09-15 23:49:10,103 - root - INFO - iteration 10: global_step=1033; loss_value=2.247307
2018-09-15 23:49:10,107 - root - INFO - iteration 10: global_step=1034; loss_value=2.234927
2018-09-15 23:49:10,114 - root - INFO - iteration 10: global_step=1035; loss_value=2.213257
2018-09-15 23:49:10,121 - root - INFO - iteration 10: global_step=1036; loss_value=2.216048
2018-09-15 23:49:10,126 - root - INFO - iteration 10: global_step=1037; loss_value=2.198470
2018-09-15 23:49:10,135 - root - INFO - iteration 10: global_step=1038; loss_value=2.295619
2018-09-15 23:49:10,153 - root - INFO - iteration 10: global_step=1039; loss_value=2.229289
2018-09-15 23:49:10,161 - root - INFO - iteration 10: global_step=1040; loss_value=2.225274
2018-09-15 23:49:10,165 - root - INFO - iteration 10: global_step=1041; loss_value=2.213752
2018-09-15 23:49:10,172 - root - INFO - iteration 10: global_step=1042; loss_value=2.162464
2018-09-15 23:49:10,180 - root - INFO - iteration 10: global_step=1043; loss_value=2.220796
2018-09-15 23:49:10,183 - root - INFO - iteration 10: global_step=1044; loss_value=2.206087
2018-09-15 23:49:10,193 - root - INFO - iteration 10: global_step=1045; loss_value=2.286891
2018-09-15 23:49:10,196 - root - INFO - iteration 10: global_step=1046; loss_value=2.214399
2018-09-15 23:49:10,204 - root - INFO - iteration 10: global_step=1047; loss_value=2.230951
2018-09-15 23:49:10,208 - root - INFO - iteration 10: global_step=1048; loss_value=2.156815
2018-09-15 23:49:10,216 - root - INFO - iteration 10: global_step=1049; loss_value=2.187375
2018-09-15 23:49:10,223 - root - INFO - iteration 10: global_step=1050; loss_value=2.190579
2018-09-15 23:49:10,227 - root - INFO - iteration 10: global_step=1051; loss_value=2.232428
2018-09-15 23:49:10,232 - root - INFO - iteration 10: global_step=1052; loss_value=2.141170
2018-09-15 23:49:10,239 - root - INFO - iteration 10: global_step=1053; loss_value=2.286069
2018-09-15 23:49:10,246 - root - INFO - iteration 10: global_step=1054; loss_value=2.208586
2018-09-15 23:49:10,259 - root - INFO - iteration 10: global_step=1055; loss_value=2.190225
2018-09-15 23:49:10,272 - root - INFO - iteration 10: global_step=1056; loss_value=2.181675
2018-09-15 23:49:10,276 - root - INFO - iteration 10: global_step=1057; loss_value=2.207537
2018-09-15 23:49:10,282 - root - INFO - iteration 10: global_step=1058; loss_value=2.259430
2018-09-15 23:49:10,290 - root - INFO - iteration 10: global_step=1059; loss_value=2.155242
2018-09-15 23:49:10,297 - root - INFO - iteration 10: global_step=1060; loss_value=2.192884
2018-09-15 23:49:10,299 - root - INFO - iteration 10: global_step=1061; loss_value=2.110654
2018-09-15 23:49:10,306 - root - INFO - iteration 10: global_step=1062; loss_value=2.227196
2018-09-15 23:49:10,308 - root - INFO - iteration 10: global_step=1063; loss_value=2.269589
2018-09-15 23:49:10,317 - root - INFO - iteration 10: global_step=1064; loss_value=2.150286
2018-09-15 23:49:10,324 - root - INFO - iteration 10: global_step=1065; loss_value=2.253366
2018-09-15 23:49:10,331 - root - INFO - iteration 10: global_step=1066; loss_value=2.324323
2018-09-15 23:49:10,336 - root - INFO - iteration 10: global_step=1067; loss_value=2.212150
2018-09-15 23:49:10,344 - root - INFO - iteration 10: global_step=1068; loss_value=2.278864
2018-09-15 23:49:10,355 - root - INFO - iteration 10: global_step=1069; loss_value=2.151998
2018-09-15 23:49:10,361 - root - INFO - iteration 10: global_step=1070; loss_value=2.220502
2018-09-15 23:49:10,366 - root - INFO - iteration 10: global_step=1071; loss_value=2.259748
2018-09-15 23:49:10,370 - root - INFO - iteration 10: global_step=1072; loss_value=2.242343
2018-09-15 23:49:10,378 - root - INFO - iteration 10: global_step=1073; loss_value=2.363911
2018-09-15 23:49:10,382 - root - INFO - iteration 10: global_step=1074; loss_value=2.226030
2018-09-15 23:49:10,388 - root - INFO - iteration 10: global_step=1075; loss_value=2.214301
2018-09-15 23:49:10,396 - root - INFO - iteration 10: global_step=1076; loss_value=2.258065
2018-09-15 23:49:10,400 - root - INFO - iteration 10: global_step=1077; loss_value=2.197204
2018-09-15 23:49:10,408 - root - INFO - iteration 10: global_step=1078; loss_value=2.271802
2018-09-15 23:49:10,412 - root - INFO - iteration 10: global_step=1079; loss_value=2.271040
2018-09-15 23:49:10,420 - root - INFO - iteration 10: global_step=1080; loss_value=2.275465
2018-09-15 23:49:10,423 - root - INFO - iteration 10: global_step=1081; loss_value=2.197288
2018-09-15 23:49:10,429 - root - INFO - iteration 10: global_step=1082; loss_value=2.259449
2018-09-15 23:49:10,438 - root - INFO - iteration 10: global_step=1083; loss_value=2.245891
2018-09-15 23:49:10,446 - root - INFO - iteration 10: global_step=1084; loss_value=2.298256
2018-09-15 23:49:10,452 - root - INFO - iteration 10: global_step=1085; loss_value=2.246464
2018-09-15 23:49:10,456 - root - INFO - iteration 10: global_step=1086; loss_value=2.218412
2018-09-15 23:49:10,462 - root - INFO - iteration 10: global_step=1087; loss_value=2.147275
2018-09-15 23:49:10,471 - root - INFO - iteration 10: global_step=1088; loss_value=2.212197
2018-09-15 23:49:10,478 - root - INFO - iteration 10: global_step=1089; loss_value=2.230009
2018-09-15 23:49:10,483 - root - INFO - iteration 10: global_step=1090; loss_value=2.166110
2018-09-15 23:49:10,491 - root - INFO - iteration 10: global_step=1091; loss_value=2.159431
2018-09-15 23:49:10,494 - root - INFO - iteration 10: global_step=1092; loss_value=2.195475
2018-09-15 23:49:10,505 - root - INFO - iteration 10: global_step=1093; loss_value=2.330730
2018-09-15 23:49:10,508 - root - INFO - iteration 10: global_step=1094; loss_value=2.327441
2018-09-15 23:49:10,515 - root - INFO - iteration 10: global_step=1095; loss_value=2.265876
2018-09-15 23:49:10,521 - root - INFO - iteration 10: global_step=1096; loss_value=2.147706
2018-09-15 23:49:10,526 - root - INFO - iteration 10: global_step=1097; loss_value=2.136478
2018-09-15 23:49:10,533 - root - INFO - iteration 10: global_step=1098; loss_value=2.268918
2018-09-15 23:49:10,535 - root - INFO - iteration 10: global_step=1099; loss_value=2.259695
2018-09-15 23:49:10,541 - root - INFO - iteration 10: global_step=1100; loss_value=2.216100
2018-09-17 13:29:49,761 - root - INFO - lr             :	0.02
2018-09-17 13:29:49,766 - root - INFO - dr             :	0.96
2018-09-17 13:29:49,767 - root - INFO - ds             :	100
2018-09-17 13:29:49,767 - root - INFO - edr            :	0.99
2018-09-17 13:29:49,767 - root - INFO - lp             :	0.3
2018-09-17 13:29:49,767 - root - INFO - bs             :	100
2018-09-17 13:29:49,767 - root - INFO - clip           :	5
2018-09-17 13:29:49,767 - root - INFO - epoch          :	20
2018-09-17 13:29:49,767 - root - INFO - layer1_units   :	50
2018-09-17 13:29:49,767 - root - INFO - layer2_units   :	100
2018-09-17 13:29:49,768 - root - INFO - input_dimension:	784
2018-09-17 13:29:49,768 - root - INFO - num_tags       :	10
2018-09-17 13:29:49,768 - root - INFO - opt            :	Adam
2018-09-17 13:29:50,164 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-17 13:29:50,277 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-17 13:29:50,283 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-17 13:29:50,684 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-17 13:29:50,691 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-17 13:29:50,875 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-17 13:29:52,076 - root - INFO - iteration 0: global_step=1; loss_value=28.458048
2018-09-17 13:29:52,086 - root - INFO - iteration 0: global_step=2; loss_value=17.959755
2018-09-17 13:29:52,088 - root - INFO - iteration 0: global_step=3; loss_value=11.411758
2018-09-17 13:29:52,092 - root - INFO - iteration 0: global_step=4; loss_value=7.957103
2018-09-17 13:29:52,098 - root - INFO - iteration 0: global_step=5; loss_value=6.846867
2018-09-17 13:29:52,104 - root - INFO - iteration 0: global_step=6; loss_value=6.344579
2018-09-17 13:29:52,106 - root - INFO - iteration 0: global_step=7; loss_value=6.444432
2018-09-17 13:29:52,112 - root - INFO - iteration 0: global_step=8; loss_value=6.228090
2018-09-17 13:29:52,117 - root - INFO - iteration 0: global_step=9; loss_value=6.138711
2018-09-17 13:29:52,119 - root - INFO - iteration 0: global_step=10; loss_value=5.718606
2018-09-17 13:29:52,125 - root - INFO - iteration 0: global_step=11; loss_value=5.342452
2018-09-17 13:29:52,133 - root - INFO - iteration 0: global_step=12; loss_value=4.934777
2018-09-17 13:29:52,141 - root - INFO - iteration 0: global_step=13; loss_value=4.488009
2018-09-17 13:29:52,148 - root - INFO - iteration 0: global_step=14; loss_value=4.314489
2018-09-17 13:29:52,153 - root - INFO - iteration 0: global_step=15; loss_value=4.293728
2018-09-17 13:29:52,155 - root - INFO - iteration 0: global_step=16; loss_value=4.292318
2018-09-17 13:29:52,160 - root - INFO - iteration 0: global_step=17; loss_value=4.250533
2018-09-17 13:29:52,169 - root - INFO - iteration 0: global_step=18; loss_value=4.319167
2018-09-17 13:29:52,171 - root - INFO - iteration 0: global_step=19; loss_value=4.257620
2018-09-17 13:29:52,173 - root - INFO - iteration 0: global_step=20; loss_value=4.140806
2018-09-17 13:29:52,180 - root - INFO - iteration 0: global_step=21; loss_value=4.039525
2018-09-17 13:29:52,185 - root - INFO - iteration 0: global_step=22; loss_value=3.806305
2018-09-17 13:29:52,188 - root - INFO - iteration 0: global_step=23; loss_value=3.701146
2018-09-17 13:29:52,193 - root - INFO - iteration 0: global_step=24; loss_value=3.546798
2018-09-17 13:29:52,198 - root - INFO - iteration 0: global_step=25; loss_value=3.419542
2018-09-17 13:29:52,201 - root - INFO - iteration 0: global_step=26; loss_value=3.244680
2018-09-17 13:29:52,209 - root - INFO - iteration 0: global_step=27; loss_value=3.202363
2018-09-17 13:29:52,217 - root - INFO - iteration 0: global_step=28; loss_value=3.212661
2018-09-17 13:29:52,221 - root - INFO - iteration 0: global_step=29; loss_value=3.148911
2018-09-17 13:29:52,225 - root - INFO - iteration 0: global_step=30; loss_value=3.002241
2018-09-17 13:29:52,233 - root - INFO - iteration 0: global_step=31; loss_value=3.093077
2018-09-17 13:29:52,236 - root - INFO - iteration 0: global_step=32; loss_value=3.051586
2018-09-17 13:29:52,241 - root - INFO - iteration 0: global_step=33; loss_value=2.999489
2018-09-17 13:29:52,247 - root - INFO - iteration 0: global_step=34; loss_value=2.969190
2018-09-17 13:29:52,249 - root - INFO - iteration 0: global_step=35; loss_value=3.056909
2018-09-17 13:29:52,254 - root - INFO - iteration 0: global_step=36; loss_value=3.015251
2018-09-17 13:29:52,259 - root - INFO - iteration 0: global_step=37; loss_value=2.959213
2018-09-17 13:29:52,262 - root - INFO - iteration 0: global_step=38; loss_value=2.893356
2018-09-17 13:29:52,268 - root - INFO - iteration 0: global_step=39; loss_value=2.870070
2018-09-17 13:29:52,273 - root - INFO - iteration 0: global_step=40; loss_value=2.881502
2018-09-17 13:29:52,276 - root - INFO - iteration 0: global_step=41; loss_value=2.848881
2018-09-17 13:29:52,282 - root - INFO - iteration 0: global_step=42; loss_value=2.793052
2018-09-17 13:29:52,288 - root - INFO - iteration 0: global_step=43; loss_value=2.837650
2018-09-17 13:29:52,298 - root - INFO - iteration 0: global_step=44; loss_value=2.757841
2018-09-17 13:29:52,300 - root - INFO - iteration 0: global_step=45; loss_value=2.694556
2018-09-17 13:29:52,305 - root - INFO - iteration 0: global_step=46; loss_value=2.688667
2018-09-17 13:29:52,310 - root - INFO - iteration 0: global_step=47; loss_value=2.770474
2018-09-17 13:29:52,319 - root - INFO - iteration 0: global_step=48; loss_value=2.888059
2018-09-17 13:29:52,327 - root - INFO - iteration 0: global_step=49; loss_value=2.777304
2018-09-17 13:29:52,329 - root - INFO - iteration 0: global_step=50; loss_value=2.725814
2018-09-17 13:29:52,331 - root - INFO - iteration 0: global_step=51; loss_value=2.639787
2018-09-17 13:29:52,337 - root - INFO - iteration 0: global_step=52; loss_value=2.684864
2018-09-17 13:29:52,342 - root - INFO - iteration 0: global_step=53; loss_value=2.687982
2018-09-17 13:29:52,346 - root - INFO - iteration 0: global_step=54; loss_value=2.710762
2018-09-17 13:29:52,351 - root - INFO - iteration 0: global_step=55; loss_value=2.833707
2018-09-17 13:29:52,355 - root - INFO - iteration 0: global_step=56; loss_value=2.653228
2018-09-17 13:29:52,360 - root - INFO - iteration 0: global_step=57; loss_value=2.623280
2018-09-17 13:29:52,364 - root - INFO - iteration 0: global_step=58; loss_value=2.629865
2018-09-17 13:29:52,369 - root - INFO - iteration 0: global_step=59; loss_value=2.654271
2018-09-17 13:29:52,372 - root - INFO - iteration 0: global_step=60; loss_value=2.707774
2018-09-17 13:29:52,376 - root - INFO - iteration 0: global_step=61; loss_value=2.657527
2018-09-17 13:29:52,380 - root - INFO - iteration 0: global_step=62; loss_value=2.725975
2018-09-17 13:29:52,384 - root - INFO - iteration 0: global_step=63; loss_value=2.617976
2018-09-17 13:29:52,389 - root - INFO - iteration 0: global_step=64; loss_value=2.703252
2018-09-17 13:29:52,398 - root - INFO - iteration 0: global_step=65; loss_value=2.599374
2018-09-17 13:29:52,401 - root - INFO - iteration 0: global_step=66; loss_value=2.584085
2018-09-17 13:29:52,403 - root - INFO - iteration 0: global_step=67; loss_value=2.680745
2018-09-17 13:29:52,408 - root - INFO - iteration 0: global_step=68; loss_value=2.669717
2018-09-17 13:29:52,414 - root - INFO - iteration 0: global_step=69; loss_value=2.610893
2018-09-17 13:29:52,416 - root - INFO - iteration 0: global_step=70; loss_value=2.512084
2018-09-17 13:29:52,421 - root - INFO - iteration 0: global_step=71; loss_value=2.617723
2018-09-17 13:29:52,431 - root - INFO - iteration 0: global_step=72; loss_value=2.579332
2018-09-17 13:29:52,442 - root - INFO - iteration 0: global_step=73; loss_value=2.588379
2018-09-17 13:29:52,444 - root - INFO - iteration 0: global_step=74; loss_value=2.542813
2018-09-17 13:29:52,450 - root - INFO - iteration 0: global_step=75; loss_value=2.499729
2018-09-17 13:29:52,452 - root - INFO - iteration 0: global_step=76; loss_value=2.631196
2018-09-17 13:29:52,458 - root - INFO - iteration 0: global_step=77; loss_value=2.587772
2018-09-17 13:29:52,460 - root - INFO - iteration 0: global_step=78; loss_value=2.614697
2018-09-17 13:29:52,468 - root - INFO - iteration 0: global_step=79; loss_value=2.662873
2018-09-17 13:29:52,470 - root - INFO - iteration 0: global_step=80; loss_value=2.625543
2018-09-17 13:29:52,474 - root - INFO - iteration 0: global_step=81; loss_value=2.554816
2018-09-17 13:29:52,479 - root - INFO - iteration 0: global_step=82; loss_value=2.661016
2018-09-17 13:29:52,484 - root - INFO - iteration 0: global_step=83; loss_value=2.552248
2018-09-17 13:29:52,488 - root - INFO - iteration 0: global_step=84; loss_value=2.532513
2018-09-17 13:29:52,492 - root - INFO - iteration 0: global_step=85; loss_value=2.479485
2018-09-17 13:29:52,501 - root - INFO - iteration 0: global_step=86; loss_value=2.513287
2018-09-17 13:29:52,503 - root - INFO - iteration 0: global_step=87; loss_value=2.481020
2018-09-17 13:29:52,505 - root - INFO - iteration 0: global_step=88; loss_value=2.477129
2018-09-17 13:29:52,513 - root - INFO - iteration 0: global_step=89; loss_value=2.581339
2018-09-17 13:29:52,515 - root - INFO - iteration 0: global_step=90; loss_value=2.518108
2018-09-17 13:29:52,519 - root - INFO - iteration 0: global_step=91; loss_value=2.539371
2018-09-17 13:29:52,526 - root - INFO - iteration 0: global_step=92; loss_value=2.504132
2018-09-17 13:29:52,533 - root - INFO - iteration 0: global_step=93; loss_value=2.571327
2018-09-17 13:29:52,540 - root - INFO - iteration 0: global_step=94; loss_value=2.531653
2018-09-17 13:29:52,544 - root - INFO - iteration 0: global_step=95; loss_value=2.520289
2018-09-17 13:29:52,550 - root - INFO - iteration 0: global_step=96; loss_value=2.569130
2018-09-17 13:29:52,558 - root - INFO - iteration 0: global_step=97; loss_value=2.608265
2018-09-17 13:29:52,560 - root - INFO - iteration 0: global_step=98; loss_value=2.617069
2018-09-17 13:29:52,562 - root - INFO - iteration 0: global_step=99; loss_value=2.529029
2018-09-17 13:29:52,566 - root - INFO - iteration 0: global_step=100; loss_value=2.457802
2018-09-17 13:29:52,645 - root - INFO - forecast result:
[[ 3.3059015  2.6895494  3.1298244 ... -1.4090663 -1.2466443 -1.4114566]
 [ 4.8185296  1.1676948  3.1587975 ... -1.4098778 -1.2473196 -1.4126456]
 [ 2.3042233  2.151166   2.5537162 ... -1.3717369 -1.2016317 -1.3740417]
 ...
 [ 3.6112106  2.2921991  3.4959507 ... -1.4143354 -1.2522099 -1.4165617]
 [ 1.1566489  3.9198618  2.7747085 ... -1.3576922 -1.1852314 -1.3590949]
 [ 2.2757432  3.3697853  3.731717  ... -1.4046626 -1.2399611 -1.4059427]]
2018-09-17 13:29:52,956 - root - INFO - forecast result:
[[ 2.8543026  2.5095744  2.7499824 ... -2.2177854 -2.0648313 -2.2270982]
 [ 4.1779637  1.2302003  2.790844  ... -2.2179127 -2.065319  -2.2275476]
 [ 2.162613   2.4346962  2.453631  ... -2.2086682 -2.0538342 -2.2179937]
 ...
 [ 3.131612   2.1985862  2.976982  ... -2.219553  -2.0668797 -2.2289202]
 [ 1.2507151  3.8562126  2.7554984 ... -2.204206  -2.0486126 -2.2134094]
 [ 2.012339   3.2321029  3.2174647 ... -2.2162046 -2.0626664 -2.2254257]]
2018-09-17 13:29:53,249 - root - INFO - forecast result:
[[ 2.571757    2.2278695   2.4467325  ... -2.8959734  -2.7466779
  -2.9070208 ]
 [ 4.0506005   0.76051986  2.481409   ... -2.8963525  -2.747065
  -2.9075327 ]
 [ 1.8867288   2.1381912   2.201243   ... -2.892771   -2.7429497
  -2.9038656 ]
 ...
 [ 2.8843682   1.7462827   2.796187   ... -2.8972     -2.7481072
  -2.9082656 ]
 [ 0.9457567   3.6352835   2.4412642  ... -2.8896892  -2.739452
  -2.9006977 ]
 [ 1.6980897   2.7725563   3.035975   ... -2.8958387  -2.7465894
  -2.9068246 ]]
2018-09-17 13:29:53,582 - root - INFO - forecast result:
[[ 2.2991853  1.9425833  2.204589  ... -3.4695096 -3.3208466 -3.4813967]
 [ 3.6646042  0.6439518  2.3054512 ... -3.4703076 -3.3218641 -3.4821653]
 [ 1.7441914  1.9173603  1.9652818 ... -3.4689054 -3.3201168 -3.4809673]
 ...
 [ 2.6322985  1.531698   2.4093308 ... -3.470448  -3.3219674 -3.482345 ]
 [ 0.8633237  3.2751825  2.2239912 ... -3.4670336 -3.3179102 -3.4791198]
 [ 1.578415   2.5471249  2.655404  ... -3.4695785 -3.3209329 -3.4816039]]
2018-09-17 13:29:53,909 - root - INFO - forecast result:
[[ 2.0892868   1.777116    1.9816859  ... -3.9637766  -3.81656
  -3.976032  ]
 [ 3.4254346   0.42435205  2.0412831  ... -3.9644368  -3.817342
  -3.9767554 ]
 [ 1.4804949   1.7587115   1.8078294  ... -3.9634645  -3.8161955
  -3.975759  ]
 ...
 [ 2.3549604   1.3893045   2.239843   ... -3.9642735  -3.8171322
  -3.9765534 ]
 [ 0.58976877  3.2688851   2.1414175  ... -3.96254    -3.815106
  -3.9747715 ]
 [ 1.2748497   2.4532142   2.5567317  ... -3.9637797  -3.8165283
  -3.9760292 ]]
2018-09-17 13:29:54,313 - root - INFO - forecast result:
[[ 2.0533404   1.6795198   1.8457254  ... -4.377182   -4.2317195
  -4.3895745 ]
 [ 3.4413614   0.2760514   1.914074   ... -4.377691   -4.2323008
  -4.390077  ]
 [ 1.3595877   1.6873162   1.7196599  ... -4.376842   -4.231305
  -4.389213  ]
 ...
 [ 2.2964168   1.2655375   2.0769973  ... -4.3774133  -4.2319775
  -4.389792  ]
 [ 0.48988265  3.2263331   1.9986432  ... -4.3762813  -4.23067
  -4.3886666 ]
 [ 1.1474849   2.3765888   2.3830764  ... -4.377199   -4.2317233
  -4.3895626 ]]
2018-09-17 13:29:54,605 - root - INFO - forecast result:
[[ 1.990397    1.6857995   1.8684378  ... -4.7196164  -4.5753927
  -4.7320223 ]
 [ 3.3607996   0.31106102  1.9553775  ... -4.7201834  -4.5760403
  -4.732575  ]
 [ 1.3732562   1.6524321   1.6964836  ... -4.719286   -4.575038
  -4.7317133 ]
 ...
 [ 2.2992358   1.2455871   2.0941198  ... -4.719865   -4.5756836
  -4.73227   ]
 [ 0.48644435  3.143528    1.981304   ... -4.718843   -4.5745134
  -4.7312737 ]
 [ 1.1887102   2.2880538   2.3447027  ... -4.7194753  -4.5752444
  -4.731897  ]]
2018-09-17 13:29:54,901 - root - INFO - forecast result:
[[ 1.9799612   1.6831379   1.8333318  ... -5.0050235  -4.8619027
  -5.0174274 ]
 [ 3.2854314   0.34146237  1.9157697  ... -5.0056157  -4.8625975
  -5.0180106 ]
 [ 1.4047579   1.6150736   1.6710123  ... -5.0047274  -4.8615627
  -5.0171385 ]
 ...
 [ 2.2541006   1.2486837   2.0931726  ... -5.005186   -4.862092
  -5.0175867 ]
 [ 0.5588814   3.0633225   1.9367919  ... -5.0043564  -4.8611293
  -5.0167737 ]
 [ 1.2023152   2.2338228   2.3491068  ... -5.0047894  -4.861628
  -5.017197  ]]
2018-09-17 13:29:55,200 - root - INFO - forecast result:
[[ 2.0175292   1.7059908   1.8207853  ... -5.2479353  -5.1057734
  -5.260299  ]
 [ 3.2987194   0.42726457  1.8948922  ... -5.2485967  -5.1065445
  -5.2609506 ]
 [ 1.4080226   1.5898378   1.6454521  ... -5.2476425  -5.1054325
  -5.2600007 ]
 ...
 [ 2.266344    1.2819085   2.0428064  ... -5.2480364  -5.105895
  -5.260394  ]
 [ 0.6352066   3.0133212   1.9131062  ... -5.247229   -5.1049566
  -5.2595987 ]
 [ 1.2330972   2.203919    2.2967076  ... -5.247599   -5.105391
  -5.2599587 ]]
2018-09-17 13:29:55,521 - root - INFO - forecast result:
[[ 2.075523    1.681119    1.8724755  ... -5.4661565  -5.324758
  -5.4784946 ]
 [ 3.382382    0.37177837  1.9550595  ... -5.46684    -5.325554
  -5.4791675 ]
 [ 1.4329644   1.6238831   1.6893489  ... -5.4658594  -5.3244276
  -5.4782076 ]
 ...
 [ 2.332009    1.2653221   2.0611787  ... -5.466289   -5.3249173
  -5.4786263 ]
 [ 0.6149318   3.0991569   1.9501642  ... -5.4655204  -5.3240247
  -5.477871  ]
 [ 1.2490574   2.286474    2.2875645  ... -5.465866   -5.3244286
  -5.4782114 ]]
2018-09-17 13:29:55,583 - root - INFO - iteration 10: global_step=1001; loss_value=2.331310
2018-09-17 13:29:55,589 - root - INFO - iteration 10: global_step=1002; loss_value=2.280443
2018-09-17 13:29:55,597 - root - INFO - iteration 10: global_step=1003; loss_value=2.241354
2018-09-17 13:29:55,599 - root - INFO - iteration 10: global_step=1004; loss_value=2.314464
2018-09-17 13:29:55,601 - root - INFO - iteration 10: global_step=1005; loss_value=2.254701
2018-09-17 13:29:55,608 - root - INFO - iteration 10: global_step=1006; loss_value=2.269750
2018-09-17 13:29:55,610 - root - INFO - iteration 10: global_step=1007; loss_value=2.208738
2018-09-17 13:29:55,617 - root - INFO - iteration 10: global_step=1008; loss_value=2.240461
2018-09-17 13:29:55,619 - root - INFO - iteration 10: global_step=1009; loss_value=2.195313
2018-09-17 13:29:55,625 - root - INFO - iteration 10: global_step=1010; loss_value=2.198659
2018-09-17 13:29:55,629 - root - INFO - iteration 10: global_step=1011; loss_value=2.157859
2018-09-17 13:29:55,636 - root - INFO - iteration 10: global_step=1012; loss_value=2.217731
2018-09-17 13:29:55,644 - root - INFO - iteration 10: global_step=1013; loss_value=2.200180
2018-09-17 13:29:55,651 - root - INFO - iteration 10: global_step=1014; loss_value=2.227044
2018-09-17 13:29:55,653 - root - INFO - iteration 10: global_step=1015; loss_value=2.279960
2018-09-17 13:29:55,659 - root - INFO - iteration 10: global_step=1016; loss_value=2.207794
2018-09-17 13:29:55,661 - root - INFO - iteration 10: global_step=1017; loss_value=2.268808
2018-09-17 13:29:55,670 - root - INFO - iteration 10: global_step=1018; loss_value=2.197806
2018-09-17 13:29:55,672 - root - INFO - iteration 10: global_step=1019; loss_value=2.227660
2018-09-17 13:29:55,678 - root - INFO - iteration 10: global_step=1020; loss_value=2.238793
2018-09-17 13:29:55,680 - root - INFO - iteration 10: global_step=1021; loss_value=2.230575
2018-09-17 13:29:55,684 - root - INFO - iteration 10: global_step=1022; loss_value=2.266767
2018-09-17 13:29:55,691 - root - INFO - iteration 10: global_step=1023; loss_value=2.236309
2018-09-17 13:29:55,693 - root - INFO - iteration 10: global_step=1024; loss_value=2.259588
2018-09-17 13:29:55,696 - root - INFO - iteration 10: global_step=1025; loss_value=2.281431
2018-09-17 13:29:55,704 - root - INFO - iteration 10: global_step=1026; loss_value=2.284734
2018-09-17 13:29:55,706 - root - INFO - iteration 10: global_step=1027; loss_value=2.261047
2018-09-17 13:29:55,711 - root - INFO - iteration 10: global_step=1028; loss_value=2.314063
2018-09-17 13:29:55,717 - root - INFO - iteration 10: global_step=1029; loss_value=2.283123
2018-09-17 13:29:55,721 - root - INFO - iteration 10: global_step=1030; loss_value=2.251798
2018-09-17 13:29:55,725 - root - INFO - iteration 10: global_step=1031; loss_value=2.250356
2018-09-17 13:29:55,732 - root - INFO - iteration 10: global_step=1032; loss_value=2.272034
2018-09-17 13:29:55,740 - root - INFO - iteration 10: global_step=1033; loss_value=2.195443
2018-09-17 13:29:55,744 - root - INFO - iteration 10: global_step=1034; loss_value=2.264430
2018-09-17 13:29:55,748 - root - INFO - iteration 10: global_step=1035; loss_value=2.227030
2018-09-17 13:29:55,758 - root - INFO - iteration 10: global_step=1036; loss_value=2.272686
2018-09-17 13:29:55,760 - root - INFO - iteration 10: global_step=1037; loss_value=2.192203
2018-09-17 13:29:55,767 - root - INFO - iteration 10: global_step=1038; loss_value=2.183337
2018-09-17 13:29:55,769 - root - INFO - iteration 10: global_step=1039; loss_value=2.340796
2018-09-17 13:29:55,775 - root - INFO - iteration 10: global_step=1040; loss_value=2.165214
2018-09-17 13:29:55,777 - root - INFO - iteration 10: global_step=1041; loss_value=2.267414
2018-09-17 13:29:55,783 - root - INFO - iteration 10: global_step=1042; loss_value=2.257768
2018-09-17 13:29:55,788 - root - INFO - iteration 10: global_step=1043; loss_value=2.240141
2018-09-17 13:29:55,792 - root - INFO - iteration 10: global_step=1044; loss_value=2.183233
2018-09-17 13:29:55,796 - root - INFO - iteration 10: global_step=1045; loss_value=2.206178
2018-09-17 13:29:55,801 - root - INFO - iteration 10: global_step=1046; loss_value=2.220840
2018-09-17 13:29:55,808 - root - INFO - iteration 10: global_step=1047; loss_value=2.267546
2018-09-17 13:29:55,816 - root - INFO - iteration 10: global_step=1048; loss_value=2.176549
2018-09-17 13:29:55,820 - root - INFO - iteration 10: global_step=1049; loss_value=2.264538
2018-09-17 13:29:55,826 - root - INFO - iteration 10: global_step=1050; loss_value=2.121722
2018-09-17 13:29:55,830 - root - INFO - iteration 10: global_step=1051; loss_value=2.113382
2018-09-17 13:29:55,834 - root - INFO - iteration 10: global_step=1052; loss_value=2.186887
2018-09-17 13:29:55,839 - root - INFO - iteration 10: global_step=1053; loss_value=2.388033
2018-09-17 13:29:55,844 - root - INFO - iteration 10: global_step=1054; loss_value=2.167760
2018-09-17 13:29:55,850 - root - INFO - iteration 10: global_step=1055; loss_value=2.189075
2018-09-17 13:29:55,853 - root - INFO - iteration 10: global_step=1056; loss_value=2.231758
2018-09-17 13:29:55,857 - root - INFO - iteration 10: global_step=1057; loss_value=2.244407
2018-09-17 13:29:55,861 - root - INFO - iteration 10: global_step=1058; loss_value=2.228238
2018-09-17 13:29:55,867 - root - INFO - iteration 10: global_step=1059; loss_value=2.209418
2018-09-17 13:29:55,872 - root - INFO - iteration 10: global_step=1060; loss_value=2.216789
2018-09-17 13:29:55,878 - root - INFO - iteration 10: global_step=1061; loss_value=2.248226
2018-09-17 13:29:55,887 - root - INFO - iteration 10: global_step=1062; loss_value=2.172110
2018-09-17 13:29:55,894 - root - INFO - iteration 10: global_step=1063; loss_value=2.263654
2018-09-17 13:29:55,896 - root - INFO - iteration 10: global_step=1064; loss_value=2.183318
2018-09-17 13:29:55,900 - root - INFO - iteration 10: global_step=1065; loss_value=2.225292
2018-09-17 13:29:55,906 - root - INFO - iteration 10: global_step=1066; loss_value=2.204118
2018-09-17 13:29:55,914 - root - INFO - iteration 10: global_step=1067; loss_value=2.219934
2018-09-17 13:29:55,916 - root - INFO - iteration 10: global_step=1068; loss_value=2.249403
2018-09-17 13:29:55,918 - root - INFO - iteration 10: global_step=1069; loss_value=2.257745
2018-09-17 13:29:55,924 - root - INFO - iteration 10: global_step=1070; loss_value=2.280305
2018-09-17 13:29:55,929 - root - INFO - iteration 10: global_step=1071; loss_value=2.245828
2018-09-17 13:29:55,934 - root - INFO - iteration 10: global_step=1072; loss_value=2.218816
2018-09-17 13:29:55,939 - root - INFO - iteration 10: global_step=1073; loss_value=2.168757
2018-09-17 13:29:55,943 - root - INFO - iteration 10: global_step=1074; loss_value=2.182554
2018-09-17 13:29:55,948 - root - INFO - iteration 10: global_step=1075; loss_value=2.162761
2018-09-17 13:29:55,954 - root - INFO - iteration 10: global_step=1076; loss_value=2.250471
2018-09-17 13:29:55,958 - root - INFO - iteration 10: global_step=1077; loss_value=2.225413
2018-09-17 13:29:55,966 - root - INFO - iteration 10: global_step=1078; loss_value=2.262216
2018-09-17 13:29:55,971 - root - INFO - iteration 10: global_step=1079; loss_value=2.205639
2018-09-17 13:29:55,977 - root - INFO - iteration 10: global_step=1080; loss_value=2.313248
2018-09-17 13:29:55,979 - root - INFO - iteration 10: global_step=1081; loss_value=2.355850
2018-09-17 13:29:55,985 - root - INFO - iteration 10: global_step=1082; loss_value=2.209071
2018-09-17 13:29:55,991 - root - INFO - iteration 10: global_step=1083; loss_value=2.271933
2018-09-17 13:29:55,993 - root - INFO - iteration 10: global_step=1084; loss_value=2.333095
2018-09-17 13:29:55,997 - root - INFO - iteration 10: global_step=1085; loss_value=2.261737
2018-09-17 13:29:56,004 - root - INFO - iteration 10: global_step=1086; loss_value=2.220413
2018-09-17 13:29:56,006 - root - INFO - iteration 10: global_step=1087; loss_value=2.233382
2018-09-17 13:29:56,013 - root - INFO - iteration 10: global_step=1088; loss_value=2.279005
2018-09-17 13:29:56,017 - root - INFO - iteration 10: global_step=1089; loss_value=2.158067
2018-09-17 13:29:56,020 - root - INFO - iteration 10: global_step=1090; loss_value=2.246441
2018-09-17 13:29:56,027 - root - INFO - iteration 10: global_step=1091; loss_value=2.276008
2018-09-17 13:29:56,034 - root - INFO - iteration 10: global_step=1092; loss_value=2.225608
2018-09-17 13:29:56,038 - root - INFO - iteration 10: global_step=1093; loss_value=2.246968
2018-09-17 13:29:56,045 - root - INFO - iteration 10: global_step=1094; loss_value=2.162042
2018-09-17 13:29:56,051 - root - INFO - iteration 10: global_step=1095; loss_value=2.211945
2018-09-17 13:29:56,053 - root - INFO - iteration 10: global_step=1096; loss_value=2.200589
2018-09-17 13:29:56,058 - root - INFO - iteration 10: global_step=1097; loss_value=2.189613
2018-09-17 13:29:56,062 - root - INFO - iteration 10: global_step=1098; loss_value=2.255890
2018-09-17 13:29:56,067 - root - INFO - iteration 10: global_step=1099; loss_value=2.262915
2018-09-17 13:29:56,071 - root - INFO - iteration 10: global_step=1100; loss_value=2.220394
2018-09-17 13:29:56,125 - root - INFO - forecast result:
[[ 2.0592585  1.6943831  1.8612278 ... -5.6636863 -5.522945  -5.675995 ]
 [ 3.378028   0.4021448  1.9566075 ... -5.664356  -5.5237107 -5.6766543]
 [ 1.433913   1.6543335  1.7087995 ... -5.663463  -5.522697  -5.675782 ]
 ...
 [ 2.3395915  1.2845981  2.083719  ... -5.663836  -5.523118  -5.676144 ]
 [ 0.6144418  3.0507426  1.9593261 ... -5.663105  -5.522288  -5.6754274]
 [ 1.2595887  2.262788   2.3231106 ... -5.663417  -5.522643  -5.675735 ]]
2018-09-17 13:29:56,555 - root - INFO - forecast result:
[[ 2.0632389   1.7286365   1.9006085  ... -5.8411074  -5.7008557
  -5.8533835 ]
 [ 3.4023552   0.40620303  2.0266044  ... -5.8417115  -5.7015457
  -5.853981  ]
 [ 1.4406937   1.675823    1.7414048  ... -5.8408704  -5.7005897
  -5.8531513 ]
 ...
 [ 2.3610418   1.2924356   2.1334734  ... -5.841231   -5.700996
  -5.8535056 ]
 [ 0.6059221   3.1166322   1.9753473  ... -5.8405843  -5.7002606
  -5.852867  ]
 [ 1.284128    2.2734983   2.349882   ... -5.8408327  -5.700542
  -5.8531127 ]]
2018-09-17 13:29:56,851 - root - INFO - forecast result:
[[ 2.0734062   1.7321823   1.9339563  ... -6.0014987  -5.861682
  -6.0137534 ]
 [ 3.356989    0.40025353  2.0327437  ... -6.00203    -5.862291
  -6.014278  ]
 [ 1.4519963   1.6778529   1.7904228  ... -6.001279   -5.861427
  -6.013538  ]
 ...
 [ 2.3582942   1.2802558   2.1698592  ... -6.0016313  -5.861833
  -6.0138845 ]
 [ 0.6103332   3.1431108   2.032667   ... -6.0010047  -5.861115
  -6.013266  ]
 [ 1.2657919   2.282858    2.4246664  ... -6.0012507  -5.861396
  -6.013509  ]]
2018-09-17 13:29:57,217 - root - INFO - forecast result:
[[ 2.0967855   1.763621    1.9139631  ... -6.1476355  -6.0081434
  -6.159875  ]
 [ 3.3999808   0.47639036  1.9883416  ... -6.148158   -6.008739
  -6.1603913 ]
 [ 1.4761112   1.6857541   1.7613208  ... -6.147429   -6.0079083
  -6.159674  ]
 ...
 [ 2.3407006   1.3689125   2.1456046  ... -6.1477494  -6.008273
  -6.1599884 ]
 [ 0.68089145  3.1029625   2.0421376  ... -6.1471972  -6.007646
  -6.1594424 ]
 [ 1.2941337   2.3149955   2.4112184  ... -6.1473894  -6.0078626
  -6.1596336 ]]
2018-09-17 13:29:57,529 - root - INFO - forecast result:
[[ 2.094177    1.7496376   1.9141418  ... -6.2819386  -6.1427197
  -6.2941556 ]
 [ 3.433853    0.37351942  1.9939526  ... -6.2824144  -6.143267
  -6.294624  ]
 [ 1.4844584   1.6795609   1.7962834  ... -6.2817397  -6.14249
  -6.293958  ]
 ...
 [ 2.367672    1.3199811   2.1142168  ... -6.282045   -6.142842
  -6.2942595 ]
 [ 0.61726683  3.1631455   2.0507538  ... -6.281515   -6.142231
  -6.293737  ]
 [ 1.2907965   2.3281138   2.381848   ... -6.2816973  -6.1424403
  -6.2939157 ]]
2018-09-17 13:29:57,828 - root - INFO - forecast result:
[[ 2.0962946   1.7716844   1.9543908  ... -6.406285   -6.2672844
  -6.4184847 ]
 [ 3.4157023   0.44054127  2.0350509  ... -6.4067216  -6.2677813
  -6.418916  ]
 [ 1.5039525   1.660723    1.8042817  ... -6.4061203  -6.267093
  -6.4183216 ]
 ...
 [ 2.3954816   1.3423749   2.1753163  ... -6.406403   -6.267417
  -6.418601  ]
 [ 0.6504731   3.089954    2.0721962  ... -6.4058924  -6.266837
  -6.418097  ]
 [ 1.3063319   2.3279407   2.4239047  ... -6.406074   -6.2670403
  -6.418275  ]]
2018-09-17 13:29:58,278 - root - INFO - forecast result:
[[ 2.1004517   1.7671199   1.9513144  ... -6.5226912  -6.383891
  -6.5348806 ]
 [ 3.4422033   0.44989967  2.0767741  ... -6.523098   -6.3843555
  -6.5352807 ]
 [ 1.5019357   1.6886011   1.785502   ... -6.522545   -6.383723
  -6.534735  ]
 ...
 [ 2.4152265   1.3359249   2.1642804  ... -6.522801   -6.3840156
  -6.534988  ]
 [ 0.656563    3.1104927   2.05676    ... -6.522338   -6.383487
  -6.5345325 ]
 [ 1.321145    2.3470933   2.4165921  ... -6.5225034  -6.3836746
  -6.5346937 ]]
2018-09-17 13:29:58,601 - root - INFO - forecast result:
[[ 2.0757747   1.7891945   1.9621549  ... -6.6324086  -6.4937687
  -6.644584  ]
 [ 3.378861    0.44046593  2.0775964  ... -6.6327844  -6.494199
  -6.6449537 ]
 [ 1.5099692   1.7327492   1.8381046  ... -6.632266   -6.493604
  -6.6444426 ]
 ...
 [ 2.3755634   1.367854    2.189326   ... -6.632512   -6.493886
  -6.644685  ]
 [ 0.61656696  3.1988523   2.0908132  ... -6.6320844  -6.4933963
  -6.6442633 ]
 [ 1.3114972   2.39216     2.4401689  ... -6.632236   -6.493569
  -6.644412  ]]
2018-09-17 13:29:58,897 - root - INFO - forecast result:
[[ 2.0932195   1.7669836   1.9690201  ... -6.736421   -6.59793
  -6.748589  ]
 [ 3.3993297   0.4169302   2.072573   ... -6.736771   -6.5983305
  -6.748934  ]
 [ 1.5142734   1.7396656   1.8328868  ... -6.736292   -6.5977817
  -6.748461  ]
 ...
 [ 2.400785    1.3493898   2.2044148  ... -6.7365174  -6.59804
  -6.748683  ]
 [ 0.64088196  3.146899    2.1096852  ... -6.736116   -6.5975795
  -6.748287  ]
 [ 1.3409793   2.3683212   2.4962387  ... -6.736261   -6.5977454
  -6.748429  ]]
2018-09-17 13:29:59,201 - root - INFO - forecast result:
[[ 2.1604364  1.758631   1.9551722 ... -6.8351164 -6.6967506 -6.847276 ]
 [ 3.5541663  0.3631785  2.0581682 ... -6.835439  -6.697121  -6.847595 ]
 [ 1.4872458  1.765364   1.8250184 ... -6.8349943 -6.6966105 -6.847155 ]
 ...
 [ 2.4329104  1.3632622  2.1594512 ... -6.835192  -6.696837  -6.8473506]
 [ 0.5969941  3.148454   2.0872993 ... -6.8348317 -6.6964235 -6.8469944]
 [ 1.292697   2.399945   2.4241486 ... -6.8349566 -6.696566  -6.8471174]]
2018-09-17 20:23:36,721 - root - INFO - lr             :	0.02
2018-09-17 20:23:36,733 - root - INFO - dr             :	0.96
2018-09-17 20:23:36,734 - root - INFO - ds             :	100
2018-09-17 20:23:36,737 - root - INFO - edr            :	0.99
2018-09-17 20:23:36,741 - root - INFO - lp             :	0.3
2018-09-17 20:23:36,746 - root - INFO - bs             :	100
2018-09-17 20:23:36,750 - root - INFO - clip           :	5
2018-09-17 20:23:36,754 - root - INFO - epoch          :	20
2018-09-17 20:23:36,756 - root - INFO - layer1_units   :	50
2018-09-17 20:23:36,761 - root - INFO - layer2_units   :	100
2018-09-17 20:23:36,765 - root - INFO - input_dimension:	784
2018-09-17 20:23:36,768 - root - INFO - num_tags       :	10
2018-09-17 20:23:36,771 - root - INFO - opt            :	Adam
2018-09-17 20:23:39,887 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-17 20:23:40,300 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-17 20:23:40,321 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-17 20:23:41,594 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-17 20:23:41,620 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-17 20:23:41,963 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-17 20:23:44,660 - root - INFO - iteration 0: global_step=1; loss_value=28.515163
2018-09-17 20:23:44,671 - root - INFO - iteration 0: global_step=2; loss_value=18.106220
2018-09-17 20:23:44,682 - root - INFO - iteration 0: global_step=3; loss_value=11.601922
2018-09-17 20:23:44,694 - root - INFO - iteration 0: global_step=4; loss_value=7.949030
2018-09-17 20:23:44,705 - root - INFO - iteration 0: global_step=5; loss_value=6.611745
2018-09-17 20:23:44,716 - root - INFO - iteration 0: global_step=6; loss_value=6.342769
2018-09-17 20:23:44,727 - root - INFO - iteration 0: global_step=7; loss_value=6.416999
2018-09-17 20:23:44,739 - root - INFO - iteration 0: global_step=8; loss_value=6.406069
2018-09-17 20:23:44,753 - root - INFO - iteration 0: global_step=9; loss_value=6.218007
2018-09-17 20:23:44,762 - root - INFO - iteration 0: global_step=10; loss_value=5.751322
2018-09-17 20:23:44,772 - root - INFO - iteration 0: global_step=11; loss_value=5.308612
2018-09-17 20:23:44,785 - root - INFO - iteration 0: global_step=12; loss_value=4.902325
2018-09-17 20:23:44,799 - root - INFO - iteration 0: global_step=13; loss_value=4.570695
2018-09-17 20:23:44,819 - root - INFO - iteration 0: global_step=14; loss_value=4.402273
2018-09-17 20:23:44,833 - root - INFO - iteration 0: global_step=15; loss_value=4.341082
2018-09-17 20:23:44,839 - root - INFO - iteration 0: global_step=16; loss_value=4.258356
2018-09-17 20:23:44,853 - root - INFO - iteration 0: global_step=17; loss_value=4.319432
2018-09-17 20:23:44,867 - root - INFO - iteration 0: global_step=18; loss_value=4.230387
2018-09-17 20:23:44,874 - root - INFO - iteration 0: global_step=19; loss_value=4.159455
2018-09-17 20:23:44,890 - root - INFO - iteration 0: global_step=20; loss_value=4.119009
2018-09-17 20:23:44,901 - root - INFO - iteration 0: global_step=21; loss_value=4.003603
2018-09-17 20:23:44,907 - root - INFO - iteration 0: global_step=22; loss_value=3.811420
2018-09-17 20:23:44,921 - root - INFO - iteration 0: global_step=23; loss_value=3.623116
2018-09-17 20:23:44,935 - root - INFO - iteration 0: global_step=24; loss_value=3.449175
2018-09-17 20:23:44,943 - root - INFO - iteration 0: global_step=25; loss_value=3.442847
2018-09-17 20:23:44,957 - root - INFO - iteration 0: global_step=26; loss_value=3.206288
2018-09-17 20:23:44,965 - root - INFO - iteration 0: global_step=27; loss_value=3.215840
2018-09-17 20:23:44,981 - root - INFO - iteration 0: global_step=28; loss_value=3.126008
2018-09-17 20:23:44,985 - root - INFO - iteration 0: global_step=29; loss_value=3.021490
2018-09-17 20:23:45,003 - root - INFO - iteration 0: global_step=30; loss_value=3.195434
2018-09-17 20:23:45,008 - root - INFO - iteration 0: global_step=31; loss_value=2.956078
2018-09-17 20:23:45,026 - root - INFO - iteration 0: global_step=32; loss_value=3.122232
2018-09-17 20:23:45,044 - root - INFO - iteration 0: global_step=33; loss_value=3.042465
2018-09-17 20:23:45,059 - root - INFO - iteration 0: global_step=34; loss_value=3.020081
2018-09-17 20:23:45,073 - root - INFO - iteration 0: global_step=35; loss_value=2.940244
2018-09-17 20:23:45,078 - root - INFO - iteration 0: global_step=36; loss_value=2.805337
2018-09-17 20:23:45,090 - root - INFO - iteration 0: global_step=37; loss_value=2.941026
2018-09-17 20:23:45,104 - root - INFO - iteration 0: global_step=38; loss_value=3.093746
2018-09-17 20:23:45,115 - root - INFO - iteration 0: global_step=39; loss_value=2.869532
2018-09-17 20:23:45,130 - root - INFO - iteration 0: global_step=40; loss_value=2.835361
2018-09-17 20:23:45,138 - root - INFO - iteration 0: global_step=41; loss_value=2.873022
2018-09-17 20:23:45,149 - root - INFO - iteration 0: global_step=42; loss_value=2.766046
2018-09-17 20:23:45,162 - root - INFO - iteration 0: global_step=43; loss_value=2.762494
2018-09-17 20:23:45,171 - root - INFO - iteration 0: global_step=44; loss_value=2.777225
2018-09-17 20:23:45,187 - root - INFO - iteration 0: global_step=45; loss_value=2.756833
2018-09-17 20:23:45,198 - root - INFO - iteration 0: global_step=46; loss_value=2.650579
2018-09-17 20:23:45,204 - root - INFO - iteration 0: global_step=47; loss_value=2.708237
2018-09-17 20:23:45,221 - root - INFO - iteration 0: global_step=48; loss_value=2.767016
2018-09-17 20:23:45,230 - root - INFO - iteration 0: global_step=49; loss_value=2.757290
2018-09-17 20:23:45,243 - root - INFO - iteration 0: global_step=50; loss_value=2.651811
2018-09-17 20:23:45,253 - root - INFO - iteration 0: global_step=51; loss_value=2.724775
2018-09-17 20:23:45,267 - root - INFO - iteration 0: global_step=52; loss_value=2.678154
2018-09-17 20:23:45,285 - root - INFO - iteration 0: global_step=53; loss_value=2.708144
2018-09-17 20:23:45,301 - root - INFO - iteration 0: global_step=54; loss_value=2.638690
2018-09-17 20:23:45,307 - root - INFO - iteration 0: global_step=55; loss_value=2.629653
2018-09-17 20:23:45,319 - root - INFO - iteration 0: global_step=56; loss_value=2.668936
2018-09-17 20:23:45,333 - root - INFO - iteration 0: global_step=57; loss_value=2.593304
2018-09-17 20:23:45,343 - root - INFO - iteration 0: global_step=58; loss_value=2.602024
2018-09-17 20:23:45,355 - root - INFO - iteration 0: global_step=59; loss_value=2.641351
2018-09-17 20:23:45,368 - root - INFO - iteration 0: global_step=60; loss_value=2.681466
2018-09-17 20:23:45,377 - root - INFO - iteration 0: global_step=61; loss_value=2.613734
2018-09-17 20:23:45,393 - root - INFO - iteration 0: global_step=62; loss_value=2.595838
2018-09-17 20:23:45,399 - root - INFO - iteration 0: global_step=63; loss_value=2.689997
2018-09-17 20:23:45,410 - root - INFO - iteration 0: global_step=64; loss_value=2.540352
2018-09-17 20:23:45,422 - root - INFO - iteration 0: global_step=65; loss_value=2.675154
2018-09-17 20:23:45,438 - root - INFO - iteration 0: global_step=66; loss_value=2.614192
2018-09-17 20:23:45,457 - root - INFO - iteration 0: global_step=67; loss_value=2.602331
2018-09-17 20:23:45,461 - root - INFO - iteration 0: global_step=68; loss_value=2.595306
2018-09-17 20:23:45,472 - root - INFO - iteration 0: global_step=69; loss_value=2.525997
2018-09-17 20:23:45,489 - root - INFO - iteration 0: global_step=70; loss_value=2.604171
2018-09-17 20:23:45,502 - root - INFO - iteration 0: global_step=71; loss_value=2.549196
2018-09-17 20:23:45,510 - root - INFO - iteration 0: global_step=72; loss_value=2.508352
2018-09-17 20:23:45,522 - root - INFO - iteration 0: global_step=73; loss_value=2.554798
2018-09-17 20:23:45,532 - root - INFO - iteration 0: global_step=74; loss_value=2.589432
2018-09-17 20:23:45,542 - root - INFO - iteration 0: global_step=75; loss_value=2.557414
2018-09-17 20:23:45,557 - root - INFO - iteration 0: global_step=76; loss_value=2.728412
2018-09-17 20:23:45,567 - root - INFO - iteration 0: global_step=77; loss_value=2.538813
2018-09-17 20:23:45,579 - root - INFO - iteration 0: global_step=78; loss_value=2.608492
2018-09-17 20:23:45,590 - root - INFO - iteration 0: global_step=79; loss_value=2.652236
2018-09-17 20:23:45,599 - root - INFO - iteration 0: global_step=80; loss_value=2.549012
2018-09-17 20:23:45,613 - root - INFO - iteration 0: global_step=81; loss_value=2.476914
2018-09-17 20:23:45,637 - root - INFO - iteration 0: global_step=82; loss_value=2.690708
2018-09-17 20:23:45,649 - root - INFO - iteration 0: global_step=83; loss_value=2.593719
2018-09-17 20:23:45,659 - root - INFO - iteration 0: global_step=84; loss_value=2.516599
2018-09-17 20:23:45,673 - root - INFO - iteration 0: global_step=85; loss_value=2.502189
2018-09-17 20:23:45,684 - root - INFO - iteration 0: global_step=86; loss_value=2.510111
2018-09-17 20:23:45,697 - root - INFO - iteration 0: global_step=87; loss_value=2.555602
2018-09-17 20:23:45,705 - root - INFO - iteration 0: global_step=88; loss_value=2.500470
2018-09-17 20:23:45,712 - root - INFO - iteration 0: global_step=89; loss_value=2.551350
2018-09-17 20:23:45,724 - root - INFO - iteration 0: global_step=90; loss_value=2.469084
2018-09-17 20:23:45,736 - root - INFO - iteration 0: global_step=91; loss_value=2.539643
2018-09-17 20:23:45,747 - root - INFO - iteration 0: global_step=92; loss_value=2.531902
2018-09-17 20:23:45,760 - root - INFO - iteration 0: global_step=93; loss_value=2.539519
2018-09-17 20:23:45,770 - root - INFO - iteration 0: global_step=94; loss_value=2.661839
2018-09-17 20:23:45,782 - root - INFO - iteration 0: global_step=95; loss_value=2.570108
2018-09-17 20:23:45,797 - root - INFO - iteration 0: global_step=96; loss_value=2.557777
2018-09-17 20:23:45,802 - root - INFO - iteration 0: global_step=97; loss_value=2.546002
2018-09-17 20:23:45,821 - root - INFO - iteration 0: global_step=98; loss_value=2.625449
2018-09-17 20:23:45,833 - root - INFO - iteration 0: global_step=99; loss_value=2.581417
2018-09-17 20:23:45,837 - root - INFO - iteration 0: global_step=100; loss_value=2.516217
2018-09-17 20:23:45,936 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:46,890 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:47,866 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:48,861 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:49,881 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:51,101 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:51,907 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:52,576 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:53,279 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:53,974 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:54,106 - root - INFO - iteration 10: global_step=1001; loss_value=2.124914
2018-09-17 20:23:54,119 - root - INFO - iteration 10: global_step=1002; loss_value=2.163054
2018-09-17 20:23:54,131 - root - INFO - iteration 10: global_step=1003; loss_value=2.280762
2018-09-17 20:23:54,143 - root - INFO - iteration 10: global_step=1004; loss_value=2.285523
2018-09-17 20:23:54,156 - root - INFO - iteration 10: global_step=1005; loss_value=2.202301
2018-09-17 20:23:54,171 - root - INFO - iteration 10: global_step=1006; loss_value=2.185234
2018-09-17 20:23:54,184 - root - INFO - iteration 10: global_step=1007; loss_value=2.233366
2018-09-17 20:23:54,197 - root - INFO - iteration 10: global_step=1008; loss_value=2.225734
2018-09-17 20:23:54,211 - root - INFO - iteration 10: global_step=1009; loss_value=2.167244
2018-09-17 20:23:54,224 - root - INFO - iteration 10: global_step=1010; loss_value=2.246070
2018-09-17 20:23:54,237 - root - INFO - iteration 10: global_step=1011; loss_value=2.191438
2018-09-17 20:23:54,248 - root - INFO - iteration 10: global_step=1012; loss_value=2.201798
2018-09-17 20:23:54,259 - root - INFO - iteration 10: global_step=1013; loss_value=2.265792
2018-09-17 20:23:54,273 - root - INFO - iteration 10: global_step=1014; loss_value=2.298202
2018-09-17 20:23:54,285 - root - INFO - iteration 10: global_step=1015; loss_value=2.240199
2018-09-17 20:23:54,299 - root - INFO - iteration 10: global_step=1016; loss_value=2.232860
2018-09-17 20:23:54,317 - root - INFO - iteration 10: global_step=1017; loss_value=2.250499
2018-09-17 20:23:54,334 - root - INFO - iteration 10: global_step=1018; loss_value=2.164068
2018-09-17 20:23:54,349 - root - INFO - iteration 10: global_step=1019; loss_value=2.273606
2018-09-17 20:23:54,361 - root - INFO - iteration 10: global_step=1020; loss_value=2.151940
2018-09-17 20:23:54,370 - root - INFO - iteration 10: global_step=1021; loss_value=2.182726
2018-09-17 20:23:54,386 - root - INFO - iteration 10: global_step=1022; loss_value=2.229451
2018-09-17 20:23:54,398 - root - INFO - iteration 10: global_step=1023; loss_value=2.251460
2018-09-17 20:23:54,406 - root - INFO - iteration 10: global_step=1024; loss_value=2.230549
2018-09-17 20:23:54,421 - root - INFO - iteration 10: global_step=1025; loss_value=2.224780
2018-09-17 20:23:54,435 - root - INFO - iteration 10: global_step=1026; loss_value=2.244745
2018-09-17 20:23:54,452 - root - INFO - iteration 10: global_step=1027; loss_value=2.139473
2018-09-17 20:23:54,466 - root - INFO - iteration 10: global_step=1028; loss_value=2.194387
2018-09-17 20:23:54,476 - root - INFO - iteration 10: global_step=1029; loss_value=2.282131
2018-09-17 20:23:54,490 - root - INFO - iteration 10: global_step=1030; loss_value=2.147545
2018-09-17 20:23:54,498 - root - INFO - iteration 10: global_step=1031; loss_value=2.186793
2018-09-17 20:23:54,514 - root - INFO - iteration 10: global_step=1032; loss_value=2.226855
2018-09-17 20:23:54,530 - root - INFO - iteration 10: global_step=1033; loss_value=2.249663
2018-09-17 20:23:54,538 - root - INFO - iteration 10: global_step=1034; loss_value=2.178564
2018-09-17 20:23:54,546 - root - INFO - iteration 10: global_step=1035; loss_value=2.344077
2018-09-17 20:23:54,558 - root - INFO - iteration 10: global_step=1036; loss_value=2.199025
2018-09-17 20:23:54,571 - root - INFO - iteration 10: global_step=1037; loss_value=2.263478
2018-09-17 20:23:54,586 - root - INFO - iteration 10: global_step=1038; loss_value=2.245278
2018-09-17 20:23:54,601 - root - INFO - iteration 10: global_step=1039; loss_value=2.215539
2018-09-17 20:23:54,610 - root - INFO - iteration 10: global_step=1040; loss_value=2.183591
2018-09-17 20:23:54,626 - root - INFO - iteration 10: global_step=1041; loss_value=2.221134
2018-09-17 20:23:54,636 - root - INFO - iteration 10: global_step=1042; loss_value=2.262339
2018-09-17 20:23:54,647 - root - INFO - iteration 10: global_step=1043; loss_value=2.244056
2018-09-17 20:23:54,659 - root - INFO - iteration 10: global_step=1044; loss_value=2.271696
2018-09-17 20:23:54,672 - root - INFO - iteration 10: global_step=1045; loss_value=2.207088
2018-09-17 20:23:54,683 - root - INFO - iteration 10: global_step=1046; loss_value=2.266606
2018-09-17 20:23:54,698 - root - INFO - iteration 10: global_step=1047; loss_value=2.220156
2018-09-17 20:23:54,710 - root - INFO - iteration 10: global_step=1048; loss_value=2.293382
2018-09-17 20:23:54,733 - root - INFO - iteration 10: global_step=1049; loss_value=2.230863
2018-09-17 20:23:54,737 - root - INFO - iteration 10: global_step=1050; loss_value=2.219533
2018-09-17 20:23:54,758 - root - INFO - iteration 10: global_step=1051; loss_value=2.272256
2018-09-17 20:23:54,768 - root - INFO - iteration 10: global_step=1052; loss_value=2.272334
2018-09-17 20:23:54,782 - root - INFO - iteration 10: global_step=1053; loss_value=2.276186
2018-09-17 20:23:54,792 - root - INFO - iteration 10: global_step=1054; loss_value=2.249944
2018-09-17 20:23:54,805 - root - INFO - iteration 10: global_step=1055; loss_value=2.178582
2018-09-17 20:23:54,811 - root - INFO - iteration 10: global_step=1056; loss_value=2.197673
2018-09-17 20:23:54,829 - root - INFO - iteration 10: global_step=1057; loss_value=2.179812
2018-09-17 20:23:54,837 - root - INFO - iteration 10: global_step=1058; loss_value=2.228691
2018-09-17 20:23:54,853 - root - INFO - iteration 10: global_step=1059; loss_value=2.313320
2018-09-17 20:23:54,862 - root - INFO - iteration 10: global_step=1060; loss_value=2.172042
2018-09-17 20:23:54,875 - root - INFO - iteration 10: global_step=1061; loss_value=2.260193
2018-09-17 20:23:54,883 - root - INFO - iteration 10: global_step=1062; loss_value=2.186349
2018-09-17 20:23:54,902 - root - INFO - iteration 10: global_step=1063; loss_value=2.146409
2018-09-17 20:23:54,915 - root - INFO - iteration 10: global_step=1064; loss_value=2.091491
2018-09-17 20:23:54,930 - root - INFO - iteration 10: global_step=1065; loss_value=2.221873
2018-09-17 20:23:54,939 - root - INFO - iteration 10: global_step=1066; loss_value=2.290645
2018-09-17 20:23:54,954 - root - INFO - iteration 10: global_step=1067; loss_value=2.254303
2018-09-17 20:23:54,967 - root - INFO - iteration 10: global_step=1068; loss_value=2.206106
2018-09-17 20:23:54,976 - root - INFO - iteration 10: global_step=1069; loss_value=2.204064
2018-09-17 20:23:54,988 - root - INFO - iteration 10: global_step=1070; loss_value=2.269121
2018-09-17 20:23:55,001 - root - INFO - iteration 10: global_step=1071; loss_value=2.311649
2018-09-17 20:23:55,015 - root - INFO - iteration 10: global_step=1072; loss_value=2.335359
2018-09-17 20:23:55,024 - root - INFO - iteration 10: global_step=1073; loss_value=2.290488
2018-09-17 20:23:55,039 - root - INFO - iteration 10: global_step=1074; loss_value=2.244731
2018-09-17 20:23:55,061 - root - INFO - iteration 10: global_step=1075; loss_value=2.269771
2018-09-17 20:23:55,073 - root - INFO - iteration 10: global_step=1076; loss_value=2.320494
2018-09-17 20:23:55,087 - root - INFO - iteration 10: global_step=1077; loss_value=2.359712
2018-09-17 20:23:55,099 - root - INFO - iteration 10: global_step=1078; loss_value=2.263859
2018-09-17 20:23:55,108 - root - INFO - iteration 10: global_step=1079; loss_value=2.179249
2018-09-17 20:23:55,121 - root - INFO - iteration 10: global_step=1080; loss_value=2.368551
2018-09-17 20:23:55,133 - root - INFO - iteration 10: global_step=1081; loss_value=2.266890
2018-09-17 20:23:55,145 - root - INFO - iteration 10: global_step=1082; loss_value=2.221287
2018-09-17 20:23:55,152 - root - INFO - iteration 10: global_step=1083; loss_value=2.275863
2018-09-17 20:23:55,164 - root - INFO - iteration 10: global_step=1084; loss_value=2.252516
2018-09-17 20:23:55,178 - root - INFO - iteration 10: global_step=1085; loss_value=2.225862
2018-09-17 20:23:55,190 - root - INFO - iteration 10: global_step=1086; loss_value=2.213250
2018-09-17 20:23:55,207 - root - INFO - iteration 10: global_step=1087; loss_value=2.290630
2018-09-17 20:23:55,226 - root - INFO - iteration 10: global_step=1088; loss_value=2.235099
2018-09-17 20:23:55,234 - root - INFO - iteration 10: global_step=1089; loss_value=2.182848
2018-09-17 20:23:55,250 - root - INFO - iteration 10: global_step=1090; loss_value=2.215254
2018-09-17 20:23:55,255 - root - INFO - iteration 10: global_step=1091; loss_value=2.199914
2018-09-17 20:23:55,267 - root - INFO - iteration 10: global_step=1092; loss_value=2.223610
2018-09-17 20:23:55,283 - root - INFO - iteration 10: global_step=1093; loss_value=2.295025
2018-09-17 20:23:55,295 - root - INFO - iteration 10: global_step=1094; loss_value=2.251786
2018-09-17 20:23:55,306 - root - INFO - iteration 10: global_step=1095; loss_value=2.136316
2018-09-17 20:23:55,315 - root - INFO - iteration 10: global_step=1096; loss_value=2.309487
2018-09-17 20:23:55,333 - root - INFO - iteration 10: global_step=1097; loss_value=2.156527
2018-09-17 20:23:55,340 - root - INFO - iteration 10: global_step=1098; loss_value=2.308806
2018-09-17 20:23:55,351 - root - INFO - iteration 10: global_step=1099; loss_value=2.156986
2018-09-17 20:23:55,365 - root - INFO - iteration 10: global_step=1100; loss_value=2.348342
2018-09-17 20:23:55,438 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:56,408 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:57,455 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:58,465 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:23:59,458 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:24:00,429 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:24:01,323 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:24:01,995 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:24:02,686 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:24:03,529 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:08,115 - root - INFO - lr             :	0.02
2018-09-17 20:41:08,116 - root - INFO - dr             :	0.96
2018-09-17 20:41:08,121 - root - INFO - ds             :	100
2018-09-17 20:41:08,121 - root - INFO - edr            :	0.99
2018-09-17 20:41:08,121 - root - INFO - lp             :	0.3
2018-09-17 20:41:08,122 - root - INFO - bs             :	100
2018-09-17 20:41:08,122 - root - INFO - clip           :	5
2018-09-17 20:41:08,122 - root - INFO - epoch          :	20
2018-09-17 20:41:08,122 - root - INFO - layer1_units   :	50
2018-09-17 20:41:08,122 - root - INFO - layer2_units   :	100
2018-09-17 20:41:08,122 - root - INFO - input_dimension:	784
2018-09-17 20:41:08,122 - root - INFO - num_tags       :	10
2018-09-17 20:41:08,122 - root - INFO - opt            :	Adam
2018-09-17 20:41:08,511 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-17 20:41:08,629 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-17 20:41:08,637 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-17 20:41:09,010 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-17 20:41:09,017 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-17 20:41:09,132 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-17 20:41:10,518 - root - INFO - iteration 0: global_step=1; loss_value=28.728100
2018-09-17 20:41:10,524 - root - INFO - iteration 0: global_step=2; loss_value=18.412786
2018-09-17 20:41:10,530 - root - INFO - iteration 0: global_step=3; loss_value=11.888845
2018-09-17 20:41:10,534 - root - INFO - iteration 0: global_step=4; loss_value=8.271714
2018-09-17 20:41:10,538 - root - INFO - iteration 0: global_step=5; loss_value=6.772276
2018-09-17 20:41:10,543 - root - INFO - iteration 0: global_step=6; loss_value=6.533238
2018-09-17 20:41:10,548 - root - INFO - iteration 0: global_step=7; loss_value=6.530185
2018-09-17 20:41:10,554 - root - INFO - iteration 0: global_step=8; loss_value=6.550987
2018-09-17 20:41:10,556 - root - INFO - iteration 0: global_step=9; loss_value=6.321105
2018-09-17 20:41:10,560 - root - INFO - iteration 0: global_step=10; loss_value=5.799031
2018-09-17 20:41:10,565 - root - INFO - iteration 0: global_step=11; loss_value=5.449347
2018-09-17 20:41:10,569 - root - INFO - iteration 0: global_step=12; loss_value=5.033542
2018-09-17 20:41:10,576 - root - INFO - iteration 0: global_step=13; loss_value=4.734105
2018-09-17 20:41:10,580 - root - INFO - iteration 0: global_step=14; loss_value=4.423424
2018-09-17 20:41:10,586 - root - INFO - iteration 0: global_step=15; loss_value=4.387107
2018-09-17 20:41:10,592 - root - INFO - iteration 0: global_step=16; loss_value=4.307704
2018-09-17 20:41:10,599 - root - INFO - iteration 0: global_step=17; loss_value=4.263021
2018-09-17 20:41:10,607 - root - INFO - iteration 0: global_step=18; loss_value=4.281930
2018-09-17 20:41:10,609 - root - INFO - iteration 0: global_step=19; loss_value=4.292618
2018-09-17 20:41:10,618 - root - INFO - iteration 0: global_step=20; loss_value=4.166985
2018-09-17 20:41:10,620 - root - INFO - iteration 0: global_step=21; loss_value=4.003014
2018-09-17 20:41:10,622 - root - INFO - iteration 0: global_step=22; loss_value=3.833889
2018-09-17 20:41:10,628 - root - INFO - iteration 0: global_step=23; loss_value=3.765893
2018-09-17 20:41:10,634 - root - INFO - iteration 0: global_step=24; loss_value=3.479027
2018-09-17 20:41:10,636 - root - INFO - iteration 0: global_step=25; loss_value=3.386596
2018-09-17 20:41:10,642 - root - INFO - iteration 0: global_step=26; loss_value=3.243195
2018-09-17 20:41:10,646 - root - INFO - iteration 0: global_step=27; loss_value=3.190103
2018-09-17 20:41:10,651 - root - INFO - iteration 0: global_step=28; loss_value=3.112537
2018-09-17 20:41:10,653 - root - INFO - iteration 0: global_step=29; loss_value=3.200222
2018-09-17 20:41:10,662 - root - INFO - iteration 0: global_step=30; loss_value=3.154093
2018-09-17 20:41:10,668 - root - INFO - iteration 0: global_step=31; loss_value=3.078567
2018-09-17 20:41:10,677 - root - INFO - iteration 0: global_step=32; loss_value=3.043298
2018-09-17 20:41:10,683 - root - INFO - iteration 0: global_step=33; loss_value=3.028176
2018-09-17 20:41:10,688 - root - INFO - iteration 0: global_step=34; loss_value=2.968622
2018-09-17 20:41:10,694 - root - INFO - iteration 0: global_step=35; loss_value=2.976454
2018-09-17 20:41:10,697 - root - INFO - iteration 0: global_step=36; loss_value=3.018493
2018-09-17 20:41:10,703 - root - INFO - iteration 0: global_step=37; loss_value=2.905484
2018-09-17 20:41:10,705 - root - INFO - iteration 0: global_step=38; loss_value=2.908081
2018-09-17 20:41:10,709 - root - INFO - iteration 0: global_step=39; loss_value=2.874695
2018-09-17 20:41:10,717 - root - INFO - iteration 0: global_step=40; loss_value=2.870898
2018-09-17 20:41:10,719 - root - INFO - iteration 0: global_step=41; loss_value=2.819711
2018-09-17 20:41:10,726 - root - INFO - iteration 0: global_step=42; loss_value=2.798557
2018-09-17 20:41:10,728 - root - INFO - iteration 0: global_step=43; loss_value=2.829364
2018-09-17 20:41:10,733 - root - INFO - iteration 0: global_step=44; loss_value=2.733293
2018-09-17 20:41:10,737 - root - INFO - iteration 0: global_step=45; loss_value=2.754583
2018-09-17 20:41:10,744 - root - INFO - iteration 0: global_step=46; loss_value=2.692881
2018-09-17 20:41:10,748 - root - INFO - iteration 0: global_step=47; loss_value=2.755164
2018-09-17 20:41:10,751 - root - INFO - iteration 0: global_step=48; loss_value=2.819547
2018-09-17 20:41:10,759 - root - INFO - iteration 0: global_step=49; loss_value=2.706965
2018-09-17 20:41:10,765 - root - INFO - iteration 0: global_step=50; loss_value=2.739022
2018-09-17 20:41:10,775 - root - INFO - iteration 0: global_step=51; loss_value=2.747850
2018-09-17 20:41:10,777 - root - INFO - iteration 0: global_step=52; loss_value=2.635696
2018-09-17 20:41:10,787 - root - INFO - iteration 0: global_step=53; loss_value=2.658317
2018-09-17 20:41:10,789 - root - INFO - iteration 0: global_step=54; loss_value=2.761958
2018-09-17 20:41:10,793 - root - INFO - iteration 0: global_step=55; loss_value=2.616638
2018-09-17 20:41:10,803 - root - INFO - iteration 0: global_step=56; loss_value=2.717371
2018-09-17 20:41:10,805 - root - INFO - iteration 0: global_step=57; loss_value=2.669606
2018-09-17 20:41:10,807 - root - INFO - iteration 0: global_step=58; loss_value=2.667544
2018-09-17 20:41:10,813 - root - INFO - iteration 0: global_step=59; loss_value=2.710465
2018-09-17 20:41:10,817 - root - INFO - iteration 0: global_step=60; loss_value=2.732985
2018-09-17 20:41:10,821 - root - INFO - iteration 0: global_step=61; loss_value=2.705197
2018-09-17 20:41:10,827 - root - INFO - iteration 0: global_step=62; loss_value=2.630498
2018-09-17 20:41:10,830 - root - INFO - iteration 0: global_step=63; loss_value=2.635407
2018-09-17 20:41:10,835 - root - INFO - iteration 0: global_step=64; loss_value=2.661156
2018-09-17 20:41:10,839 - root - INFO - iteration 0: global_step=65; loss_value=2.597317
2018-09-17 20:41:10,843 - root - INFO - iteration 0: global_step=66; loss_value=2.596494
2018-09-17 20:41:10,848 - root - INFO - iteration 0: global_step=67; loss_value=2.685446
2018-09-17 20:41:10,853 - root - INFO - iteration 0: global_step=68; loss_value=2.629671
2018-09-17 20:41:10,856 - root - INFO - iteration 0: global_step=69; loss_value=2.536537
2018-09-17 20:41:10,861 - root - INFO - iteration 0: global_step=70; loss_value=2.650719
2018-09-17 20:41:10,866 - root - INFO - iteration 0: global_step=71; loss_value=2.547868
2018-09-17 20:41:10,870 - root - INFO - iteration 0: global_step=72; loss_value=2.564064
2018-09-17 20:41:10,876 - root - INFO - iteration 0: global_step=73; loss_value=2.569482
2018-09-17 20:41:10,882 - root - INFO - iteration 0: global_step=74; loss_value=2.478386
2018-09-17 20:41:10,888 - root - INFO - iteration 0: global_step=75; loss_value=2.600766
2018-09-17 20:41:10,898 - root - INFO - iteration 0: global_step=76; loss_value=2.673118
2018-09-17 20:41:10,903 - root - INFO - iteration 0: global_step=77; loss_value=2.604173
2018-09-17 20:41:10,906 - root - INFO - iteration 0: global_step=78; loss_value=2.531628
2018-09-17 20:41:10,910 - root - INFO - iteration 0: global_step=79; loss_value=2.580145
2018-09-17 20:41:10,918 - root - INFO - iteration 0: global_step=80; loss_value=2.544964
2018-09-17 20:41:10,921 - root - INFO - iteration 0: global_step=81; loss_value=2.593712
2018-09-17 20:41:10,923 - root - INFO - iteration 0: global_step=82; loss_value=2.536372
2018-09-17 20:41:10,928 - root - INFO - iteration 0: global_step=83; loss_value=2.664667
2018-09-17 20:41:10,935 - root - INFO - iteration 0: global_step=84; loss_value=2.624737
2018-09-17 20:41:10,937 - root - INFO - iteration 0: global_step=85; loss_value=2.467064
2018-09-17 20:41:10,940 - root - INFO - iteration 0: global_step=86; loss_value=2.598163
2018-09-17 20:41:10,946 - root - INFO - iteration 0: global_step=87; loss_value=2.556540
2018-09-17 20:41:10,950 - root - INFO - iteration 0: global_step=88; loss_value=2.490283
2018-09-17 20:41:10,955 - root - INFO - iteration 0: global_step=89; loss_value=2.611259
2018-09-17 20:41:10,960 - root - INFO - iteration 0: global_step=90; loss_value=2.441783
2018-09-17 20:41:10,965 - root - INFO - iteration 0: global_step=91; loss_value=2.457769
2018-09-17 20:41:10,969 - root - INFO - iteration 0: global_step=92; loss_value=2.584029
2018-09-17 20:41:10,974 - root - INFO - iteration 0: global_step=93; loss_value=2.575577
2018-09-17 20:41:10,979 - root - INFO - iteration 0: global_step=94; loss_value=2.471378
2018-09-17 20:41:10,983 - root - INFO - iteration 0: global_step=95; loss_value=2.503119
2018-09-17 20:41:10,989 - root - INFO - iteration 0: global_step=96; loss_value=2.395902
2018-09-17 20:41:10,993 - root - INFO - iteration 0: global_step=97; loss_value=2.550609
2018-09-17 20:41:11,002 - root - INFO - iteration 0: global_step=98; loss_value=2.520738
2018-09-17 20:41:11,008 - root - INFO - iteration 0: global_step=99; loss_value=2.498689
2018-09-17 20:41:11,010 - root - INFO - iteration 0: global_step=100; loss_value=2.508271
2018-09-17 20:41:11,093 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:11,399 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:11,661 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:11,921 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:12,188 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:12,669 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:12,962 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:13,229 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:13,496 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:13,764 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:13,824 - root - INFO - iteration 10: global_step=1001; loss_value=2.263546
2018-09-17 20:41:13,832 - root - INFO - iteration 10: global_step=1002; loss_value=2.327629
2018-09-17 20:41:13,839 - root - INFO - iteration 10: global_step=1003; loss_value=2.233217
2018-09-17 20:41:13,841 - root - INFO - iteration 10: global_step=1004; loss_value=2.235784
2018-09-17 20:41:13,844 - root - INFO - iteration 10: global_step=1005; loss_value=2.217627
2018-09-17 20:41:13,850 - root - INFO - iteration 10: global_step=1006; loss_value=2.198317
2018-09-17 20:41:13,855 - root - INFO - iteration 10: global_step=1007; loss_value=2.238537
2018-09-17 20:41:13,858 - root - INFO - iteration 10: global_step=1008; loss_value=2.268208
2018-09-17 20:41:13,864 - root - INFO - iteration 10: global_step=1009; loss_value=2.225025
2018-09-17 20:41:13,872 - root - INFO - iteration 10: global_step=1010; loss_value=2.219810
2018-09-17 20:41:13,876 - root - INFO - iteration 10: global_step=1011; loss_value=2.143436
2018-09-17 20:41:13,886 - root - INFO - iteration 10: global_step=1012; loss_value=2.256298
2018-09-17 20:41:13,891 - root - INFO - iteration 10: global_step=1013; loss_value=2.106968
2018-09-17 20:41:13,898 - root - INFO - iteration 10: global_step=1014; loss_value=2.185132
2018-09-17 20:41:13,904 - root - INFO - iteration 10: global_step=1015; loss_value=2.329852
2018-09-17 20:41:13,911 - root - INFO - iteration 10: global_step=1016; loss_value=2.284444
2018-09-17 20:41:13,913 - root - INFO - iteration 10: global_step=1017; loss_value=2.239317
2018-09-17 20:41:13,917 - root - INFO - iteration 10: global_step=1018; loss_value=2.242592
2018-09-17 20:41:13,921 - root - INFO - iteration 10: global_step=1019; loss_value=2.177528
2018-09-17 20:41:13,929 - root - INFO - iteration 10: global_step=1020; loss_value=2.106331
2018-09-17 20:41:13,932 - root - INFO - iteration 10: global_step=1021; loss_value=2.263533
2018-09-17 20:41:13,936 - root - INFO - iteration 10: global_step=1022; loss_value=2.303167
2018-09-17 20:41:13,941 - root - INFO - iteration 10: global_step=1023; loss_value=2.143301
2018-09-17 20:41:13,948 - root - INFO - iteration 10: global_step=1024; loss_value=2.276837
2018-09-17 20:41:13,953 - root - INFO - iteration 10: global_step=1025; loss_value=2.256366
2018-09-17 20:41:13,961 - root - INFO - iteration 10: global_step=1026; loss_value=2.167580
2018-09-17 20:41:13,968 - root - INFO - iteration 10: global_step=1027; loss_value=2.249937
2018-09-17 20:41:13,972 - root - INFO - iteration 10: global_step=1028; loss_value=2.189204
2018-09-17 20:41:13,979 - root - INFO - iteration 10: global_step=1029; loss_value=2.300179
2018-09-17 20:41:13,981 - root - INFO - iteration 10: global_step=1030; loss_value=2.193128
2018-09-17 20:41:13,987 - root - INFO - iteration 10: global_step=1031; loss_value=2.221170
2018-09-17 20:41:13,990 - root - INFO - iteration 10: global_step=1032; loss_value=2.189259
2018-09-17 20:41:13,998 - root - INFO - iteration 10: global_step=1033; loss_value=2.178044
2018-09-17 20:41:14,000 - root - INFO - iteration 10: global_step=1034; loss_value=2.186316
2018-09-17 20:41:14,002 - root - INFO - iteration 10: global_step=1035; loss_value=2.227201
2018-09-17 20:41:14,008 - root - INFO - iteration 10: global_step=1036; loss_value=2.195032
2018-09-17 20:41:14,014 - root - INFO - iteration 10: global_step=1037; loss_value=2.253295
2018-09-17 20:41:14,016 - root - INFO - iteration 10: global_step=1038; loss_value=2.252347
2018-09-17 20:41:14,021 - root - INFO - iteration 10: global_step=1039; loss_value=2.159308
2018-09-17 20:41:14,025 - root - INFO - iteration 10: global_step=1040; loss_value=2.292136
2018-09-17 20:41:14,032 - root - INFO - iteration 10: global_step=1041; loss_value=2.304345
2018-09-17 20:41:14,036 - root - INFO - iteration 10: global_step=1042; loss_value=2.169583
2018-09-17 20:41:14,044 - root - INFO - iteration 10: global_step=1043; loss_value=2.256788
2018-09-17 20:41:14,048 - root - INFO - iteration 10: global_step=1044; loss_value=2.151815
2018-09-17 20:41:14,057 - root - INFO - iteration 10: global_step=1045; loss_value=2.241476
2018-09-17 20:41:14,062 - root - INFO - iteration 10: global_step=1046; loss_value=2.186923
2018-09-17 20:41:14,070 - root - INFO - iteration 10: global_step=1047; loss_value=2.167851
2018-09-17 20:41:14,072 - root - INFO - iteration 10: global_step=1048; loss_value=2.258282
2018-09-17 20:41:14,078 - root - INFO - iteration 10: global_step=1049; loss_value=2.215045
2018-09-17 20:41:14,082 - root - INFO - iteration 10: global_step=1050; loss_value=2.154914
2018-09-17 20:41:14,089 - root - INFO - iteration 10: global_step=1051; loss_value=2.245146
2018-09-17 20:41:14,091 - root - INFO - iteration 10: global_step=1052; loss_value=2.219048
2018-09-17 20:41:14,097 - root - INFO - iteration 10: global_step=1053; loss_value=2.197875
2018-09-17 20:41:14,099 - root - INFO - iteration 10: global_step=1054; loss_value=2.193297
2018-09-17 20:41:14,104 - root - INFO - iteration 10: global_step=1055; loss_value=2.190393
2018-09-17 20:41:14,109 - root - INFO - iteration 10: global_step=1056; loss_value=2.171371
2018-09-17 20:41:14,113 - root - INFO - iteration 10: global_step=1057; loss_value=2.268455
2018-09-17 20:41:14,119 - root - INFO - iteration 10: global_step=1058; loss_value=2.219537
2018-09-17 20:41:14,125 - root - INFO - iteration 10: global_step=1059; loss_value=2.247457
2018-09-17 20:41:14,134 - root - INFO - iteration 10: global_step=1060; loss_value=2.186504
2018-09-17 20:41:14,138 - root - INFO - iteration 10: global_step=1061; loss_value=2.230329
2018-09-17 20:41:14,142 - root - INFO - iteration 10: global_step=1062; loss_value=2.196008
2018-09-17 20:41:14,148 - root - INFO - iteration 10: global_step=1063; loss_value=2.222281
2018-09-17 20:41:14,155 - root - INFO - iteration 10: global_step=1064; loss_value=2.249068
2018-09-17 20:41:14,157 - root - INFO - iteration 10: global_step=1065; loss_value=2.239362
2018-09-17 20:41:14,161 - root - INFO - iteration 10: global_step=1066; loss_value=2.263859
2018-09-17 20:41:14,165 - root - INFO - iteration 10: global_step=1067; loss_value=2.186677
2018-09-17 20:41:14,171 - root - INFO - iteration 10: global_step=1068; loss_value=2.200269
2018-09-17 20:41:14,179 - root - INFO - iteration 10: global_step=1069; loss_value=2.181809
2018-09-17 20:41:14,181 - root - INFO - iteration 10: global_step=1070; loss_value=2.216383
2018-09-17 20:41:14,183 - root - INFO - iteration 10: global_step=1071; loss_value=2.259779
2018-09-17 20:41:14,188 - root - INFO - iteration 10: global_step=1072; loss_value=2.275891
2018-09-17 20:41:14,193 - root - INFO - iteration 10: global_step=1073; loss_value=2.234470
2018-09-17 20:41:14,198 - root - INFO - iteration 10: global_step=1074; loss_value=2.209136
2018-09-17 20:41:14,203 - root - INFO - iteration 10: global_step=1075; loss_value=2.203693
2018-09-17 20:41:14,207 - root - INFO - iteration 10: global_step=1076; loss_value=2.262761
2018-09-17 20:41:14,212 - root - INFO - iteration 10: global_step=1077; loss_value=2.169032
2018-09-17 20:41:14,223 - root - INFO - iteration 10: global_step=1078; loss_value=2.163633
2018-09-17 20:41:14,225 - root - INFO - iteration 10: global_step=1079; loss_value=2.218508
2018-09-17 20:41:14,231 - root - INFO - iteration 10: global_step=1080; loss_value=2.239988
2018-09-17 20:41:14,235 - root - INFO - iteration 10: global_step=1081; loss_value=2.245743
2018-09-17 20:41:14,241 - root - INFO - iteration 10: global_step=1082; loss_value=2.217082
2018-09-17 20:41:14,243 - root - INFO - iteration 10: global_step=1083; loss_value=2.269979
2018-09-17 20:41:14,249 - root - INFO - iteration 10: global_step=1084; loss_value=2.291404
2018-09-17 20:41:14,256 - root - INFO - iteration 10: global_step=1085; loss_value=2.184234
2018-09-17 20:41:14,258 - root - INFO - iteration 10: global_step=1086; loss_value=2.214010
2018-09-17 20:41:14,264 - root - INFO - iteration 10: global_step=1087; loss_value=2.231771
2018-09-17 20:41:14,266 - root - INFO - iteration 10: global_step=1088; loss_value=2.157637
2018-09-17 20:41:14,272 - root - INFO - iteration 10: global_step=1089; loss_value=2.253718
2018-09-17 20:41:14,274 - root - INFO - iteration 10: global_step=1090; loss_value=2.231284
2018-09-17 20:41:14,279 - root - INFO - iteration 10: global_step=1091; loss_value=2.204097
2018-09-17 20:41:14,285 - root - INFO - iteration 10: global_step=1092; loss_value=2.264141
2018-09-17 20:41:14,289 - root - INFO - iteration 10: global_step=1093; loss_value=2.216513
2018-09-17 20:41:14,294 - root - INFO - iteration 10: global_step=1094; loss_value=2.238388
2018-09-17 20:41:14,303 - root - INFO - iteration 10: global_step=1095; loss_value=2.264061
2018-09-17 20:41:14,309 - root - INFO - iteration 10: global_step=1096; loss_value=2.215882
2018-09-17 20:41:14,318 - root - INFO - iteration 10: global_step=1097; loss_value=2.295546
2018-09-17 20:41:14,321 - root - INFO - iteration 10: global_step=1098; loss_value=2.321429
2018-09-17 20:41:14,323 - root - INFO - iteration 10: global_step=1099; loss_value=2.223164
2018-09-17 20:41:14,328 - root - INFO - iteration 10: global_step=1100; loss_value=2.242693
2018-09-17 20:41:14,388 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:14,847 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:15,111 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:15,376 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:15,700 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:15,961 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:16,381 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:16,645 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:16,909 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 20:41:17,171 - root - INFO - forecast result shape:
(5000, 100)
2018-09-17 21:19:53,563 - root - INFO - lr             :	0.02
2018-09-17 21:19:53,564 - root - INFO - dr             :	0.96
2018-09-17 21:19:53,564 - root - INFO - ds             :	100
2018-09-17 21:19:53,564 - root - INFO - edr            :	0.99
2018-09-17 21:19:53,564 - root - INFO - lp             :	0.3
2018-09-17 21:19:53,564 - root - INFO - bs             :	100
2018-09-17 21:19:53,564 - root - INFO - clip           :	5
2018-09-17 21:19:53,564 - root - INFO - epoch          :	20
2018-09-17 21:19:53,564 - root - INFO - layer1_units   :	50
2018-09-17 21:19:53,564 - root - INFO - layer2_units   :	100
2018-09-17 21:19:53,564 - root - INFO - input_dimension:	784
2018-09-17 21:19:53,564 - root - INFO - num_tags       :	10
2018-09-17 21:19:53,565 - root - INFO - opt            :	Adam
2018-09-17 21:24:12,566 - root - INFO - lr             :	0.02
2018-09-17 21:24:12,568 - root - INFO - dr             :	0.96
2018-09-17 21:24:12,572 - root - INFO - ds             :	100
2018-09-17 21:24:12,572 - root - INFO - edr            :	0.99
2018-09-17 21:24:12,572 - root - INFO - lp             :	0.3
2018-09-17 21:24:12,572 - root - INFO - bs             :	100
2018-09-17 21:24:12,572 - root - INFO - clip           :	5
2018-09-17 21:24:12,573 - root - INFO - epoch          :	20
2018-09-17 21:24:12,573 - root - INFO - layer1_units   :	50
2018-09-17 21:24:12,573 - root - INFO - layer2_units   :	100
2018-09-17 21:24:12,573 - root - INFO - input_dimension:	784
2018-09-17 21:24:12,573 - root - INFO - num_tags       :	10
2018-09-17 21:24:12,573 - root - INFO - opt            :	Adam
2018-09-17 21:26:25,576 - root - INFO - lr             :	0.02
2018-09-17 21:26:25,578 - root - INFO - dr             :	0.96
2018-09-17 21:26:25,578 - root - INFO - ds             :	100
2018-09-17 21:26:25,578 - root - INFO - edr            :	0.99
2018-09-17 21:26:25,578 - root - INFO - lp             :	0.3
2018-09-17 21:26:25,579 - root - INFO - bs             :	100
2018-09-17 21:26:25,579 - root - INFO - clip           :	5
2018-09-17 21:26:25,579 - root - INFO - epoch          :	20
2018-09-17 21:26:25,579 - root - INFO - layer1_units   :	50
2018-09-17 21:26:25,579 - root - INFO - layer2_units   :	100
2018-09-17 21:26:25,579 - root - INFO - input_dimension:	784
2018-09-17 21:26:25,579 - root - INFO - num_tags       :	10
2018-09-17 21:26:25,579 - root - INFO - opt            :	Adam
2018-09-17 21:26:26,347 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-17 21:26:26,475 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-17 21:26:26,484 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-17 21:26:27,101 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-17 21:26:27,106 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-17 21:26:27,233 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-17 21:26:28,353 - root - INFO - iteration 0: global_step=1; loss_value=4.730910
2018-09-17 21:26:28,357 - root - INFO - iteration 0: global_step=2; loss_value=3.169197
2018-09-17 21:26:28,361 - root - INFO - iteration 0: global_step=3; loss_value=1.947322
2018-09-17 21:26:28,365 - root - INFO - iteration 0: global_step=4; loss_value=1.250644
2018-09-17 21:26:28,369 - root - INFO - iteration 0: global_step=5; loss_value=1.245777
2018-09-17 21:26:28,375 - root - INFO - iteration 0: global_step=6; loss_value=1.325175
2018-09-17 21:26:28,379 - root - INFO - iteration 0: global_step=7; loss_value=0.928817
2018-09-17 21:26:28,383 - root - INFO - iteration 0: global_step=8; loss_value=0.850942
2018-09-17 21:26:28,389 - root - INFO - iteration 0: global_step=9; loss_value=1.095523
2018-09-17 21:26:28,393 - root - INFO - iteration 0: global_step=10; loss_value=0.836396
2018-09-17 21:26:28,397 - root - INFO - iteration 0: global_step=11; loss_value=0.670814
2018-09-17 21:26:28,402 - root - INFO - iteration 0: global_step=12; loss_value=0.541982
2018-09-17 21:26:28,411 - root - INFO - iteration 0: global_step=13; loss_value=0.556385
2018-09-17 21:26:28,417 - root - INFO - iteration 0: global_step=14; loss_value=0.542133
2018-09-17 21:26:28,421 - root - INFO - iteration 0: global_step=15; loss_value=0.660890
2018-09-17 21:26:28,425 - root - INFO - iteration 0: global_step=16; loss_value=0.551955
2018-09-17 21:26:28,429 - root - INFO - iteration 0: global_step=17; loss_value=0.753015
2018-09-17 21:26:28,436 - root - INFO - iteration 0: global_step=18; loss_value=0.417668
2018-09-17 21:26:28,442 - root - INFO - iteration 0: global_step=19; loss_value=0.690827
2018-09-17 21:26:28,446 - root - INFO - iteration 0: global_step=20; loss_value=0.608897
2018-09-17 21:26:28,453 - root - INFO - iteration 0: global_step=21; loss_value=0.478552
2018-09-17 21:26:28,460 - root - INFO - iteration 0: global_step=22; loss_value=0.367748
2018-09-17 21:26:28,465 - root - INFO - iteration 0: global_step=23; loss_value=0.415064
2018-09-17 21:26:28,472 - root - INFO - iteration 0: global_step=24; loss_value=0.384241
2018-09-17 21:26:28,474 - root - INFO - iteration 0: global_step=25; loss_value=0.489371
2018-09-17 21:26:28,478 - root - INFO - iteration 0: global_step=26; loss_value=0.634783
2018-09-17 21:26:28,482 - root - INFO - iteration 0: global_step=27; loss_value=0.397071
2018-09-17 21:26:28,487 - root - INFO - iteration 0: global_step=28; loss_value=0.449092
2018-09-17 21:26:28,491 - root - INFO - iteration 0: global_step=29; loss_value=0.317331
2018-09-17 21:26:28,498 - root - INFO - iteration 0: global_step=30; loss_value=0.483777
2018-09-17 21:26:28,500 - root - INFO - iteration 0: global_step=31; loss_value=0.871779
2018-09-17 21:26:28,506 - root - INFO - iteration 0: global_step=32; loss_value=0.619267
2018-09-17 21:26:28,508 - root - INFO - iteration 0: global_step=33; loss_value=0.436060
2018-09-17 21:26:28,510 - root - INFO - iteration 0: global_step=34; loss_value=0.378549
2018-09-17 21:26:28,515 - root - INFO - iteration 0: global_step=35; loss_value=0.488612
2018-09-17 21:26:28,520 - root - INFO - iteration 0: global_step=36; loss_value=0.361448
2018-09-17 21:26:28,522 - root - INFO - iteration 0: global_step=37; loss_value=0.508784
2018-09-17 21:26:28,527 - root - INFO - iteration 0: global_step=38; loss_value=0.427104
2018-09-17 21:26:28,531 - root - INFO - iteration 0: global_step=39; loss_value=0.373140
2018-09-17 21:26:28,537 - root - INFO - iteration 0: global_step=40; loss_value=0.541429
2018-09-17 21:26:28,539 - root - INFO - iteration 0: global_step=41; loss_value=0.401944
2018-09-17 21:26:28,545 - root - INFO - iteration 0: global_step=42; loss_value=0.312566
2018-09-17 21:26:28,549 - root - INFO - iteration 0: global_step=43; loss_value=0.218355
2018-09-17 21:26:28,553 - root - INFO - iteration 0: global_step=44; loss_value=0.373166
2018-09-17 21:26:28,557 - root - INFO - iteration 0: global_step=45; loss_value=0.515182
2018-09-17 21:26:28,561 - root - INFO - iteration 0: global_step=46; loss_value=0.436080
2018-09-17 21:26:28,569 - root - INFO - iteration 0: global_step=47; loss_value=0.462750
2018-09-17 21:26:28,571 - root - INFO - iteration 0: global_step=48; loss_value=0.502367
2018-09-17 21:26:28,573 - root - INFO - iteration 0: global_step=49; loss_value=0.368155
2018-09-17 21:26:28,578 - root - INFO - iteration 0: global_step=50; loss_value=0.494688
2018-09-17 21:26:28,583 - root - INFO - iteration 0: global_step=51; loss_value=0.271787
2018-09-17 21:26:28,589 - root - INFO - iteration 0: global_step=52; loss_value=0.266588
2018-09-17 21:26:28,591 - root - INFO - iteration 0: global_step=53; loss_value=0.397677
2018-09-17 21:26:28,597 - root - INFO - iteration 0: global_step=54; loss_value=0.193139
2018-09-17 21:26:28,599 - root - INFO - iteration 0: global_step=55; loss_value=0.295855
2018-09-17 21:26:28,603 - root - INFO - iteration 0: global_step=56; loss_value=0.514266
2018-09-17 21:26:28,607 - root - INFO - iteration 0: global_step=57; loss_value=0.364471
2018-09-17 21:26:28,611 - root - INFO - iteration 0: global_step=58; loss_value=0.528975
2018-09-17 21:26:28,616 - root - INFO - iteration 0: global_step=59; loss_value=0.349574
2018-09-17 21:26:28,618 - root - INFO - iteration 0: global_step=60; loss_value=0.323109
2018-09-17 21:26:28,623 - root - INFO - iteration 0: global_step=61; loss_value=0.310994
2018-09-17 21:26:28,627 - root - INFO - iteration 0: global_step=62; loss_value=0.442656
2018-09-17 21:26:28,631 - root - INFO - iteration 0: global_step=63; loss_value=0.336136
2018-09-17 21:26:28,635 - root - INFO - iteration 0: global_step=64; loss_value=0.368669
2018-09-17 21:26:28,639 - root - INFO - iteration 0: global_step=65; loss_value=0.284569
2018-09-17 21:26:28,646 - root - INFO - iteration 0: global_step=66; loss_value=0.413252
2018-09-17 21:26:28,653 - root - INFO - iteration 0: global_step=67; loss_value=0.424157
2018-09-17 21:26:28,655 - root - INFO - iteration 0: global_step=68; loss_value=0.316890
2018-09-17 21:26:28,659 - root - INFO - iteration 0: global_step=69; loss_value=0.282877
2018-09-17 21:26:28,661 - root - INFO - iteration 0: global_step=70; loss_value=0.373148
2018-09-17 21:26:28,666 - root - INFO - iteration 0: global_step=71; loss_value=0.327102
2018-09-17 21:26:28,673 - root - INFO - iteration 0: global_step=72; loss_value=0.673442
2018-09-17 21:26:28,678 - root - INFO - iteration 0: global_step=73; loss_value=0.153699
2018-09-17 21:26:28,688 - root - INFO - iteration 0: global_step=74; loss_value=0.361978
2018-09-17 21:26:28,693 - root - INFO - iteration 0: global_step=75; loss_value=0.408200
2018-09-17 21:26:28,695 - root - INFO - iteration 0: global_step=76; loss_value=0.377950
2018-09-17 21:26:28,705 - root - INFO - iteration 0: global_step=77; loss_value=0.332354
2018-09-17 21:26:28,707 - root - INFO - iteration 0: global_step=78; loss_value=0.463406
2018-09-17 21:26:28,711 - root - INFO - iteration 0: global_step=79; loss_value=0.214657
2018-09-17 21:26:28,715 - root - INFO - iteration 0: global_step=80; loss_value=0.335680
2018-09-17 21:26:28,721 - root - INFO - iteration 0: global_step=81; loss_value=0.320582
2018-09-17 21:26:28,726 - root - INFO - iteration 0: global_step=82; loss_value=0.312458
2018-09-17 21:26:28,732 - root - INFO - iteration 0: global_step=83; loss_value=0.243428
2018-09-17 21:26:28,741 - root - INFO - iteration 0: global_step=84; loss_value=0.285079
2018-09-17 21:26:28,743 - root - INFO - iteration 0: global_step=85; loss_value=0.218254
2018-09-17 21:26:28,749 - root - INFO - iteration 0: global_step=86; loss_value=0.494967
2018-09-17 21:26:28,753 - root - INFO - iteration 0: global_step=87; loss_value=0.334427
2018-09-17 21:26:28,759 - root - INFO - iteration 0: global_step=88; loss_value=0.213587
2018-09-17 21:26:28,765 - root - INFO - iteration 0: global_step=89; loss_value=0.267267
2018-09-17 21:26:28,767 - root - INFO - iteration 0: global_step=90; loss_value=0.300281
2018-09-17 21:26:28,773 - root - INFO - iteration 0: global_step=91; loss_value=0.273776
2018-09-17 21:26:28,775 - root - INFO - iteration 0: global_step=92; loss_value=0.201405
2018-09-17 21:26:28,781 - root - INFO - iteration 0: global_step=93; loss_value=0.375307
2018-09-17 21:26:28,783 - root - INFO - iteration 0: global_step=94; loss_value=0.170922
2018-09-17 21:26:28,789 - root - INFO - iteration 0: global_step=95; loss_value=0.394212
2018-09-17 21:26:28,791 - root - INFO - iteration 0: global_step=96; loss_value=0.429546
2018-09-17 21:26:28,797 - root - INFO - iteration 0: global_step=97; loss_value=0.339351
2018-09-17 21:26:28,799 - root - INFO - iteration 0: global_step=98; loss_value=0.155381
2018-09-17 21:26:28,805 - root - INFO - iteration 0: global_step=99; loss_value=0.213717
2018-09-17 21:26:28,807 - root - INFO - iteration 0: global_step=100; loss_value=0.281166
2018-09-17 21:26:28,863 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:29,371 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:29,897 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:30,414 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:30,950 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:31,794 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:32,358 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:32,918 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:33,480 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:34,009 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:34,074 - root - INFO - iteration 10: global_step=1001; loss_value=0.095521
2018-09-17 21:26:34,076 - root - INFO - iteration 10: global_step=1002; loss_value=0.097815
2018-09-17 21:26:34,080 - root - INFO - iteration 10: global_step=1003; loss_value=0.159653
2018-09-17 21:26:34,085 - root - INFO - iteration 10: global_step=1004; loss_value=0.158479
2018-09-17 21:26:34,090 - root - INFO - iteration 10: global_step=1005; loss_value=0.051618
2018-09-17 21:26:34,094 - root - INFO - iteration 10: global_step=1006; loss_value=0.121042
2018-09-17 21:26:34,103 - root - INFO - iteration 10: global_step=1007; loss_value=0.140008
2018-09-17 21:26:34,110 - root - INFO - iteration 10: global_step=1008; loss_value=0.143942
2018-09-17 21:26:34,121 - root - INFO - iteration 10: global_step=1009; loss_value=0.280825
2018-09-17 21:26:34,123 - root - INFO - iteration 10: global_step=1010; loss_value=0.051655
2018-09-17 21:26:34,126 - root - INFO - iteration 10: global_step=1011; loss_value=0.166542
2018-09-17 21:26:34,131 - root - INFO - iteration 10: global_step=1012; loss_value=0.137104
2018-09-17 21:26:34,138 - root - INFO - iteration 10: global_step=1013; loss_value=0.201332
2018-09-17 21:26:34,140 - root - INFO - iteration 10: global_step=1014; loss_value=0.214912
2018-09-17 21:26:34,144 - root - INFO - iteration 10: global_step=1015; loss_value=0.267206
2018-09-17 21:26:34,148 - root - INFO - iteration 10: global_step=1016; loss_value=0.175466
2018-09-17 21:26:34,154 - root - INFO - iteration 10: global_step=1017; loss_value=0.258690
2018-09-17 21:26:34,156 - root - INFO - iteration 10: global_step=1018; loss_value=0.060263
2018-09-17 21:26:34,161 - root - INFO - iteration 10: global_step=1019; loss_value=0.130824
2018-09-17 21:26:34,165 - root - INFO - iteration 10: global_step=1020; loss_value=0.109112
2018-09-17 21:26:34,170 - root - INFO - iteration 10: global_step=1021; loss_value=0.058723
2018-09-17 21:26:34,175 - root - INFO - iteration 10: global_step=1022; loss_value=0.206832
2018-09-17 21:26:34,179 - root - INFO - iteration 10: global_step=1023; loss_value=0.132271
2018-09-17 21:26:34,183 - root - INFO - iteration 10: global_step=1024; loss_value=0.121765
2018-09-17 21:26:34,187 - root - INFO - iteration 10: global_step=1025; loss_value=0.205786
2018-09-17 21:26:34,192 - root - INFO - iteration 10: global_step=1026; loss_value=0.137009
2018-09-17 21:26:34,195 - root - INFO - iteration 10: global_step=1027; loss_value=0.197977
2018-09-17 21:26:34,199 - root - INFO - iteration 10: global_step=1028; loss_value=0.144286
2018-09-17 21:26:34,203 - root - INFO - iteration 10: global_step=1029; loss_value=0.179662
2018-09-17 21:26:34,208 - root - INFO - iteration 10: global_step=1030; loss_value=0.211562
2018-09-17 21:26:34,212 - root - INFO - iteration 10: global_step=1031; loss_value=0.148797
2018-09-17 21:26:34,219 - root - INFO - iteration 10: global_step=1032; loss_value=0.233279
2018-09-17 21:26:34,223 - root - INFO - iteration 10: global_step=1033; loss_value=0.079318
2018-09-17 21:26:34,225 - root - INFO - iteration 10: global_step=1034; loss_value=0.268408
2018-09-17 21:26:34,232 - root - INFO - iteration 10: global_step=1035; loss_value=0.124092
2018-09-17 21:26:34,234 - root - INFO - iteration 10: global_step=1036; loss_value=0.212020
2018-09-17 21:26:34,239 - root - INFO - iteration 10: global_step=1037; loss_value=0.151935
2018-09-17 21:26:34,244 - root - INFO - iteration 10: global_step=1038; loss_value=0.129475
2018-09-17 21:26:34,247 - root - INFO - iteration 10: global_step=1039; loss_value=0.129404
2018-09-17 21:26:34,253 - root - INFO - iteration 10: global_step=1040; loss_value=0.171599
2018-09-17 21:26:34,265 - root - INFO - iteration 10: global_step=1041; loss_value=0.238913
2018-09-17 21:26:34,267 - root - INFO - iteration 10: global_step=1042; loss_value=0.153803
2018-09-17 21:26:34,271 - root - INFO - iteration 10: global_step=1043; loss_value=0.106671
2018-09-17 21:26:34,277 - root - INFO - iteration 10: global_step=1044; loss_value=0.161262
2018-09-17 21:26:34,279 - root - INFO - iteration 10: global_step=1045; loss_value=0.086508
2018-09-17 21:26:34,289 - root - INFO - iteration 10: global_step=1046; loss_value=0.322735
2018-09-17 21:26:34,291 - root - INFO - iteration 10: global_step=1047; loss_value=0.260654
2018-09-17 21:26:34,295 - root - INFO - iteration 10: global_step=1048; loss_value=0.074070
2018-09-17 21:26:34,298 - root - INFO - iteration 10: global_step=1049; loss_value=0.225883
2018-09-17 21:26:34,305 - root - INFO - iteration 10: global_step=1050; loss_value=0.174218
2018-09-17 21:26:34,309 - root - INFO - iteration 10: global_step=1051; loss_value=0.269290
2018-09-17 21:26:34,314 - root - INFO - iteration 10: global_step=1052; loss_value=0.121865
2018-09-17 21:26:34,320 - root - INFO - iteration 10: global_step=1053; loss_value=0.233853
2018-09-17 21:26:34,329 - root - INFO - iteration 10: global_step=1054; loss_value=0.026742
2018-09-17 21:26:34,337 - root - INFO - iteration 10: global_step=1055; loss_value=0.060055
2018-09-17 21:26:34,341 - root - INFO - iteration 10: global_step=1056; loss_value=0.154214
2018-09-17 21:26:34,345 - root - INFO - iteration 10: global_step=1057; loss_value=0.308043
2018-09-17 21:26:34,351 - root - INFO - iteration 10: global_step=1058; loss_value=0.153175
2018-09-17 21:26:34,353 - root - INFO - iteration 10: global_step=1059; loss_value=0.084791
2018-09-17 21:26:34,359 - root - INFO - iteration 10: global_step=1060; loss_value=0.130352
2018-09-17 21:26:34,365 - root - INFO - iteration 10: global_step=1061; loss_value=0.153685
2018-09-17 21:26:34,367 - root - INFO - iteration 10: global_step=1062; loss_value=0.106808
2018-09-17 21:26:34,370 - root - INFO - iteration 10: global_step=1063; loss_value=0.120815
2018-09-17 21:26:34,374 - root - INFO - iteration 10: global_step=1064; loss_value=0.137350
2018-09-17 21:26:34,379 - root - INFO - iteration 10: global_step=1065; loss_value=0.075727
2018-09-17 21:26:34,383 - root - INFO - iteration 10: global_step=1066; loss_value=0.227134
2018-09-17 21:26:34,393 - root - INFO - iteration 10: global_step=1067; loss_value=0.239199
2018-09-17 21:26:34,395 - root - INFO - iteration 10: global_step=1068; loss_value=0.174057
2018-09-17 21:26:34,397 - root - INFO - iteration 10: global_step=1069; loss_value=0.103004
2018-09-17 21:26:34,401 - root - INFO - iteration 10: global_step=1070; loss_value=0.201900
2018-09-17 21:26:34,405 - root - INFO - iteration 10: global_step=1071; loss_value=0.161944
2018-09-17 21:26:34,410 - root - INFO - iteration 10: global_step=1072; loss_value=0.196943
2018-09-17 21:26:34,416 - root - INFO - iteration 10: global_step=1073; loss_value=0.360029
2018-09-17 21:26:34,418 - root - INFO - iteration 10: global_step=1074; loss_value=0.401760
2018-09-17 21:26:34,423 - root - INFO - iteration 10: global_step=1075; loss_value=0.083718
2018-09-17 21:26:34,429 - root - INFO - iteration 10: global_step=1076; loss_value=0.097932
2018-09-17 21:26:34,431 - root - INFO - iteration 10: global_step=1077; loss_value=0.085954
2018-09-17 21:26:34,437 - root - INFO - iteration 10: global_step=1078; loss_value=0.176892
2018-09-17 21:26:34,441 - root - INFO - iteration 10: global_step=1079; loss_value=0.107633
2018-09-17 21:26:34,445 - root - INFO - iteration 10: global_step=1080; loss_value=0.184882
2018-09-17 21:26:34,450 - root - INFO - iteration 10: global_step=1081; loss_value=0.202648
2018-09-17 21:26:34,452 - root - INFO - iteration 10: global_step=1082; loss_value=0.251878
2018-09-17 21:26:34,458 - root - INFO - iteration 10: global_step=1083; loss_value=0.114977
2018-09-17 21:26:34,464 - root - INFO - iteration 10: global_step=1084; loss_value=0.278953
2018-09-17 21:26:34,466 - root - INFO - iteration 10: global_step=1085; loss_value=0.069513
2018-09-17 21:26:34,470 - root - INFO - iteration 10: global_step=1086; loss_value=0.420188
2018-09-17 21:26:34,474 - root - INFO - iteration 10: global_step=1087; loss_value=0.166274
2018-09-17 21:26:34,478 - root - INFO - iteration 10: global_step=1088; loss_value=0.073684
2018-09-17 21:26:34,482 - root - INFO - iteration 10: global_step=1089; loss_value=0.152070
2018-09-17 21:26:34,489 - root - INFO - iteration 10: global_step=1090; loss_value=0.242627
2018-09-17 21:26:34,491 - root - INFO - iteration 10: global_step=1091; loss_value=0.074494
2018-09-17 21:26:34,495 - root - INFO - iteration 10: global_step=1092; loss_value=0.262249
2018-09-17 21:26:34,500 - root - INFO - iteration 10: global_step=1093; loss_value=0.161785
2018-09-17 21:26:34,505 - root - INFO - iteration 10: global_step=1094; loss_value=0.134774
2018-09-17 21:26:34,510 - root - INFO - iteration 10: global_step=1095; loss_value=0.222669
2018-09-17 21:26:34,512 - root - INFO - iteration 10: global_step=1096; loss_value=0.247137
2018-09-17 21:26:34,519 - root - INFO - iteration 10: global_step=1097; loss_value=0.124892
2018-09-17 21:26:34,521 - root - INFO - iteration 10: global_step=1098; loss_value=0.170126
2018-09-17 21:26:34,527 - root - INFO - iteration 10: global_step=1099; loss_value=0.229031
2018-09-17 21:26:34,533 - root - INFO - iteration 10: global_step=1100; loss_value=0.396578
2018-09-17 21:26:34,578 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:35,287 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:35,879 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:36,479 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:37,072 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:37,661 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:38,474 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:39,201 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:39,804 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-17 21:26:40,426 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 100)
2018-09-18 01:50:14,831 - root - INFO - lr             :	0.02
2018-09-18 01:50:14,836 - root - INFO - dr             :	0.96
2018-09-18 01:50:14,837 - root - INFO - ds             :	100
2018-09-18 01:50:14,837 - root - INFO - edr            :	0.99
2018-09-18 01:50:14,838 - root - INFO - lp             :	0.3
2018-09-18 01:50:14,838 - root - INFO - bs             :	100
2018-09-18 01:50:14,838 - root - INFO - clip           :	5
2018-09-18 01:50:14,838 - root - INFO - epoch          :	20
2018-09-18 01:50:14,838 - root - INFO - layer1_units   :	50
2018-09-18 01:50:14,838 - root - INFO - layer2_units   :	10
2018-09-18 01:50:14,838 - root - INFO - input_dimension:	784
2018-09-18 01:50:14,838 - root - INFO - num_tags       :	10
2018-09-18 01:50:14,838 - root - INFO - opt            :	Adam
2018-09-18 01:50:15,330 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 01:50:15,470 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-18 01:50:15,475 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 01:50:15,903 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 01:50:15,910 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-18 01:50:16,035 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 01:50:17,258 - root - INFO - iteration 0: global_step=1; loss_value=2.576561
2018-09-18 01:50:17,273 - root - INFO - iteration 0: global_step=2; loss_value=2.821797
2018-09-18 01:50:17,275 - root - INFO - iteration 0: global_step=3; loss_value=1.696180
2018-09-18 01:50:17,284 - root - INFO - iteration 0: global_step=4; loss_value=1.581909
2018-09-18 01:50:17,293 - root - INFO - iteration 0: global_step=5; loss_value=1.472907
2018-09-18 01:50:17,294 - root - INFO - iteration 0: global_step=6; loss_value=1.229671
2018-09-18 01:50:17,300 - root - INFO - iteration 0: global_step=7; loss_value=1.168304
2018-09-18 01:50:17,304 - root - INFO - iteration 0: global_step=8; loss_value=1.100444
2018-09-18 01:50:17,306 - root - INFO - iteration 0: global_step=9; loss_value=0.770945
2018-09-18 01:50:17,310 - root - INFO - iteration 0: global_step=10; loss_value=0.743153
2018-09-18 01:50:17,319 - root - INFO - iteration 0: global_step=11; loss_value=0.757056
2018-09-18 01:50:17,326 - root - INFO - iteration 0: global_step=12; loss_value=0.708661
2018-09-18 01:50:17,335 - root - INFO - iteration 0: global_step=13; loss_value=0.497573
2018-09-18 01:50:17,340 - root - INFO - iteration 0: global_step=14; loss_value=0.728836
2018-09-18 01:50:17,343 - root - INFO - iteration 0: global_step=15; loss_value=0.633518
2018-09-18 01:50:17,351 - root - INFO - iteration 0: global_step=16; loss_value=0.642778
2018-09-18 01:50:17,353 - root - INFO - iteration 0: global_step=17; loss_value=0.488706
2018-09-18 01:50:17,361 - root - INFO - iteration 0: global_step=18; loss_value=0.445461
2018-09-18 01:50:17,366 - root - INFO - iteration 0: global_step=19; loss_value=0.526731
2018-09-18 01:50:17,374 - root - INFO - iteration 0: global_step=20; loss_value=0.424805
2018-09-18 01:50:17,380 - root - INFO - iteration 0: global_step=21; loss_value=0.434722
2018-09-18 01:50:17,384 - root - INFO - iteration 0: global_step=22; loss_value=0.572350
2018-09-18 01:50:17,388 - root - INFO - iteration 0: global_step=23; loss_value=0.705343
2018-09-18 01:50:17,393 - root - INFO - iteration 0: global_step=24; loss_value=0.762362
2018-09-18 01:50:17,395 - root - INFO - iteration 0: global_step=25; loss_value=0.347623
2018-09-18 01:50:17,402 - root - INFO - iteration 0: global_step=26; loss_value=0.989332
2018-09-18 01:50:17,403 - root - INFO - iteration 0: global_step=27; loss_value=0.720470
2018-09-18 01:50:17,408 - root - INFO - iteration 0: global_step=28; loss_value=0.375280
2018-09-18 01:50:17,415 - root - INFO - iteration 0: global_step=29; loss_value=0.450992
2018-09-18 01:50:17,419 - root - INFO - iteration 0: global_step=30; loss_value=0.321147
2018-09-18 01:50:17,423 - root - INFO - iteration 0: global_step=31; loss_value=0.463176
2018-09-18 01:50:17,428 - root - INFO - iteration 0: global_step=32; loss_value=0.730680
2018-09-18 01:50:17,436 - root - INFO - iteration 0: global_step=33; loss_value=0.588438
2018-09-18 01:50:17,438 - root - INFO - iteration 0: global_step=34; loss_value=0.417655
2018-09-18 01:50:17,439 - root - INFO - iteration 0: global_step=35; loss_value=0.519700
2018-09-18 01:50:17,445 - root - INFO - iteration 0: global_step=36; loss_value=0.382310
2018-09-18 01:50:17,447 - root - INFO - iteration 0: global_step=37; loss_value=0.474358
2018-09-18 01:50:17,452 - root - INFO - iteration 0: global_step=38; loss_value=0.395327
2018-09-18 01:50:17,458 - root - INFO - iteration 0: global_step=39; loss_value=0.472968
2018-09-18 01:50:17,465 - root - INFO - iteration 0: global_step=40; loss_value=0.501275
2018-09-18 01:50:17,467 - root - INFO - iteration 0: global_step=41; loss_value=0.520099
2018-09-18 01:50:17,473 - root - INFO - iteration 0: global_step=42; loss_value=0.569848
2018-09-18 01:50:17,477 - root - INFO - iteration 0: global_step=43; loss_value=0.329131
2018-09-18 01:50:17,482 - root - INFO - iteration 0: global_step=44; loss_value=0.381664
2018-09-18 01:50:17,487 - root - INFO - iteration 0: global_step=45; loss_value=0.214460
2018-09-18 01:50:17,493 - root - INFO - iteration 0: global_step=46; loss_value=0.466982
2018-09-18 01:50:17,503 - root - INFO - iteration 0: global_step=47; loss_value=0.211999
2018-09-18 01:50:17,507 - root - INFO - iteration 0: global_step=48; loss_value=0.401866
2018-09-18 01:50:17,509 - root - INFO - iteration 0: global_step=49; loss_value=0.334469
2018-09-18 01:50:17,516 - root - INFO - iteration 0: global_step=50; loss_value=0.360032
2018-09-18 01:50:17,519 - root - INFO - iteration 0: global_step=51; loss_value=0.380787
2018-09-18 01:50:17,524 - root - INFO - iteration 0: global_step=52; loss_value=0.350967
2018-09-18 01:50:17,528 - root - INFO - iteration 0: global_step=53; loss_value=0.276142
2018-09-18 01:50:17,533 - root - INFO - iteration 0: global_step=54; loss_value=0.304390
2018-09-18 01:50:17,539 - root - INFO - iteration 0: global_step=55; loss_value=0.258058
2018-09-18 01:50:17,543 - root - INFO - iteration 0: global_step=56; loss_value=0.372281
2018-09-18 01:50:17,549 - root - INFO - iteration 0: global_step=57; loss_value=0.280087
2018-09-18 01:50:17,553 - root - INFO - iteration 0: global_step=58; loss_value=0.314711
2018-09-18 01:50:17,557 - root - INFO - iteration 0: global_step=59; loss_value=0.337000
2018-09-18 01:50:17,561 - root - INFO - iteration 0: global_step=60; loss_value=0.592451
2018-09-18 01:50:17,567 - root - INFO - iteration 0: global_step=61; loss_value=0.480810
2018-09-18 01:50:17,569 - root - INFO - iteration 0: global_step=62; loss_value=0.543856
2018-09-18 01:50:17,576 - root - INFO - iteration 0: global_step=63; loss_value=0.416237
2018-09-18 01:50:17,584 - root - INFO - iteration 0: global_step=64; loss_value=0.422004
2018-09-18 01:50:17,586 - root - INFO - iteration 0: global_step=65; loss_value=0.319989
2018-09-18 01:50:17,590 - root - INFO - iteration 0: global_step=66; loss_value=0.382693
2018-09-18 01:50:17,594 - root - INFO - iteration 0: global_step=67; loss_value=0.266743
2018-09-18 01:50:17,599 - root - INFO - iteration 0: global_step=68; loss_value=0.400669
2018-09-18 01:50:17,601 - root - INFO - iteration 0: global_step=69; loss_value=0.375190
2018-09-18 01:50:17,605 - root - INFO - iteration 0: global_step=70; loss_value=0.275734
2018-09-18 01:50:17,609 - root - INFO - iteration 0: global_step=71; loss_value=0.267435
2018-09-18 01:50:17,613 - root - INFO - iteration 0: global_step=72; loss_value=0.344994
2018-09-18 01:50:17,618 - root - INFO - iteration 0: global_step=73; loss_value=0.265844
2018-09-18 01:50:17,622 - root - INFO - iteration 0: global_step=74; loss_value=0.323667
2018-09-18 01:50:17,630 - root - INFO - iteration 0: global_step=75; loss_value=0.297104
2018-09-18 01:50:17,634 - root - INFO - iteration 0: global_step=76; loss_value=0.442960
2018-09-18 01:50:17,640 - root - INFO - iteration 0: global_step=77; loss_value=0.427147
2018-09-18 01:50:17,642 - root - INFO - iteration 0: global_step=78; loss_value=0.370126
2018-09-18 01:50:17,646 - root - INFO - iteration 0: global_step=79; loss_value=0.216380
2018-09-18 01:50:17,650 - root - INFO - iteration 0: global_step=80; loss_value=0.351859
2018-09-18 01:50:17,654 - root - INFO - iteration 0: global_step=81; loss_value=0.169804
2018-09-18 01:50:17,662 - root - INFO - iteration 0: global_step=82; loss_value=0.292575
2018-09-18 01:50:17,667 - root - INFO - iteration 0: global_step=83; loss_value=0.393445
2018-09-18 01:50:17,671 - root - INFO - iteration 0: global_step=84; loss_value=0.406995
2018-09-18 01:50:17,674 - root - INFO - iteration 0: global_step=85; loss_value=0.357710
2018-09-18 01:50:17,680 - root - INFO - iteration 0: global_step=86; loss_value=0.353271
2018-09-18 01:50:17,684 - root - INFO - iteration 0: global_step=87; loss_value=0.215144
2018-09-18 01:50:17,688 - root - INFO - iteration 0: global_step=88; loss_value=0.429873
2018-09-18 01:50:17,695 - root - INFO - iteration 0: global_step=89; loss_value=0.315669
2018-09-18 01:50:17,697 - root - INFO - iteration 0: global_step=90; loss_value=0.256785
2018-09-18 01:50:17,705 - root - INFO - iteration 0: global_step=91; loss_value=0.492650
2018-09-18 01:50:17,716 - root - INFO - iteration 0: global_step=92; loss_value=0.372962
2018-09-18 01:50:17,718 - root - INFO - iteration 0: global_step=93; loss_value=0.331967
2018-09-18 01:50:17,720 - root - INFO - iteration 0: global_step=94; loss_value=0.348085
2018-09-18 01:50:17,724 - root - INFO - iteration 0: global_step=95; loss_value=0.238367
2018-09-18 01:50:17,726 - root - INFO - iteration 0: global_step=96; loss_value=0.244480
2018-09-18 01:50:17,730 - root - INFO - iteration 0: global_step=97; loss_value=0.559383
2018-09-18 01:50:17,734 - root - INFO - iteration 0: global_step=98; loss_value=0.407174
2018-09-18 01:50:17,738 - root - INFO - iteration 0: global_step=99; loss_value=0.172539
2018-09-18 01:50:17,744 - root - INFO - iteration 0: global_step=100; loss_value=0.256820
2018-09-18 01:50:17,808 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:18,104 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:18,421 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:18,693 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:18,995 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:19,513 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:19,787 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:20,051 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:20,347 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:20,663 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:20,730 - root - INFO - iteration 10: global_step=1001; loss_value=0.108230
2018-09-18 01:50:20,734 - root - INFO - iteration 10: global_step=1002; loss_value=0.089925
2018-09-18 01:50:20,738 - root - INFO - iteration 10: global_step=1003; loss_value=0.151627
2018-09-18 01:50:20,740 - root - INFO - iteration 10: global_step=1004; loss_value=0.135979
2018-09-18 01:50:20,745 - root - INFO - iteration 10: global_step=1005; loss_value=0.206083
2018-09-18 01:50:20,749 - root - INFO - iteration 10: global_step=1006; loss_value=0.085600
2018-09-18 01:50:20,753 - root - INFO - iteration 10: global_step=1007; loss_value=0.299305
2018-09-18 01:50:20,760 - root - INFO - iteration 10: global_step=1008; loss_value=0.130047
2018-09-18 01:50:20,767 - root - INFO - iteration 10: global_step=1009; loss_value=0.100907
2018-09-18 01:50:20,771 - root - INFO - iteration 10: global_step=1010; loss_value=0.376055
2018-09-18 01:50:20,773 - root - INFO - iteration 10: global_step=1011; loss_value=0.087048
2018-09-18 01:50:20,777 - root - INFO - iteration 10: global_step=1012; loss_value=0.264953
2018-09-18 01:50:20,781 - root - INFO - iteration 10: global_step=1013; loss_value=0.252373
2018-09-18 01:50:20,785 - root - INFO - iteration 10: global_step=1014; loss_value=0.246521
2018-09-18 01:50:20,789 - root - INFO - iteration 10: global_step=1015; loss_value=0.251434
2018-09-18 01:50:20,793 - root - INFO - iteration 10: global_step=1016; loss_value=0.090881
2018-09-18 01:50:20,798 - root - INFO - iteration 10: global_step=1017; loss_value=0.109858
2018-09-18 01:50:20,802 - root - INFO - iteration 10: global_step=1018; loss_value=0.193818
2018-09-18 01:50:20,808 - root - INFO - iteration 10: global_step=1019; loss_value=0.268267
2018-09-18 01:50:20,815 - root - INFO - iteration 10: global_step=1020; loss_value=0.097908
2018-09-18 01:50:20,818 - root - INFO - iteration 10: global_step=1021; loss_value=0.391053
2018-09-18 01:50:20,830 - root - INFO - iteration 10: global_step=1022; loss_value=0.047854
2018-09-18 01:50:20,843 - root - INFO - iteration 10: global_step=1023; loss_value=0.147452
2018-09-18 01:50:20,851 - root - INFO - iteration 10: global_step=1024; loss_value=0.145394
2018-09-18 01:50:20,866 - root - INFO - iteration 10: global_step=1025; loss_value=0.350586
2018-09-18 01:50:20,873 - root - INFO - iteration 10: global_step=1026; loss_value=0.176560
2018-09-18 01:50:20,883 - root - INFO - iteration 10: global_step=1027; loss_value=0.072280
2018-09-18 01:50:20,901 - root - INFO - iteration 10: global_step=1028; loss_value=0.149710
2018-09-18 01:50:20,910 - root - INFO - iteration 10: global_step=1029; loss_value=0.297019
2018-09-18 01:50:20,920 - root - INFO - iteration 10: global_step=1030; loss_value=0.190259
2018-09-18 01:50:20,935 - root - INFO - iteration 10: global_step=1031; loss_value=0.216736
2018-09-18 01:50:20,946 - root - INFO - iteration 10: global_step=1032; loss_value=0.280216
2018-09-18 01:50:20,956 - root - INFO - iteration 10: global_step=1033; loss_value=0.132899
2018-09-18 01:50:20,969 - root - INFO - iteration 10: global_step=1034; loss_value=0.316597
2018-09-18 01:50:20,981 - root - INFO - iteration 10: global_step=1035; loss_value=0.200694
2018-09-18 01:50:20,990 - root - INFO - iteration 10: global_step=1036; loss_value=0.082349
2018-09-18 01:50:20,995 - root - INFO - iteration 10: global_step=1037; loss_value=0.065081
2018-09-18 01:50:21,004 - root - INFO - iteration 10: global_step=1038; loss_value=0.293464
2018-09-18 01:50:21,020 - root - INFO - iteration 10: global_step=1039; loss_value=0.211850
2018-09-18 01:50:21,026 - root - INFO - iteration 10: global_step=1040; loss_value=0.175263
2018-09-18 01:50:21,030 - root - INFO - iteration 10: global_step=1041; loss_value=0.055804
2018-09-18 01:50:21,037 - root - INFO - iteration 10: global_step=1042; loss_value=0.224316
2018-09-18 01:50:21,044 - root - INFO - iteration 10: global_step=1043; loss_value=0.122824
2018-09-18 01:50:21,047 - root - INFO - iteration 10: global_step=1044; loss_value=0.096226
2018-09-18 01:50:21,050 - root - INFO - iteration 10: global_step=1045; loss_value=0.225826
2018-09-18 01:50:21,059 - root - INFO - iteration 10: global_step=1046; loss_value=0.164834
2018-09-18 01:50:21,065 - root - INFO - iteration 10: global_step=1047; loss_value=0.290582
2018-09-18 01:50:21,069 - root - INFO - iteration 10: global_step=1048; loss_value=0.128134
2018-09-18 01:50:21,073 - root - INFO - iteration 10: global_step=1049; loss_value=0.146485
2018-09-18 01:50:21,077 - root - INFO - iteration 10: global_step=1050; loss_value=0.172009
2018-09-18 01:50:21,084 - root - INFO - iteration 10: global_step=1051; loss_value=0.119320
2018-09-18 01:50:21,087 - root - INFO - iteration 10: global_step=1052; loss_value=0.227291
2018-09-18 01:50:21,092 - root - INFO - iteration 10: global_step=1053; loss_value=0.076269
2018-09-18 01:50:21,096 - root - INFO - iteration 10: global_step=1054; loss_value=0.252262
2018-09-18 01:50:21,103 - root - INFO - iteration 10: global_step=1055; loss_value=0.320607
2018-09-18 01:50:21,108 - root - INFO - iteration 10: global_step=1056; loss_value=0.257926
2018-09-18 01:50:21,114 - root - INFO - iteration 10: global_step=1057; loss_value=0.179879
2018-09-18 01:50:21,124 - root - INFO - iteration 10: global_step=1058; loss_value=0.043358
2018-09-18 01:50:21,127 - root - INFO - iteration 10: global_step=1059; loss_value=0.317321
2018-09-18 01:50:21,132 - root - INFO - iteration 10: global_step=1060; loss_value=0.218900
2018-09-18 01:50:21,136 - root - INFO - iteration 10: global_step=1061; loss_value=0.311542
2018-09-18 01:50:21,146 - root - INFO - iteration 10: global_step=1062; loss_value=0.178767
2018-09-18 01:50:21,149 - root - INFO - iteration 10: global_step=1063; loss_value=0.150004
2018-09-18 01:50:21,159 - root - INFO - iteration 10: global_step=1064; loss_value=0.267531
2018-09-18 01:50:21,162 - root - INFO - iteration 10: global_step=1065; loss_value=0.055813
2018-09-18 01:50:21,165 - root - INFO - iteration 10: global_step=1066; loss_value=0.105460
2018-09-18 01:50:21,169 - root - INFO - iteration 10: global_step=1067; loss_value=0.148596
2018-09-18 01:50:21,173 - root - INFO - iteration 10: global_step=1068; loss_value=0.121884
2018-09-18 01:50:21,177 - root - INFO - iteration 10: global_step=1069; loss_value=0.163180
2018-09-18 01:50:21,187 - root - INFO - iteration 10: global_step=1070; loss_value=0.214069
2018-09-18 01:50:21,189 - root - INFO - iteration 10: global_step=1071; loss_value=0.284810
2018-09-18 01:50:21,191 - root - INFO - iteration 10: global_step=1072; loss_value=0.153285
2018-09-18 01:50:21,198 - root - INFO - iteration 10: global_step=1073; loss_value=0.127066
2018-09-18 01:50:21,201 - root - INFO - iteration 10: global_step=1074; loss_value=0.147745
2018-09-18 01:50:21,207 - root - INFO - iteration 10: global_step=1075; loss_value=0.153143
2018-09-18 01:50:21,213 - root - INFO - iteration 10: global_step=1076; loss_value=0.118734
2018-09-18 01:50:21,217 - root - INFO - iteration 10: global_step=1077; loss_value=0.230692
2018-09-18 01:50:21,219 - root - INFO - iteration 10: global_step=1078; loss_value=0.186313
2018-09-18 01:50:21,229 - root - INFO - iteration 10: global_step=1079; loss_value=0.181390
2018-09-18 01:50:21,238 - root - INFO - iteration 10: global_step=1080; loss_value=0.179478
2018-09-18 01:50:21,240 - root - INFO - iteration 10: global_step=1081; loss_value=0.083981
2018-09-18 01:50:21,246 - root - INFO - iteration 10: global_step=1082; loss_value=0.278138
2018-09-18 01:50:21,253 - root - INFO - iteration 10: global_step=1083; loss_value=0.286333
2018-09-18 01:50:21,255 - root - INFO - iteration 10: global_step=1084; loss_value=0.191447
2018-09-18 01:50:21,259 - root - INFO - iteration 10: global_step=1085; loss_value=0.192703
2018-09-18 01:50:21,266 - root - INFO - iteration 10: global_step=1086; loss_value=0.110637
2018-09-18 01:50:21,270 - root - INFO - iteration 10: global_step=1087; loss_value=0.155230
2018-09-18 01:50:21,276 - root - INFO - iteration 10: global_step=1088; loss_value=0.140628
2018-09-18 01:50:21,280 - root - INFO - iteration 10: global_step=1089; loss_value=0.272249
2018-09-18 01:50:21,284 - root - INFO - iteration 10: global_step=1090; loss_value=0.180271
2018-09-18 01:50:21,286 - root - INFO - iteration 10: global_step=1091; loss_value=0.198042
2018-09-18 01:50:21,290 - root - INFO - iteration 10: global_step=1092; loss_value=0.069233
2018-09-18 01:50:21,294 - root - INFO - iteration 10: global_step=1093; loss_value=0.092779
2018-09-18 01:50:21,298 - root - INFO - iteration 10: global_step=1094; loss_value=0.067636
2018-09-18 01:50:21,302 - root - INFO - iteration 10: global_step=1095; loss_value=0.119259
2018-09-18 01:50:21,312 - root - INFO - iteration 10: global_step=1096; loss_value=0.137056
2018-09-18 01:50:21,316 - root - INFO - iteration 10: global_step=1097; loss_value=0.248320
2018-09-18 01:50:21,321 - root - INFO - iteration 10: global_step=1098; loss_value=0.356652
2018-09-18 01:50:21,326 - root - INFO - iteration 10: global_step=1099; loss_value=0.402736
2018-09-18 01:50:21,330 - root - INFO - iteration 10: global_step=1100; loss_value=0.156644
2018-09-18 01:50:21,385 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:21,868 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:22,125 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:22,398 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:22,702 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:22,986 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:23,410 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:23,758 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:24,070 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 01:50:24,334 - root - INFO - steps_per_epoch=100 and forecast result shape:
(5000, 10)
2018-09-18 22:55:43,803 - root - INFO - lr             :	0.02
2018-09-18 22:55:43,809 - root - INFO - dr             :	0.96
2018-09-18 22:55:43,809 - root - INFO - ds             :	100
2018-09-18 22:55:43,809 - root - INFO - edr            :	0.99
2018-09-18 22:55:43,809 - root - INFO - lp             :	0.3
2018-09-18 22:55:43,809 - root - INFO - bs             :	100
2018-09-18 22:55:43,809 - root - INFO - clip           :	5
2018-09-18 22:55:43,809 - root - INFO - epoch          :	20
2018-09-18 22:55:43,809 - root - INFO - layer1_units   :	50
2018-09-18 22:55:43,809 - root - INFO - layer2_units   :	10
2018-09-18 22:55:43,809 - root - INFO - input_dimension:	784
2018-09-18 22:55:43,810 - root - INFO - num_tags       :	10
2018-09-18 22:55:43,810 - root - INFO - opt            :	Adam
2018-09-18 22:55:44,394 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 22:55:44,519 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-18 22:55:44,527 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 22:55:44,950 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 22:55:44,957 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-18 22:55:45,101 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 22:55:46,162 - root - INFO - iteration 0: global_step=1; loss_value=2.438111
2018-09-18 22:55:46,171 - root - INFO - iteration 0: global_step=2; loss_value=1.950510
2018-09-18 22:55:46,173 - root - INFO - iteration 0: global_step=3; loss_value=1.910227
2018-09-18 22:55:46,177 - root - INFO - iteration 0: global_step=4; loss_value=1.148543
2018-09-18 22:55:46,181 - root - INFO - iteration 0: global_step=5; loss_value=1.241230
2018-09-18 22:55:46,185 - root - INFO - iteration 0: global_step=6; loss_value=1.046468
2018-09-18 22:55:46,188 - root - INFO - iteration 0: global_step=7; loss_value=0.767394
2018-09-18 22:55:46,194 - root - INFO - iteration 0: global_step=8; loss_value=0.846376
2018-09-18 22:55:46,196 - root - INFO - iteration 0: global_step=9; loss_value=0.478756
2018-09-18 22:55:46,198 - root - INFO - iteration 0: global_step=10; loss_value=0.864431
2018-09-18 22:55:46,207 - root - INFO - iteration 0: global_step=11; loss_value=0.770641
2018-09-18 22:55:46,208 - root - INFO - iteration 0: global_step=12; loss_value=0.709332
2018-09-18 22:55:46,210 - root - INFO - iteration 0: global_step=13; loss_value=0.495831
2018-09-18 22:55:46,215 - root - INFO - iteration 0: global_step=14; loss_value=0.628460
2018-09-18 22:55:46,217 - root - INFO - iteration 0: global_step=15; loss_value=0.481645
2018-09-18 22:55:46,221 - root - INFO - iteration 0: global_step=16; loss_value=0.514398
2018-09-18 22:55:46,224 - root - INFO - iteration 0: global_step=17; loss_value=0.643337
2018-09-18 22:55:46,228 - root - INFO - iteration 0: global_step=18; loss_value=0.465817
2018-09-18 22:55:46,233 - root - INFO - iteration 0: global_step=19; loss_value=0.318947
2018-09-18 22:55:46,239 - root - INFO - iteration 0: global_step=20; loss_value=0.589830
2018-09-18 22:55:46,243 - root - INFO - iteration 0: global_step=21; loss_value=0.487726
2018-09-18 22:55:46,247 - root - INFO - iteration 0: global_step=22; loss_value=0.524765
2018-09-18 22:55:46,253 - root - INFO - iteration 0: global_step=23; loss_value=0.291246
2018-09-18 22:55:46,261 - root - INFO - iteration 0: global_step=24; loss_value=0.260901
2018-09-18 22:55:46,267 - root - INFO - iteration 0: global_step=25; loss_value=0.335833
2018-09-18 22:55:46,272 - root - INFO - iteration 0: global_step=26; loss_value=0.446032
2018-09-18 22:55:46,277 - root - INFO - iteration 0: global_step=27; loss_value=0.553880
2018-09-18 22:55:46,281 - root - INFO - iteration 0: global_step=28; loss_value=0.568313
2018-09-18 22:55:46,285 - root - INFO - iteration 0: global_step=29; loss_value=0.595801
2018-09-18 22:55:46,289 - root - INFO - iteration 0: global_step=30; loss_value=0.429095
2018-09-18 22:55:46,293 - root - INFO - iteration 0: global_step=31; loss_value=0.502580
2018-09-18 22:55:46,297 - root - INFO - iteration 0: global_step=32; loss_value=0.730367
2018-09-18 22:55:46,302 - root - INFO - iteration 0: global_step=33; loss_value=0.468628
2018-09-18 22:55:46,306 - root - INFO - iteration 0: global_step=34; loss_value=0.276163
2018-09-18 22:55:46,312 - root - INFO - iteration 0: global_step=35; loss_value=0.475219
2018-09-18 22:55:46,314 - root - INFO - iteration 0: global_step=36; loss_value=0.410003
2018-09-18 22:55:46,318 - root - INFO - iteration 0: global_step=37; loss_value=0.471631
2018-09-18 22:55:46,320 - root - INFO - iteration 0: global_step=38; loss_value=0.460236
2018-09-18 22:55:46,325 - root - INFO - iteration 0: global_step=39; loss_value=0.557832
2018-09-18 22:55:46,331 - root - INFO - iteration 0: global_step=40; loss_value=0.567885
2018-09-18 22:55:46,333 - root - INFO - iteration 0: global_step=41; loss_value=0.314545
2018-09-18 22:55:46,334 - root - INFO - iteration 0: global_step=42; loss_value=0.261655
2018-09-18 22:55:46,339 - root - INFO - iteration 0: global_step=43; loss_value=0.432829
2018-09-18 22:55:46,342 - root - INFO - iteration 0: global_step=44; loss_value=0.251540
2018-09-18 22:55:46,347 - root - INFO - iteration 0: global_step=45; loss_value=0.533648
2018-09-18 22:55:46,351 - root - INFO - iteration 0: global_step=46; loss_value=0.245756
2018-09-18 22:55:46,353 - root - INFO - iteration 0: global_step=47; loss_value=0.457278
2018-09-18 22:55:46,357 - root - INFO - iteration 0: global_step=48; loss_value=0.341481
2018-09-18 22:55:46,361 - root - INFO - iteration 0: global_step=49; loss_value=0.320660
2018-09-18 22:55:46,365 - root - INFO - iteration 0: global_step=50; loss_value=0.196008
2018-09-18 22:55:46,369 - root - INFO - iteration 0: global_step=51; loss_value=0.378745
2018-09-18 22:55:46,373 - root - INFO - iteration 0: global_step=52; loss_value=0.311417
2018-09-18 22:55:46,376 - root - INFO - iteration 0: global_step=53; loss_value=0.394930
2018-09-18 22:55:46,381 - root - INFO - iteration 0: global_step=54; loss_value=0.344737
2018-09-18 22:55:46,385 - root - INFO - iteration 0: global_step=55; loss_value=0.342228
2018-09-18 22:55:46,388 - root - INFO - iteration 0: global_step=56; loss_value=0.251285
2018-09-18 22:55:46,396 - root - INFO - iteration 0: global_step=57; loss_value=0.489574
2018-09-18 22:55:46,400 - root - INFO - iteration 0: global_step=58; loss_value=0.457761
2018-09-18 22:55:46,406 - root - INFO - iteration 0: global_step=59; loss_value=0.152239
2018-09-18 22:55:46,413 - root - INFO - iteration 0: global_step=60; loss_value=0.700394
2018-09-18 22:55:46,416 - root - INFO - iteration 0: global_step=61; loss_value=0.300368
2018-09-18 22:55:46,422 - root - INFO - iteration 0: global_step=62; loss_value=0.369527
2018-09-18 22:55:46,429 - root - INFO - iteration 0: global_step=63; loss_value=0.267523
2018-09-18 22:55:46,430 - root - INFO - iteration 0: global_step=64; loss_value=0.325097
2018-09-18 22:55:46,436 - root - INFO - iteration 0: global_step=65; loss_value=0.294989
2018-09-18 22:55:46,438 - root - INFO - iteration 0: global_step=66; loss_value=0.187464
2018-09-18 22:55:46,442 - root - INFO - iteration 0: global_step=67; loss_value=0.317319
2018-09-18 22:55:46,447 - root - INFO - iteration 0: global_step=68; loss_value=0.487642
2018-09-18 22:55:46,449 - root - INFO - iteration 0: global_step=69; loss_value=0.295561
2018-09-18 22:55:46,453 - root - INFO - iteration 0: global_step=70; loss_value=0.162711
2018-09-18 22:55:46,459 - root - INFO - iteration 0: global_step=71; loss_value=0.469755
2018-09-18 22:55:46,461 - root - INFO - iteration 0: global_step=72; loss_value=0.252005
2018-09-18 22:55:46,463 - root - INFO - iteration 0: global_step=73; loss_value=0.364773
2018-09-18 22:55:46,469 - root - INFO - iteration 0: global_step=74; loss_value=0.451166
2018-09-18 22:55:46,470 - root - INFO - iteration 0: global_step=75; loss_value=0.355288
2018-09-18 22:55:46,474 - root - INFO - iteration 0: global_step=76; loss_value=0.409089
2018-09-18 22:55:46,479 - root - INFO - iteration 0: global_step=77; loss_value=0.407955
2018-09-18 22:55:46,483 - root - INFO - iteration 0: global_step=78; loss_value=0.205374
2018-09-18 22:55:46,485 - root - INFO - iteration 0: global_step=79; loss_value=0.419776
2018-09-18 22:55:46,489 - root - INFO - iteration 0: global_step=80; loss_value=0.465335
2018-09-18 22:55:46,493 - root - INFO - iteration 0: global_step=81; loss_value=0.286214
2018-09-18 22:55:46,497 - root - INFO - iteration 0: global_step=82; loss_value=0.264932
2018-09-18 22:55:46,500 - root - INFO - iteration 0: global_step=83; loss_value=0.269489
2018-09-18 22:55:46,505 - root - INFO - iteration 0: global_step=84; loss_value=0.281442
2018-09-18 22:55:46,509 - root - INFO - iteration 0: global_step=85; loss_value=0.357100
2018-09-18 22:55:46,512 - root - INFO - iteration 0: global_step=86; loss_value=0.485626
2018-09-18 22:55:46,523 - root - INFO - iteration 0: global_step=87; loss_value=0.277488
2018-09-18 22:55:46,525 - root - INFO - iteration 0: global_step=88; loss_value=0.110004
2018-09-18 22:55:46,529 - root - INFO - iteration 0: global_step=89; loss_value=0.272254
2018-09-18 22:55:46,533 - root - INFO - iteration 0: global_step=90; loss_value=0.248594
2018-09-18 22:55:46,537 - root - INFO - iteration 0: global_step=91; loss_value=0.250993
2018-09-18 22:55:46,543 - root - INFO - iteration 0: global_step=92; loss_value=0.350564
2018-09-18 22:55:46,545 - root - INFO - iteration 0: global_step=93; loss_value=0.316878
2018-09-18 22:55:46,557 - root - INFO - iteration 0: global_step=94; loss_value=0.216108
2018-09-18 22:55:46,563 - root - INFO - iteration 0: global_step=95; loss_value=0.285535
2018-09-18 22:55:46,569 - root - INFO - iteration 0: global_step=96; loss_value=0.302303
2018-09-18 22:55:46,574 - root - INFO - iteration 0: global_step=97; loss_value=0.182420
2018-09-18 22:55:46,579 - root - INFO - iteration 0: global_step=98; loss_value=0.410105
2018-09-18 22:55:46,586 - root - INFO - iteration 0: global_step=99; loss_value=0.396719
2018-09-18 22:55:46,591 - root - INFO - iteration 0: global_step=100; loss_value=0.269535
2018-09-18 22:55:48,505 - root - INFO - iteration 10: global_step=1001; loss_value=0.190077
2018-09-18 22:55:48,512 - root - INFO - iteration 10: global_step=1002; loss_value=0.098370
2018-09-18 22:55:48,518 - root - INFO - iteration 10: global_step=1003; loss_value=0.241997
2018-09-18 22:55:48,520 - root - INFO - iteration 10: global_step=1004; loss_value=0.281423
2018-09-18 22:55:48,522 - root - INFO - iteration 10: global_step=1005; loss_value=0.282174
2018-09-18 22:55:48,527 - root - INFO - iteration 10: global_step=1006; loss_value=0.187591
2018-09-18 22:55:48,529 - root - INFO - iteration 10: global_step=1007; loss_value=0.078650
2018-09-18 22:55:48,533 - root - INFO - iteration 10: global_step=1008; loss_value=0.190242
2018-09-18 22:55:48,537 - root - INFO - iteration 10: global_step=1009; loss_value=0.177919
2018-09-18 22:55:48,541 - root - INFO - iteration 10: global_step=1010; loss_value=0.139847
2018-09-18 22:55:48,546 - root - INFO - iteration 10: global_step=1011; loss_value=0.085694
2018-09-18 22:55:48,551 - root - INFO - iteration 10: global_step=1012; loss_value=0.200156
2018-09-18 22:55:48,555 - root - INFO - iteration 10: global_step=1013; loss_value=0.126116
2018-09-18 22:55:48,560 - root - INFO - iteration 10: global_step=1014; loss_value=0.181787
2018-09-18 22:55:48,562 - root - INFO - iteration 10: global_step=1015; loss_value=0.278877
2018-09-18 22:55:48,569 - root - INFO - iteration 10: global_step=1016; loss_value=0.151561
2018-09-18 22:55:48,573 - root - INFO - iteration 10: global_step=1017; loss_value=0.080012
2018-09-18 22:55:48,583 - root - INFO - iteration 10: global_step=1018; loss_value=0.204454
2018-09-18 22:55:48,590 - root - INFO - iteration 10: global_step=1019; loss_value=0.102707
2018-09-18 22:55:48,594 - root - INFO - iteration 10: global_step=1020; loss_value=0.325283
2018-09-18 22:55:48,600 - root - INFO - iteration 10: global_step=1021; loss_value=0.240193
2018-09-18 22:55:48,602 - root - INFO - iteration 10: global_step=1022; loss_value=0.251860
2018-09-18 22:55:48,607 - root - INFO - iteration 10: global_step=1023; loss_value=0.106332
2018-09-18 22:55:48,611 - root - INFO - iteration 10: global_step=1024; loss_value=0.049466
2018-09-18 22:55:48,615 - root - INFO - iteration 10: global_step=1025; loss_value=0.128977
2018-09-18 22:55:48,617 - root - INFO - iteration 10: global_step=1026; loss_value=0.041445
2018-09-18 22:55:48,623 - root - INFO - iteration 10: global_step=1027; loss_value=0.140913
2018-09-18 22:55:48,624 - root - INFO - iteration 10: global_step=1028; loss_value=0.147060
2018-09-18 22:55:48,629 - root - INFO - iteration 10: global_step=1029; loss_value=0.349742
2018-09-18 22:55:48,635 - root - INFO - iteration 10: global_step=1030; loss_value=0.292517
2018-09-18 22:55:48,637 - root - INFO - iteration 10: global_step=1031; loss_value=0.128832
2018-09-18 22:55:48,641 - root - INFO - iteration 10: global_step=1032; loss_value=0.253789
2018-09-18 22:55:48,645 - root - INFO - iteration 10: global_step=1033; loss_value=0.185026
2018-09-18 22:55:48,649 - root - INFO - iteration 10: global_step=1034; loss_value=0.154032
2018-09-18 22:55:48,652 - root - INFO - iteration 10: global_step=1035; loss_value=0.220276
2018-09-18 22:55:48,658 - root - INFO - iteration 10: global_step=1036; loss_value=0.032740
2018-09-18 22:55:48,660 - root - INFO - iteration 10: global_step=1037; loss_value=0.027709
2018-09-18 22:55:48,664 - root - INFO - iteration 10: global_step=1038; loss_value=0.159304
2018-09-18 22:55:48,669 - root - INFO - iteration 10: global_step=1039; loss_value=0.172471
2018-09-18 22:55:48,674 - root - INFO - iteration 10: global_step=1040; loss_value=0.294487
2018-09-18 22:55:48,685 - root - INFO - iteration 10: global_step=1041; loss_value=0.091160
2018-09-18 22:55:48,689 - root - INFO - iteration 10: global_step=1042; loss_value=0.292996
2018-09-18 22:55:48,699 - root - INFO - iteration 10: global_step=1043; loss_value=0.244810
2018-09-18 22:55:48,701 - root - INFO - iteration 10: global_step=1044; loss_value=0.139946
2018-09-18 22:55:48,703 - root - INFO - iteration 10: global_step=1045; loss_value=0.129689
2018-09-18 22:55:48,709 - root - INFO - iteration 10: global_step=1046; loss_value=0.078983
2018-09-18 22:55:48,711 - root - INFO - iteration 10: global_step=1047; loss_value=0.026641
2018-09-18 22:55:48,715 - root - INFO - iteration 10: global_step=1048; loss_value=0.165830
2018-09-18 22:55:48,720 - root - INFO - iteration 10: global_step=1049; loss_value=0.139048
2018-09-18 22:55:48,721 - root - INFO - iteration 10: global_step=1050; loss_value=0.250715
2018-09-18 22:55:48,727 - root - INFO - iteration 10: global_step=1051; loss_value=0.175715
2018-09-18 22:55:48,729 - root - INFO - iteration 10: global_step=1052; loss_value=0.120146
2018-09-18 22:55:48,733 - root - INFO - iteration 10: global_step=1053; loss_value=0.223429
2018-09-18 22:55:48,737 - root - INFO - iteration 10: global_step=1054; loss_value=0.047692
2018-09-18 22:55:48,741 - root - INFO - iteration 10: global_step=1055; loss_value=0.109181
2018-09-18 22:55:48,745 - root - INFO - iteration 10: global_step=1056; loss_value=0.034391
2018-09-18 22:55:48,750 - root - INFO - iteration 10: global_step=1057; loss_value=0.248459
2018-09-18 22:55:48,754 - root - INFO - iteration 10: global_step=1058; loss_value=0.079832
2018-09-18 22:55:48,758 - root - INFO - iteration 10: global_step=1059; loss_value=0.178706
2018-09-18 22:55:48,762 - root - INFO - iteration 10: global_step=1060; loss_value=0.203842
2018-09-18 22:55:48,768 - root - INFO - iteration 10: global_step=1061; loss_value=0.163378
2018-09-18 22:55:48,774 - root - INFO - iteration 10: global_step=1062; loss_value=0.216573
2018-09-18 22:55:48,783 - root - INFO - iteration 10: global_step=1063; loss_value=0.089899
2018-09-18 22:55:48,785 - root - INFO - iteration 10: global_step=1064; loss_value=0.089198
2018-09-18 22:55:48,787 - root - INFO - iteration 10: global_step=1065; loss_value=0.193538
2018-09-18 22:55:48,795 - root - INFO - iteration 10: global_step=1066; loss_value=0.232088
2018-09-18 22:55:48,799 - root - INFO - iteration 10: global_step=1067; loss_value=0.232186
2018-09-18 22:55:48,801 - root - INFO - iteration 10: global_step=1068; loss_value=0.065808
2018-09-18 22:55:48,805 - root - INFO - iteration 10: global_step=1069; loss_value=0.077752
2018-09-18 22:55:48,809 - root - INFO - iteration 10: global_step=1070; loss_value=0.111911
2018-09-18 22:55:48,813 - root - INFO - iteration 10: global_step=1071; loss_value=0.120567
2018-09-18 22:55:48,817 - root - INFO - iteration 10: global_step=1072; loss_value=0.070115
2018-09-18 22:55:48,821 - root - INFO - iteration 10: global_step=1073; loss_value=0.095027
2018-09-18 22:55:48,824 - root - INFO - iteration 10: global_step=1074; loss_value=0.093358
2018-09-18 22:55:48,829 - root - INFO - iteration 10: global_step=1075; loss_value=0.101910
2018-09-18 22:55:48,833 - root - INFO - iteration 10: global_step=1076; loss_value=0.281976
2018-09-18 22:55:48,835 - root - INFO - iteration 10: global_step=1077; loss_value=0.172226
2018-09-18 22:55:48,839 - root - INFO - iteration 10: global_step=1078; loss_value=0.128908
2018-09-18 22:55:48,843 - root - INFO - iteration 10: global_step=1079; loss_value=0.099559
2018-09-18 22:55:48,848 - root - INFO - iteration 10: global_step=1080; loss_value=0.131505
2018-09-18 22:55:48,852 - root - INFO - iteration 10: global_step=1081; loss_value=0.263254
2018-09-18 22:55:48,858 - root - INFO - iteration 10: global_step=1082; loss_value=0.363375
2018-09-18 22:55:48,866 - root - INFO - iteration 10: global_step=1083; loss_value=0.362041
2018-09-18 22:55:48,877 - root - INFO - iteration 10: global_step=1084; loss_value=0.284531
2018-09-18 22:55:48,879 - root - INFO - iteration 10: global_step=1085; loss_value=0.183869
2018-09-18 22:55:48,884 - root - INFO - iteration 10: global_step=1086; loss_value=0.261233
2018-09-18 22:55:48,892 - root - INFO - iteration 10: global_step=1087; loss_value=0.163654
2018-09-18 22:55:48,894 - root - INFO - iteration 10: global_step=1088; loss_value=0.067419
2018-09-18 22:55:48,895 - root - INFO - iteration 10: global_step=1089; loss_value=0.125264
2018-09-18 22:55:48,901 - root - INFO - iteration 10: global_step=1090; loss_value=0.097911
2018-09-18 22:55:48,903 - root - INFO - iteration 10: global_step=1091; loss_value=0.106180
2018-09-18 22:55:48,907 - root - INFO - iteration 10: global_step=1092; loss_value=0.368431
2018-09-18 22:55:48,912 - root - INFO - iteration 10: global_step=1093; loss_value=0.098651
2018-09-18 22:55:48,915 - root - INFO - iteration 10: global_step=1094; loss_value=0.216523
2018-09-18 22:55:48,921 - root - INFO - iteration 10: global_step=1095; loss_value=0.175091
2018-09-18 22:55:48,930 - root - INFO - iteration 10: global_step=1096; loss_value=0.146928
2018-09-18 22:55:48,932 - root - INFO - iteration 10: global_step=1097; loss_value=0.205410
2018-09-18 22:55:48,938 - root - INFO - iteration 10: global_step=1098; loss_value=0.073953
2018-09-18 22:55:48,945 - root - INFO - iteration 10: global_step=1099; loss_value=0.380443
2018-09-18 22:55:48,950 - root - INFO - iteration 10: global_step=1100; loss_value=0.279760
2018-09-18 23:13:50,187 - root - INFO - lr             :	0.02
2018-09-18 23:13:50,188 - root - INFO - dr             :	0.96
2018-09-18 23:13:50,188 - root - INFO - ds             :	100
2018-09-18 23:13:50,188 - root - INFO - edr            :	0.99
2018-09-18 23:13:50,188 - root - INFO - lp             :	0.3
2018-09-18 23:13:50,188 - root - INFO - bs             :	100
2018-09-18 23:13:50,188 - root - INFO - clip           :	5
2018-09-18 23:13:50,188 - root - INFO - epoch          :	20
2018-09-18 23:13:50,188 - root - INFO - layer1_units   :	50
2018-09-18 23:13:50,189 - root - INFO - layer2_units   :	10
2018-09-18 23:13:50,190 - root - INFO - input_dimension:	784
2018-09-18 23:13:50,190 - root - INFO - num_tags       :	10
2018-09-18 23:13:50,190 - root - INFO - opt            :	Adam
2018-09-18 23:13:50,965 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 23:13:51,081 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-18 23:13:51,083 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 23:13:52,019 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 23:13:52,029 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-18 23:13:52,222 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 23:13:54,596 - root - INFO - iteration 0: global_step=1; loss_value=2.434890
2018-09-18 23:13:54,597 - root - INFO - iteration 0: global_step=2; loss_value=1.784064
2018-09-18 23:13:54,599 - root - INFO - iteration 0: global_step=3; loss_value=1.093638
2018-09-18 23:13:54,603 - root - INFO - iteration 0: global_step=4; loss_value=1.059539
2018-09-18 23:13:54,607 - root - INFO - iteration 0: global_step=5; loss_value=0.876226
2018-09-18 23:13:54,613 - root - INFO - iteration 0: global_step=6; loss_value=0.696887
2018-09-18 23:13:54,614 - root - INFO - iteration 0: global_step=7; loss_value=0.917144
2018-09-18 23:13:54,618 - root - INFO - iteration 0: global_step=8; loss_value=0.881952
2018-09-18 23:13:54,622 - root - INFO - iteration 0: global_step=9; loss_value=0.589771
2018-09-18 23:13:54,629 - root - INFO - iteration 0: global_step=10; loss_value=0.614358
2018-09-18 23:13:54,630 - root - INFO - iteration 0: global_step=11; loss_value=0.494343
2018-09-18 23:13:54,632 - root - INFO - iteration 0: global_step=12; loss_value=0.672344
2018-09-18 23:13:54,637 - root - INFO - iteration 0: global_step=13; loss_value=0.494433
2018-09-18 23:13:54,639 - root - INFO - iteration 0: global_step=14; loss_value=0.653663
2018-09-18 23:13:54,645 - root - INFO - iteration 0: global_step=15; loss_value=0.657923
2018-09-18 23:13:54,649 - root - INFO - iteration 0: global_step=16; loss_value=0.394349
2018-09-18 23:13:54,652 - root - INFO - iteration 0: global_step=17; loss_value=0.428312
2018-09-18 23:13:54,656 - root - INFO - iteration 0: global_step=18; loss_value=0.326809
2018-09-18 23:13:54,661 - root - INFO - iteration 0: global_step=19; loss_value=0.513087
2018-09-18 23:13:54,663 - root - INFO - iteration 0: global_step=20; loss_value=0.698197
2018-09-18 23:13:54,666 - root - INFO - iteration 0: global_step=21; loss_value=0.486759
2018-09-18 23:13:54,670 - root - INFO - iteration 0: global_step=22; loss_value=0.367855
2018-09-18 23:13:54,674 - root - INFO - iteration 0: global_step=23; loss_value=0.478005
2018-09-18 23:13:54,678 - root - INFO - iteration 0: global_step=24; loss_value=0.421829
2018-09-18 23:13:54,683 - root - INFO - iteration 0: global_step=25; loss_value=0.707239
2018-09-18 23:13:54,686 - root - INFO - iteration 0: global_step=26; loss_value=0.608263
2018-09-18 23:13:54,690 - root - INFO - iteration 0: global_step=27; loss_value=0.548782
2018-09-18 23:13:54,695 - root - INFO - iteration 0: global_step=28; loss_value=0.607627
2018-09-18 23:13:54,699 - root - INFO - iteration 0: global_step=29; loss_value=0.324690
2018-09-18 23:13:54,705 - root - INFO - iteration 0: global_step=30; loss_value=0.429545
2018-09-18 23:13:54,713 - root - INFO - iteration 0: global_step=31; loss_value=0.338183
2018-09-18 23:13:54,716 - root - INFO - iteration 0: global_step=32; loss_value=0.375604
2018-09-18 23:13:54,722 - root - INFO - iteration 0: global_step=33; loss_value=0.424268
2018-09-18 23:13:54,728 - root - INFO - iteration 0: global_step=34; loss_value=0.378785
2018-09-18 23:13:54,730 - root - INFO - iteration 0: global_step=35; loss_value=0.292439
2018-09-18 23:13:54,732 - root - INFO - iteration 0: global_step=36; loss_value=0.537489
2018-09-18 23:13:54,738 - root - INFO - iteration 0: global_step=37; loss_value=0.569297
2018-09-18 23:13:54,740 - root - INFO - iteration 0: global_step=38; loss_value=0.356275
2018-09-18 23:13:54,745 - root - INFO - iteration 0: global_step=39; loss_value=0.286414
2018-09-18 23:13:54,747 - root - INFO - iteration 0: global_step=40; loss_value=0.216716
2018-09-18 23:13:54,752 - root - INFO - iteration 0: global_step=41; loss_value=0.269219
2018-09-18 23:13:54,754 - root - INFO - iteration 0: global_step=42; loss_value=0.276947
2018-09-18 23:13:54,760 - root - INFO - iteration 0: global_step=43; loss_value=0.353457
2018-09-18 23:13:54,762 - root - INFO - iteration 0: global_step=44; loss_value=0.299893
2018-09-18 23:13:54,766 - root - INFO - iteration 0: global_step=45; loss_value=0.325707
2018-09-18 23:13:54,770 - root - INFO - iteration 0: global_step=46; loss_value=0.192380
2018-09-18 23:13:54,773 - root - INFO - iteration 0: global_step=47; loss_value=0.456912
2018-09-18 23:13:54,778 - root - INFO - iteration 0: global_step=48; loss_value=0.325492
2018-09-18 23:13:54,784 - root - INFO - iteration 0: global_step=49; loss_value=0.268908
2018-09-18 23:13:54,786 - root - INFO - iteration 0: global_step=50; loss_value=0.232317
2018-09-18 23:13:54,788 - root - INFO - iteration 0: global_step=51; loss_value=0.489734
2018-09-18 23:13:54,792 - root - INFO - iteration 0: global_step=52; loss_value=0.309693
2018-09-18 23:13:54,796 - root - INFO - iteration 0: global_step=53; loss_value=0.235906
2018-09-18 23:13:54,802 - root - INFO - iteration 0: global_step=54; loss_value=0.301213
2018-09-18 23:13:54,804 - root - INFO - iteration 0: global_step=55; loss_value=0.390505
2018-09-18 23:13:54,808 - root - INFO - iteration 0: global_step=56; loss_value=0.336767
2018-09-18 23:13:54,812 - root - INFO - iteration 0: global_step=57; loss_value=0.286764
2018-09-18 23:13:54,819 - root - INFO - iteration 0: global_step=58; loss_value=0.646618
2018-09-18 23:13:54,824 - root - INFO - iteration 0: global_step=59; loss_value=0.318641
2018-09-18 23:13:54,828 - root - INFO - iteration 0: global_step=60; loss_value=0.290853
2018-09-18 23:13:54,833 - root - INFO - iteration 0: global_step=61; loss_value=0.230626
2018-09-18 23:13:54,844 - root - INFO - iteration 0: global_step=62; loss_value=0.333231
2018-09-18 23:13:54,846 - root - INFO - iteration 0: global_step=63; loss_value=0.439214
2018-09-18 23:13:54,848 - root - INFO - iteration 0: global_step=64; loss_value=0.313234
2018-09-18 23:13:54,853 - root - INFO - iteration 0: global_step=65; loss_value=0.471278
2018-09-18 23:13:54,855 - root - INFO - iteration 0: global_step=66; loss_value=0.302323
2018-09-18 23:13:54,859 - root - INFO - iteration 0: global_step=67; loss_value=0.398526
2018-09-18 23:13:54,864 - root - INFO - iteration 0: global_step=68; loss_value=0.230399
2018-09-18 23:13:54,868 - root - INFO - iteration 0: global_step=69; loss_value=0.387723
2018-09-18 23:13:54,870 - root - INFO - iteration 0: global_step=70; loss_value=0.505302
2018-09-18 23:13:54,874 - root - INFO - iteration 0: global_step=71; loss_value=0.322991
2018-09-18 23:13:54,878 - root - INFO - iteration 0: global_step=72; loss_value=0.294038
2018-09-18 23:13:54,885 - root - INFO - iteration 0: global_step=73; loss_value=0.406395
2018-09-18 23:13:54,887 - root - INFO - iteration 0: global_step=74; loss_value=0.420350
2018-09-18 23:13:54,889 - root - INFO - iteration 0: global_step=75; loss_value=0.225839
2018-09-18 23:13:54,894 - root - INFO - iteration 0: global_step=76; loss_value=0.430899
2018-09-18 23:13:54,900 - root - INFO - iteration 0: global_step=77; loss_value=0.258396
2018-09-18 23:13:54,902 - root - INFO - iteration 0: global_step=78; loss_value=0.362058
2018-09-18 23:13:54,904 - root - INFO - iteration 0: global_step=79; loss_value=0.234954
2018-09-18 23:13:54,909 - root - INFO - iteration 0: global_step=80; loss_value=0.284587
2018-09-18 23:13:54,914 - root - INFO - iteration 0: global_step=81; loss_value=0.309840
2018-09-18 23:13:54,918 - root - INFO - iteration 0: global_step=82; loss_value=0.284759
2018-09-18 23:13:54,922 - root - INFO - iteration 0: global_step=83; loss_value=0.163869
2018-09-18 23:13:54,926 - root - INFO - iteration 0: global_step=84; loss_value=0.307459
2018-09-18 23:13:54,932 - root - INFO - iteration 0: global_step=85; loss_value=0.407833
2018-09-18 23:13:54,934 - root - INFO - iteration 0: global_step=86; loss_value=0.255074
2018-09-18 23:13:54,936 - root - INFO - iteration 0: global_step=87; loss_value=0.247072
2018-09-18 23:13:54,940 - root - INFO - iteration 0: global_step=88; loss_value=0.290731
2018-09-18 23:13:54,944 - root - INFO - iteration 0: global_step=89; loss_value=0.319727
2018-09-18 23:13:54,946 - root - INFO - iteration 0: global_step=90; loss_value=0.295221
2018-09-18 23:13:54,950 - root - INFO - iteration 0: global_step=91; loss_value=0.354098
2018-09-18 23:13:54,954 - root - INFO - iteration 0: global_step=92; loss_value=0.291363
2018-09-18 23:13:54,958 - root - INFO - iteration 0: global_step=93; loss_value=0.276284
2018-09-18 23:13:54,962 - root - INFO - iteration 0: global_step=94; loss_value=0.435668
2018-09-18 23:13:54,966 - root - INFO - iteration 0: global_step=95; loss_value=0.439036
2018-09-18 23:13:54,971 - root - INFO - iteration 0: global_step=96; loss_value=0.295105
2018-09-18 23:13:54,973 - root - INFO - iteration 0: global_step=97; loss_value=0.242181
2018-09-18 23:13:54,976 - root - INFO - iteration 0: global_step=98; loss_value=0.199430
2018-09-18 23:13:54,980 - root - INFO - iteration 0: global_step=99; loss_value=0.158040
2018-09-18 23:13:54,983 - root - INFO - iteration 0: global_step=100; loss_value=0.329251
2018-09-18 23:13:58,677 - root - INFO - iteration 10: global_step=1001; loss_value=0.074918
2018-09-18 23:13:58,683 - root - INFO - iteration 10: global_step=1002; loss_value=0.179879
2018-09-18 23:13:58,689 - root - INFO - iteration 10: global_step=1003; loss_value=0.183338
2018-09-18 23:13:58,694 - root - INFO - iteration 10: global_step=1004; loss_value=0.040314
2018-09-18 23:13:58,699 - root - INFO - iteration 10: global_step=1005; loss_value=0.278616
2018-09-18 23:13:58,701 - root - INFO - iteration 10: global_step=1006; loss_value=0.112375
2018-09-18 23:13:58,704 - root - INFO - iteration 10: global_step=1007; loss_value=0.157178
2018-09-18 23:13:58,710 - root - INFO - iteration 10: global_step=1008; loss_value=0.249114
2018-09-18 23:13:58,712 - root - INFO - iteration 10: global_step=1009; loss_value=0.099332
2018-09-18 23:13:58,716 - root - INFO - iteration 10: global_step=1010; loss_value=0.260998
2018-09-18 23:13:58,718 - root - INFO - iteration 10: global_step=1011; loss_value=0.367293
2018-09-18 23:13:58,722 - root - INFO - iteration 10: global_step=1012; loss_value=0.248073
2018-09-18 23:13:58,726 - root - INFO - iteration 10: global_step=1013; loss_value=0.182082
2018-09-18 23:13:58,730 - root - INFO - iteration 10: global_step=1014; loss_value=0.245832
2018-09-18 23:13:58,734 - root - INFO - iteration 10: global_step=1015; loss_value=0.160232
2018-09-18 23:13:58,738 - root - INFO - iteration 10: global_step=1016; loss_value=0.032455
2018-09-18 23:13:58,740 - root - INFO - iteration 10: global_step=1017; loss_value=0.128422
2018-09-18 23:13:58,744 - root - INFO - iteration 10: global_step=1018; loss_value=0.183587
2018-09-18 23:13:58,748 - root - INFO - iteration 10: global_step=1019; loss_value=0.256650
2018-09-18 23:13:58,754 - root - INFO - iteration 10: global_step=1020; loss_value=0.234710
2018-09-18 23:13:58,756 - root - INFO - iteration 10: global_step=1021; loss_value=0.308316
2018-09-18 23:13:58,761 - root - INFO - iteration 10: global_step=1022; loss_value=0.082752
2018-09-18 23:13:58,767 - root - INFO - iteration 10: global_step=1023; loss_value=0.046804
2018-09-18 23:13:58,769 - root - INFO - iteration 10: global_step=1024; loss_value=0.319601
2018-09-18 23:13:58,771 - root - INFO - iteration 10: global_step=1025; loss_value=0.296957
2018-09-18 23:13:58,776 - root - INFO - iteration 10: global_step=1026; loss_value=0.443247
2018-09-18 23:13:58,779 - root - INFO - iteration 10: global_step=1027; loss_value=0.098444
2018-09-18 23:13:58,784 - root - INFO - iteration 10: global_step=1028; loss_value=0.114586
2018-09-18 23:13:58,788 - root - INFO - iteration 10: global_step=1029; loss_value=0.308240
2018-09-18 23:13:58,792 - root - INFO - iteration 10: global_step=1030; loss_value=0.190635
2018-09-18 23:13:58,798 - root - INFO - iteration 10: global_step=1031; loss_value=0.186014
2018-09-18 23:13:58,802 - root - INFO - iteration 10: global_step=1032; loss_value=0.277150
2018-09-18 23:13:58,805 - root - INFO - iteration 10: global_step=1033; loss_value=0.138428
2018-09-18 23:13:58,811 - root - INFO - iteration 10: global_step=1034; loss_value=0.306483
2018-09-18 23:13:58,818 - root - INFO - iteration 10: global_step=1035; loss_value=0.331577
2018-09-18 23:13:58,820 - root - INFO - iteration 10: global_step=1036; loss_value=0.041120
2018-09-18 23:13:58,822 - root - INFO - iteration 10: global_step=1037; loss_value=0.151023
2018-09-18 23:13:58,832 - root - INFO - iteration 10: global_step=1038; loss_value=0.146855
2018-09-18 23:13:58,834 - root - INFO - iteration 10: global_step=1039; loss_value=0.188550
2018-09-18 23:13:58,838 - root - INFO - iteration 10: global_step=1040; loss_value=0.163176
2018-09-18 23:13:58,842 - root - INFO - iteration 10: global_step=1041; loss_value=0.082546
2018-09-18 23:13:58,843 - root - INFO - iteration 10: global_step=1042; loss_value=0.310867
2018-09-18 23:13:58,852 - root - INFO - iteration 10: global_step=1043; loss_value=0.252731
2018-09-18 23:13:58,858 - root - INFO - iteration 10: global_step=1044; loss_value=0.038285
2018-09-18 23:13:58,860 - root - INFO - iteration 10: global_step=1045; loss_value=0.162217
2018-09-18 23:13:58,866 - root - INFO - iteration 10: global_step=1046; loss_value=0.151895
2018-09-18 23:13:58,872 - root - INFO - iteration 10: global_step=1047; loss_value=0.115624
2018-09-18 23:13:58,874 - root - INFO - iteration 10: global_step=1048; loss_value=0.177448
2018-09-18 23:13:58,880 - root - INFO - iteration 10: global_step=1049; loss_value=0.125739
2018-09-18 23:13:58,882 - root - INFO - iteration 10: global_step=1050; loss_value=0.221731
2018-09-18 23:13:58,883 - root - INFO - iteration 10: global_step=1051; loss_value=0.124755
2018-09-18 23:13:58,889 - root - INFO - iteration 10: global_step=1052; loss_value=0.140992
2018-09-18 23:13:58,891 - root - INFO - iteration 10: global_step=1053; loss_value=0.240790
2018-09-18 23:13:58,896 - root - INFO - iteration 10: global_step=1054; loss_value=0.157813
2018-09-18 23:13:58,898 - root - INFO - iteration 10: global_step=1055; loss_value=0.113290
2018-09-18 23:13:58,904 - root - INFO - iteration 10: global_step=1056; loss_value=0.171928
2018-09-18 23:13:58,906 - root - INFO - iteration 10: global_step=1057; loss_value=0.119196
2018-09-18 23:13:58,909 - root - INFO - iteration 10: global_step=1058; loss_value=0.241173
2018-09-18 23:13:58,917 - root - INFO - iteration 10: global_step=1059; loss_value=0.100292
2018-09-18 23:13:58,919 - root - INFO - iteration 10: global_step=1060; loss_value=0.151343
2018-09-18 23:13:58,924 - root - INFO - iteration 10: global_step=1061; loss_value=0.077151
2018-09-18 23:13:58,926 - root - INFO - iteration 10: global_step=1062; loss_value=0.178424
2018-09-18 23:13:58,932 - root - INFO - iteration 10: global_step=1063; loss_value=0.316255
2018-09-18 23:13:58,934 - root - INFO - iteration 10: global_step=1064; loss_value=0.137861
2018-09-18 23:13:58,935 - root - INFO - iteration 10: global_step=1065; loss_value=0.128336
2018-09-18 23:13:58,940 - root - INFO - iteration 10: global_step=1066; loss_value=0.123669
2018-09-18 23:13:58,945 - root - INFO - iteration 10: global_step=1067; loss_value=0.156721
2018-09-18 23:13:58,947 - root - INFO - iteration 10: global_step=1068; loss_value=0.238344
2018-09-18 23:13:58,953 - root - INFO - iteration 10: global_step=1069; loss_value=0.213917
2018-09-18 23:13:58,955 - root - INFO - iteration 10: global_step=1070; loss_value=0.114176
2018-09-18 23:13:58,959 - root - INFO - iteration 10: global_step=1071; loss_value=0.282156
2018-09-18 23:13:58,961 - root - INFO - iteration 10: global_step=1072; loss_value=0.040702
2018-09-18 23:13:58,966 - root - INFO - iteration 10: global_step=1073; loss_value=0.132341
2018-09-18 23:13:58,971 - root - INFO - iteration 10: global_step=1074; loss_value=0.165453
2018-09-18 23:13:58,973 - root - INFO - iteration 10: global_step=1075; loss_value=0.221502
2018-09-18 23:13:58,978 - root - INFO - iteration 10: global_step=1076; loss_value=0.149192
2018-09-18 23:13:58,982 - root - INFO - iteration 10: global_step=1077; loss_value=0.160922
2018-09-18 23:13:58,987 - root - INFO - iteration 10: global_step=1078; loss_value=0.320453
2018-09-18 23:13:58,991 - root - INFO - iteration 10: global_step=1079; loss_value=0.149908
2018-09-18 23:13:59,000 - root - INFO - iteration 10: global_step=1080; loss_value=0.209585
2018-09-18 23:13:59,009 - root - INFO - iteration 10: global_step=1081; loss_value=0.218923
2018-09-18 23:13:59,011 - root - INFO - iteration 10: global_step=1082; loss_value=0.231301
2018-09-18 23:13:59,013 - root - INFO - iteration 10: global_step=1083; loss_value=0.174930
2018-09-18 23:13:59,016 - root - INFO - iteration 10: global_step=1084; loss_value=0.078799
2018-09-18 23:13:59,022 - root - INFO - iteration 10: global_step=1085; loss_value=0.262674
2018-09-18 23:13:59,024 - root - INFO - iteration 10: global_step=1086; loss_value=0.105549
2018-09-18 23:13:59,030 - root - INFO - iteration 10: global_step=1087; loss_value=0.345421
2018-09-18 23:13:59,032 - root - INFO - iteration 10: global_step=1088; loss_value=0.221215
2018-09-18 23:13:59,036 - root - INFO - iteration 10: global_step=1089; loss_value=0.135990
2018-09-18 23:13:59,038 - root - INFO - iteration 10: global_step=1090; loss_value=0.067542
2018-09-18 23:13:59,044 - root - INFO - iteration 10: global_step=1091; loss_value=0.169697
2018-09-18 23:13:59,046 - root - INFO - iteration 10: global_step=1092; loss_value=0.176074
2018-09-18 23:13:59,050 - root - INFO - iteration 10: global_step=1093; loss_value=0.039021
2018-09-18 23:13:59,054 - root - INFO - iteration 10: global_step=1094; loss_value=0.168862
2018-09-18 23:13:59,058 - root - INFO - iteration 10: global_step=1095; loss_value=0.204963
2018-09-18 23:13:59,062 - root - INFO - iteration 10: global_step=1096; loss_value=0.166392
2018-09-18 23:13:59,066 - root - INFO - iteration 10: global_step=1097; loss_value=0.102370
2018-09-18 23:13:59,070 - root - INFO - iteration 10: global_step=1098; loss_value=0.165997
2018-09-18 23:13:59,075 - root - INFO - iteration 10: global_step=1099; loss_value=0.097147
2018-09-18 23:13:59,077 - root - INFO - iteration 10: global_step=1100; loss_value=0.197683
2018-09-18 23:21:24,017 - root - INFO - lr             :	0.02
2018-09-18 23:21:24,019 - root - INFO - dr             :	0.96
2018-09-18 23:21:24,023 - root - INFO - ds             :	100
2018-09-18 23:21:24,023 - root - INFO - edr            :	0.99
2018-09-18 23:21:24,023 - root - INFO - lp             :	0.3
2018-09-18 23:21:24,023 - root - INFO - bs             :	100
2018-09-18 23:21:24,023 - root - INFO - clip           :	5
2018-09-18 23:21:24,023 - root - INFO - epoch          :	20
2018-09-18 23:21:24,023 - root - INFO - layer1_units   :	50
2018-09-18 23:21:24,023 - root - INFO - layer2_units   :	10
2018-09-18 23:21:24,023 - root - INFO - input_dimension:	784
2018-09-18 23:21:24,024 - root - INFO - num_tags       :	10
2018-09-18 23:21:24,024 - root - INFO - opt            :	Adam
2018-09-18 23:21:24,369 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 23:21:24,486 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-18 23:21:24,496 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 23:21:24,857 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 23:21:24,864 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-18 23:21:24,985 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 23:21:26,045 - root - INFO - iteration 0: global_step=1; loss_value=2.491186
2018-09-18 23:21:26,053 - root - INFO - iteration 0: global_step=2; loss_value=2.753539
2018-09-18 23:21:26,055 - root - INFO - iteration 0: global_step=3; loss_value=1.896139
2018-09-18 23:21:26,062 - root - INFO - iteration 0: global_step=4; loss_value=1.754207
2018-09-18 23:21:26,064 - root - INFO - iteration 0: global_step=5; loss_value=1.544918
2018-09-18 23:21:26,068 - root - INFO - iteration 0: global_step=6; loss_value=1.317911
2018-09-18 23:21:26,072 - root - INFO - iteration 0: global_step=7; loss_value=1.274805
2018-09-18 23:21:26,078 - root - INFO - iteration 0: global_step=8; loss_value=1.165841
2018-09-18 23:21:26,080 - root - INFO - iteration 0: global_step=9; loss_value=0.974482
2018-09-18 23:21:26,083 - root - INFO - iteration 0: global_step=10; loss_value=1.046214
2018-09-18 23:21:26,088 - root - INFO - iteration 0: global_step=11; loss_value=0.912215
2018-09-18 23:21:26,094 - root - INFO - iteration 0: global_step=12; loss_value=0.741415
2018-09-18 23:21:26,102 - root - INFO - iteration 0: global_step=13; loss_value=0.785282
2018-09-18 23:21:26,111 - root - INFO - iteration 0: global_step=14; loss_value=0.814666
2018-09-18 23:21:26,115 - root - INFO - iteration 0: global_step=15; loss_value=0.473972
2018-09-18 23:21:26,120 - root - INFO - iteration 0: global_step=16; loss_value=0.574475
2018-09-18 23:21:26,121 - root - INFO - iteration 0: global_step=17; loss_value=0.435976
2018-09-18 23:21:26,126 - root - INFO - iteration 0: global_step=18; loss_value=0.768094
2018-09-18 23:21:26,133 - root - INFO - iteration 0: global_step=19; loss_value=0.545487
2018-09-18 23:21:26,134 - root - INFO - iteration 0: global_step=20; loss_value=0.420851
2018-09-18 23:21:26,139 - root - INFO - iteration 0: global_step=21; loss_value=0.369969
2018-09-18 23:21:26,141 - root - INFO - iteration 0: global_step=22; loss_value=0.530322
2018-09-18 23:21:26,145 - root - INFO - iteration 0: global_step=23; loss_value=0.494088
2018-09-18 23:21:26,149 - root - INFO - iteration 0: global_step=24; loss_value=0.480039
2018-09-18 23:21:26,154 - root - INFO - iteration 0: global_step=25; loss_value=0.355810
2018-09-18 23:21:26,155 - root - INFO - iteration 0: global_step=26; loss_value=0.636719
2018-09-18 23:21:26,162 - root - INFO - iteration 0: global_step=27; loss_value=0.329507
2018-09-18 23:21:26,166 - root - INFO - iteration 0: global_step=28; loss_value=0.578273
2018-09-18 23:21:26,170 - root - INFO - iteration 0: global_step=29; loss_value=0.358216
2018-09-18 23:21:26,174 - root - INFO - iteration 0: global_step=30; loss_value=0.383323
2018-09-18 23:21:26,179 - root - INFO - iteration 0: global_step=31; loss_value=0.327559
2018-09-18 23:21:26,183 - root - INFO - iteration 0: global_step=32; loss_value=0.524596
2018-09-18 23:21:26,191 - root - INFO - iteration 0: global_step=33; loss_value=0.554337
2018-09-18 23:21:26,200 - root - INFO - iteration 0: global_step=34; loss_value=0.398105
2018-09-18 23:21:26,202 - root - INFO - iteration 0: global_step=35; loss_value=0.448843
2018-09-18 23:21:26,203 - root - INFO - iteration 0: global_step=36; loss_value=0.615439
2018-09-18 23:21:26,210 - root - INFO - iteration 0: global_step=37; loss_value=0.367785
2018-09-18 23:21:26,211 - root - INFO - iteration 0: global_step=38; loss_value=0.289146
2018-09-18 23:21:26,215 - root - INFO - iteration 0: global_step=39; loss_value=0.225543
2018-09-18 23:21:26,221 - root - INFO - iteration 0: global_step=40; loss_value=0.456331
2018-09-18 23:21:26,223 - root - INFO - iteration 0: global_step=41; loss_value=0.457609
2018-09-18 23:21:26,229 - root - INFO - iteration 0: global_step=42; loss_value=0.391366
2018-09-18 23:21:26,231 - root - INFO - iteration 0: global_step=43; loss_value=0.255638
2018-09-18 23:21:26,239 - root - INFO - iteration 0: global_step=44; loss_value=0.457377
2018-09-18 23:21:26,241 - root - INFO - iteration 0: global_step=45; loss_value=0.285564
2018-09-18 23:21:26,242 - root - INFO - iteration 0: global_step=46; loss_value=0.367897
2018-09-18 23:21:26,247 - root - INFO - iteration 0: global_step=47; loss_value=0.331687
2018-09-18 23:21:26,251 - root - INFO - iteration 0: global_step=48; loss_value=0.475642
2018-09-18 23:21:26,255 - root - INFO - iteration 0: global_step=49; loss_value=0.278619
2018-09-18 23:21:26,260 - root - INFO - iteration 0: global_step=50; loss_value=0.535586
2018-09-18 23:21:26,266 - root - INFO - iteration 0: global_step=51; loss_value=0.680570
2018-09-18 23:21:26,270 - root - INFO - iteration 0: global_step=52; loss_value=0.349631
2018-09-18 23:21:26,279 - root - INFO - iteration 0: global_step=53; loss_value=0.209160
2018-09-18 23:21:26,281 - root - INFO - iteration 0: global_step=54; loss_value=0.305751
2018-09-18 23:21:26,285 - root - INFO - iteration 0: global_step=55; loss_value=0.339471
2018-09-18 23:21:26,289 - root - INFO - iteration 0: global_step=56; loss_value=0.455227
2018-09-18 23:21:26,299 - root - INFO - iteration 0: global_step=57; loss_value=0.332842
2018-09-18 23:21:26,301 - root - INFO - iteration 0: global_step=58; loss_value=0.355843
2018-09-18 23:21:26,303 - root - INFO - iteration 0: global_step=59; loss_value=0.366716
2018-09-18 23:21:26,310 - root - INFO - iteration 0: global_step=60; loss_value=0.513853
2018-09-18 23:21:26,311 - root - INFO - iteration 0: global_step=61; loss_value=0.426071
2018-09-18 23:21:26,316 - root - INFO - iteration 0: global_step=62; loss_value=0.326915
2018-09-18 23:21:26,318 - root - INFO - iteration 0: global_step=63; loss_value=0.300145
2018-09-18 23:21:26,321 - root - INFO - iteration 0: global_step=64; loss_value=0.396700
2018-09-18 23:21:26,325 - root - INFO - iteration 0: global_step=65; loss_value=0.169955
2018-09-18 23:21:26,329 - root - INFO - iteration 0: global_step=66; loss_value=0.212236
2018-09-18 23:21:26,333 - root - INFO - iteration 0: global_step=67; loss_value=0.439461
2018-09-18 23:21:26,337 - root - INFO - iteration 0: global_step=68; loss_value=0.326173
2018-09-18 23:21:26,342 - root - INFO - iteration 0: global_step=69; loss_value=0.301603
2018-09-18 23:21:26,346 - root - INFO - iteration 0: global_step=70; loss_value=0.296108
2018-09-18 23:21:26,351 - root - INFO - iteration 0: global_step=71; loss_value=0.285615
2018-09-18 23:21:26,354 - root - INFO - iteration 0: global_step=72; loss_value=0.384469
2018-09-18 23:21:26,358 - root - INFO - iteration 0: global_step=73; loss_value=0.356472
2018-09-18 23:21:26,365 - root - INFO - iteration 0: global_step=74; loss_value=0.132888
2018-09-18 23:21:26,373 - root - INFO - iteration 0: global_step=75; loss_value=0.221731
2018-09-18 23:21:26,380 - root - INFO - iteration 0: global_step=76; loss_value=0.235459
2018-09-18 23:21:26,382 - root - INFO - iteration 0: global_step=77; loss_value=0.342979
2018-09-18 23:21:26,383 - root - INFO - iteration 0: global_step=78; loss_value=0.169753
2018-09-18 23:21:26,388 - root - INFO - iteration 0: global_step=79; loss_value=0.339924
2018-09-18 23:21:26,392 - root - INFO - iteration 0: global_step=80; loss_value=0.248300
2018-09-18 23:21:26,397 - root - INFO - iteration 0: global_step=81; loss_value=0.359138
2018-09-18 23:21:26,399 - root - INFO - iteration 0: global_step=82; loss_value=0.456454
2018-09-18 23:21:26,403 - root - INFO - iteration 0: global_step=83; loss_value=0.133592
2018-09-18 23:21:26,408 - root - INFO - iteration 0: global_step=84; loss_value=0.491474
2018-09-18 23:21:26,410 - root - INFO - iteration 0: global_step=85; loss_value=0.220852
2018-09-18 23:21:26,413 - root - INFO - iteration 0: global_step=86; loss_value=0.295546
2018-09-18 23:21:26,417 - root - INFO - iteration 0: global_step=87; loss_value=0.527200
2018-09-18 23:21:26,422 - root - INFO - iteration 0: global_step=88; loss_value=0.340293
2018-09-18 23:21:26,425 - root - INFO - iteration 0: global_step=89; loss_value=0.220425
2018-09-18 23:21:26,429 - root - INFO - iteration 0: global_step=90; loss_value=0.251403
2018-09-18 23:21:26,433 - root - INFO - iteration 0: global_step=91; loss_value=0.403836
2018-09-18 23:21:26,437 - root - INFO - iteration 0: global_step=92; loss_value=0.301198
2018-09-18 23:21:26,441 - root - INFO - iteration 0: global_step=93; loss_value=0.413888
2018-09-18 23:21:26,445 - root - INFO - iteration 0: global_step=94; loss_value=0.429191
2018-09-18 23:21:26,449 - root - INFO - iteration 0: global_step=95; loss_value=0.235205
2018-09-18 23:21:26,453 - root - INFO - iteration 0: global_step=96; loss_value=0.135335
2018-09-18 23:21:26,457 - root - INFO - iteration 0: global_step=97; loss_value=0.401213
2018-09-18 23:21:26,461 - root - INFO - iteration 0: global_step=98; loss_value=0.378249
2018-09-18 23:21:26,467 - root - INFO - iteration 0: global_step=99; loss_value=0.193424
2018-09-18 23:21:26,471 - root - INFO - iteration 0: global_step=100; loss_value=0.216464
2018-09-18 23:21:26,548 - root - INFO - saving model ...
2018-09-18 23:27:50,225 - root - INFO - lr             :	0.02
2018-09-18 23:27:50,226 - root - INFO - dr             :	0.96
2018-09-18 23:27:50,230 - root - INFO - ds             :	100
2018-09-18 23:27:50,230 - root - INFO - edr            :	0.99
2018-09-18 23:27:50,230 - root - INFO - lp             :	0.3
2018-09-18 23:27:50,230 - root - INFO - bs             :	100
2018-09-18 23:27:50,230 - root - INFO - clip           :	5
2018-09-18 23:27:50,230 - root - INFO - epoch          :	20
2018-09-18 23:27:50,230 - root - INFO - layer1_units   :	50
2018-09-18 23:27:50,230 - root - INFO - layer2_units   :	10
2018-09-18 23:27:50,230 - root - INFO - input_dimension:	784
2018-09-18 23:27:50,231 - root - INFO - num_tags       :	10
2018-09-18 23:27:50,231 - root - INFO - opt            :	Adam
2018-09-18 23:27:50,813 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 23:27:50,946 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-18 23:27:50,950 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 23:27:51,834 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 23:27:51,841 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-18 23:27:51,974 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 23:27:52,878 - root - INFO - iteration 0: global_step=1; loss_value=2.408463
2018-09-18 23:27:52,885 - root - INFO - iteration 0: global_step=2; loss_value=2.416197
2018-09-18 23:27:52,891 - root - INFO - iteration 0: global_step=3; loss_value=1.718778
2018-09-18 23:27:52,893 - root - INFO - iteration 0: global_step=4; loss_value=1.255379
2018-09-18 23:27:52,895 - root - INFO - iteration 0: global_step=5; loss_value=1.062039
2018-09-18 23:27:52,900 - root - INFO - iteration 0: global_step=6; loss_value=1.187013
2018-09-18 23:27:52,902 - root - INFO - iteration 0: global_step=7; loss_value=0.958345
2018-09-18 23:27:52,906 - root - INFO - iteration 0: global_step=8; loss_value=0.626183
2018-09-18 23:27:52,911 - root - INFO - iteration 0: global_step=9; loss_value=0.748871
2018-09-18 23:27:52,915 - root - INFO - iteration 0: global_step=10; loss_value=0.564340
2018-09-18 23:27:52,919 - root - INFO - iteration 0: global_step=11; loss_value=0.575436
2018-09-18 23:27:52,923 - root - INFO - iteration 0: global_step=12; loss_value=0.480118
2018-09-18 23:27:52,929 - root - INFO - iteration 0: global_step=13; loss_value=0.665491
2018-09-18 23:27:52,934 - root - INFO - iteration 0: global_step=14; loss_value=0.516581
2018-09-18 23:27:52,938 - root - INFO - iteration 0: global_step=15; loss_value=0.569449
2018-09-18 23:27:52,944 - root - INFO - iteration 0: global_step=16; loss_value=0.643493
2018-09-18 23:27:52,946 - root - INFO - iteration 0: global_step=17; loss_value=0.502177
2018-09-18 23:27:52,952 - root - INFO - iteration 0: global_step=18; loss_value=0.544467
2018-09-18 23:27:52,953 - root - INFO - iteration 0: global_step=19; loss_value=0.703858
2018-09-18 23:27:52,957 - root - INFO - iteration 0: global_step=20; loss_value=0.587082
2018-09-18 23:27:52,962 - root - INFO - iteration 0: global_step=21; loss_value=0.470865
2018-09-18 23:27:52,966 - root - INFO - iteration 0: global_step=22; loss_value=0.410052
2018-09-18 23:27:52,970 - root - INFO - iteration 0: global_step=23; loss_value=0.606804
2018-09-18 23:27:52,976 - root - INFO - iteration 0: global_step=24; loss_value=0.596255
2018-09-18 23:27:52,977 - root - INFO - iteration 0: global_step=25; loss_value=0.695919
2018-09-18 23:27:52,981 - root - INFO - iteration 0: global_step=26; loss_value=0.358658
2018-09-18 23:27:52,985 - root - INFO - iteration 0: global_step=27; loss_value=0.680325
2018-09-18 23:27:52,989 - root - INFO - iteration 0: global_step=28; loss_value=0.632647
2018-09-18 23:27:52,993 - root - INFO - iteration 0: global_step=29; loss_value=0.311939
2018-09-18 23:27:52,997 - root - INFO - iteration 0: global_step=30; loss_value=0.267391
2018-09-18 23:27:53,003 - root - INFO - iteration 0: global_step=31; loss_value=0.506045
2018-09-18 23:27:53,005 - root - INFO - iteration 0: global_step=32; loss_value=0.421409
2018-09-18 23:27:53,007 - root - INFO - iteration 0: global_step=33; loss_value=0.395468
2018-09-18 23:27:53,012 - root - INFO - iteration 0: global_step=34; loss_value=0.462390
2018-09-18 23:27:53,015 - root - INFO - iteration 0: global_step=35; loss_value=0.442438
2018-09-18 23:27:53,018 - root - INFO - iteration 0: global_step=36; loss_value=0.311679
2018-09-18 23:27:53,024 - root - INFO - iteration 0: global_step=37; loss_value=0.311142
2018-09-18 23:27:53,027 - root - INFO - iteration 0: global_step=38; loss_value=0.495793
2018-09-18 23:27:53,034 - root - INFO - iteration 0: global_step=39; loss_value=0.356622
2018-09-18 23:27:53,037 - root - INFO - iteration 0: global_step=40; loss_value=0.342701
2018-09-18 23:27:53,046 - root - INFO - iteration 0: global_step=41; loss_value=0.339822
2018-09-18 23:27:53,049 - root - INFO - iteration 0: global_step=42; loss_value=0.588091
2018-09-18 23:27:53,053 - root - INFO - iteration 0: global_step=43; loss_value=0.409076
2018-09-18 23:27:53,057 - root - INFO - iteration 0: global_step=44; loss_value=0.324306
2018-09-18 23:27:53,064 - root - INFO - iteration 0: global_step=45; loss_value=0.378790
2018-09-18 23:27:53,066 - root - INFO - iteration 0: global_step=46; loss_value=0.350919
2018-09-18 23:27:53,069 - root - INFO - iteration 0: global_step=47; loss_value=0.438014
2018-09-18 23:27:53,073 - root - INFO - iteration 0: global_step=48; loss_value=0.519202
2018-09-18 23:27:53,077 - root - INFO - iteration 0: global_step=49; loss_value=0.376665
2018-09-18 23:27:53,082 - root - INFO - iteration 0: global_step=50; loss_value=0.271128
2018-09-18 23:27:53,085 - root - INFO - iteration 0: global_step=51; loss_value=0.294490
2018-09-18 23:27:53,089 - root - INFO - iteration 0: global_step=52; loss_value=0.399522
2018-09-18 23:27:53,093 - root - INFO - iteration 0: global_step=53; loss_value=0.332326
2018-09-18 23:27:53,097 - root - INFO - iteration 0: global_step=54; loss_value=0.492842
2018-09-18 23:27:53,101 - root - INFO - iteration 0: global_step=55; loss_value=0.545427
2018-09-18 23:27:53,105 - root - INFO - iteration 0: global_step=56; loss_value=0.378069
2018-09-18 23:27:53,107 - root - INFO - iteration 0: global_step=57; loss_value=0.445009
2018-09-18 23:27:53,112 - root - INFO - iteration 0: global_step=58; loss_value=0.239146
2018-09-18 23:27:53,116 - root - INFO - iteration 0: global_step=59; loss_value=0.367666
2018-09-18 23:27:53,119 - root - INFO - iteration 0: global_step=60; loss_value=0.307040
2018-09-18 23:27:53,123 - root - INFO - iteration 0: global_step=61; loss_value=0.276167
2018-09-18 23:27:53,127 - root - INFO - iteration 0: global_step=62; loss_value=0.160742
2018-09-18 23:27:53,131 - root - INFO - iteration 0: global_step=63; loss_value=0.292283
2018-09-18 23:27:53,135 - root - INFO - iteration 0: global_step=64; loss_value=0.166983
2018-09-18 23:27:53,138 - root - INFO - iteration 0: global_step=65; loss_value=0.192908
2018-09-18 23:27:53,143 - root - INFO - iteration 0: global_step=66; loss_value=0.240316
2018-09-18 23:27:53,148 - root - INFO - iteration 0: global_step=67; loss_value=0.364788
2018-09-18 23:27:53,154 - root - INFO - iteration 0: global_step=68; loss_value=0.454327
2018-09-18 23:27:53,161 - root - INFO - iteration 0: global_step=69; loss_value=0.257358
2018-09-18 23:27:53,162 - root - INFO - iteration 0: global_step=70; loss_value=0.437287
2018-09-18 23:27:53,166 - root - INFO - iteration 0: global_step=71; loss_value=0.448456
2018-09-18 23:27:53,171 - root - INFO - iteration 0: global_step=72; loss_value=0.467262
2018-09-18 23:27:53,172 - root - INFO - iteration 0: global_step=73; loss_value=0.231026
2018-09-18 23:27:53,182 - root - INFO - iteration 0: global_step=74; loss_value=0.450093
2018-09-18 23:27:53,184 - root - INFO - iteration 0: global_step=75; loss_value=0.238194
2018-09-18 23:27:53,189 - root - INFO - iteration 0: global_step=76; loss_value=0.353626
2018-09-18 23:27:53,190 - root - INFO - iteration 0: global_step=77; loss_value=0.206979
2018-09-18 23:27:53,196 - root - INFO - iteration 0: global_step=78; loss_value=0.400584
2018-09-18 23:27:53,197 - root - INFO - iteration 0: global_step=79; loss_value=0.286355
2018-09-18 23:27:53,203 - root - INFO - iteration 0: global_step=80; loss_value=0.219954
2018-09-18 23:27:53,205 - root - INFO - iteration 0: global_step=81; loss_value=0.190118
2018-09-18 23:27:53,209 - root - INFO - iteration 0: global_step=82; loss_value=0.286144
2018-09-18 23:27:53,213 - root - INFO - iteration 0: global_step=83; loss_value=0.226488
2018-09-18 23:27:53,217 - root - INFO - iteration 0: global_step=84; loss_value=0.198951
2018-09-18 23:27:53,221 - root - INFO - iteration 0: global_step=85; loss_value=0.254277
2018-09-18 23:27:53,227 - root - INFO - iteration 0: global_step=86; loss_value=0.319611
2018-09-18 23:27:53,229 - root - INFO - iteration 0: global_step=87; loss_value=0.286400
2018-09-18 23:27:53,230 - root - INFO - iteration 0: global_step=88; loss_value=0.390341
2018-09-18 23:27:53,235 - root - INFO - iteration 0: global_step=89; loss_value=0.258221
2018-09-18 23:27:53,239 - root - INFO - iteration 0: global_step=90; loss_value=0.259934
2018-09-18 23:27:53,241 - root - INFO - iteration 0: global_step=91; loss_value=0.296488
2018-09-18 23:27:53,247 - root - INFO - iteration 0: global_step=92; loss_value=0.443069
2018-09-18 23:27:53,249 - root - INFO - iteration 0: global_step=93; loss_value=0.316910
2018-09-18 23:27:53,254 - root - INFO - iteration 0: global_step=94; loss_value=0.264010
2018-09-18 23:27:53,259 - root - INFO - iteration 0: global_step=95; loss_value=0.585192
2018-09-18 23:27:53,264 - root - INFO - iteration 0: global_step=96; loss_value=0.165434
2018-09-18 23:27:53,270 - root - INFO - iteration 0: global_step=97; loss_value=0.291177
2018-09-18 23:27:53,279 - root - INFO - iteration 0: global_step=98; loss_value=0.352579
2018-09-18 23:27:53,287 - root - INFO - iteration 0: global_step=99; loss_value=0.232237
2018-09-18 23:27:53,289 - root - INFO - iteration 0: global_step=100; loss_value=0.181079
2018-09-18 23:27:53,349 - root - INFO - saving model ...
2018-09-18 23:30:41,178 - root - INFO - lr             :	0.02
2018-09-18 23:30:41,179 - root - INFO - dr             :	0.96
2018-09-18 23:30:41,179 - root - INFO - ds             :	100
2018-09-18 23:30:41,179 - root - INFO - edr            :	0.99
2018-09-18 23:30:41,181 - root - INFO - lp             :	0.3
2018-09-18 23:30:41,181 - root - INFO - bs             :	100
2018-09-18 23:30:41,181 - root - INFO - clip           :	5
2018-09-18 23:30:41,181 - root - INFO - epoch          :	20
2018-09-18 23:30:41,181 - root - INFO - layer1_units   :	50
2018-09-18 23:30:41,181 - root - INFO - layer2_units   :	10
2018-09-18 23:30:41,181 - root - INFO - input_dimension:	784
2018-09-18 23:30:41,181 - root - INFO - num_tags       :	10
2018-09-18 23:30:41,181 - root - INFO - opt            :	Adam
2018-09-18 23:30:42,174 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 23:30:42,342 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-18 23:30:42,347 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 23:30:42,929 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 23:30:42,934 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-18 23:30:43,045 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 23:30:44,213 - root - INFO - iteration 0: global_step=1; loss_value=2.442779
2018-09-18 23:30:44,220 - root - INFO - iteration 0: global_step=2; loss_value=2.160073
2018-09-18 23:30:44,225 - root - INFO - iteration 0: global_step=3; loss_value=1.761603
2018-09-18 23:30:44,227 - root - INFO - iteration 0: global_step=4; loss_value=1.330001
2018-09-18 23:30:44,230 - root - INFO - iteration 0: global_step=5; loss_value=1.264112
2018-09-18 23:30:44,236 - root - INFO - iteration 0: global_step=6; loss_value=0.992981
2018-09-18 23:30:44,238 - root - INFO - iteration 0: global_step=7; loss_value=0.899737
2018-09-18 23:30:44,243 - root - INFO - iteration 0: global_step=8; loss_value=0.864964
2018-09-18 23:30:44,248 - root - INFO - iteration 0: global_step=9; loss_value=0.921728
2018-09-18 23:30:44,253 - root - INFO - iteration 0: global_step=10; loss_value=1.059484
2018-09-18 23:30:44,260 - root - INFO - iteration 0: global_step=11; loss_value=0.696142
2018-09-18 23:30:44,264 - root - INFO - iteration 0: global_step=12; loss_value=0.681912
2018-09-18 23:30:44,269 - root - INFO - iteration 0: global_step=13; loss_value=0.793344
2018-09-18 23:30:44,276 - root - INFO - iteration 0: global_step=14; loss_value=0.608575
2018-09-18 23:30:44,278 - root - INFO - iteration 0: global_step=15; loss_value=0.882223
2018-09-18 23:30:44,281 - root - INFO - iteration 0: global_step=16; loss_value=0.526245
2018-09-18 23:30:44,287 - root - INFO - iteration 0: global_step=17; loss_value=0.555501
2018-09-18 23:30:44,291 - root - INFO - iteration 0: global_step=18; loss_value=0.561392
2018-09-18 23:30:44,293 - root - INFO - iteration 0: global_step=19; loss_value=0.564635
2018-09-18 23:30:44,301 - root - INFO - iteration 0: global_step=20; loss_value=0.425062
2018-09-18 23:30:44,306 - root - INFO - iteration 0: global_step=21; loss_value=0.580013
2018-09-18 23:30:44,316 - root - INFO - iteration 0: global_step=22; loss_value=0.454762
2018-09-18 23:30:44,322 - root - INFO - iteration 0: global_step=23; loss_value=0.459351
2018-09-18 23:30:44,327 - root - INFO - iteration 0: global_step=24; loss_value=0.612410
2018-09-18 23:30:44,329 - root - INFO - iteration 0: global_step=25; loss_value=0.816272
2018-09-18 23:30:44,333 - root - INFO - iteration 0: global_step=26; loss_value=0.346042
2018-09-18 23:30:44,339 - root - INFO - iteration 0: global_step=27; loss_value=0.559959
2018-09-18 23:30:44,343 - root - INFO - iteration 0: global_step=28; loss_value=0.387778
2018-09-18 23:30:44,347 - root - INFO - iteration 0: global_step=29; loss_value=0.370789
2018-09-18 23:30:44,349 - root - INFO - iteration 0: global_step=30; loss_value=0.408449
2018-09-18 23:30:44,357 - root - INFO - iteration 0: global_step=31; loss_value=0.511766
2018-09-18 23:30:44,362 - root - INFO - iteration 0: global_step=32; loss_value=0.599671
2018-09-18 23:30:44,371 - root - INFO - iteration 0: global_step=33; loss_value=0.515843
2018-09-18 23:30:44,375 - root - INFO - iteration 0: global_step=34; loss_value=0.437355
2018-09-18 23:30:44,383 - root - INFO - iteration 0: global_step=35; loss_value=0.342895
2018-09-18 23:30:44,384 - root - INFO - iteration 0: global_step=36; loss_value=0.508520
2018-09-18 23:30:44,386 - root - INFO - iteration 0: global_step=37; loss_value=0.222301
2018-09-18 23:30:44,391 - root - INFO - iteration 0: global_step=38; loss_value=0.453898
2018-09-18 23:30:44,392 - root - INFO - iteration 0: global_step=39; loss_value=0.407712
2018-09-18 23:30:44,396 - root - INFO - iteration 0: global_step=40; loss_value=0.326175
2018-09-18 23:30:44,402 - root - INFO - iteration 0: global_step=41; loss_value=0.333844
2018-09-18 23:30:44,404 - root - INFO - iteration 0: global_step=42; loss_value=0.243616
2018-09-18 23:30:44,410 - root - INFO - iteration 0: global_step=43; loss_value=0.464488
2018-09-18 23:30:44,415 - root - INFO - iteration 0: global_step=44; loss_value=0.433633
2018-09-18 23:30:44,420 - root - INFO - iteration 0: global_step=45; loss_value=0.273862
2018-09-18 23:30:44,431 - root - INFO - iteration 0: global_step=46; loss_value=0.420615
2018-09-18 23:30:44,432 - root - INFO - iteration 0: global_step=47; loss_value=0.389282
2018-09-18 23:30:44,437 - root - INFO - iteration 0: global_step=48; loss_value=0.539105
2018-09-18 23:30:44,444 - root - INFO - iteration 0: global_step=49; loss_value=0.494408
2018-09-18 23:30:44,446 - root - INFO - iteration 0: global_step=50; loss_value=0.290808
2018-09-18 23:30:44,451 - root - INFO - iteration 0: global_step=51; loss_value=0.226661
2018-09-18 23:30:44,455 - root - INFO - iteration 0: global_step=52; loss_value=0.249582
2018-09-18 23:30:44,459 - root - INFO - iteration 0: global_step=53; loss_value=0.435219
2018-09-18 23:30:44,463 - root - INFO - iteration 0: global_step=54; loss_value=0.333556
2018-09-18 23:30:44,467 - root - INFO - iteration 0: global_step=55; loss_value=0.424264
2018-09-18 23:30:44,473 - root - INFO - iteration 0: global_step=56; loss_value=0.217118
2018-09-18 23:30:44,483 - root - INFO - iteration 0: global_step=57; loss_value=0.480210
2018-09-18 23:30:44,484 - root - INFO - iteration 0: global_step=58; loss_value=0.425426
2018-09-18 23:30:44,489 - root - INFO - iteration 0: global_step=59; loss_value=0.220761
2018-09-18 23:30:44,495 - root - INFO - iteration 0: global_step=60; loss_value=0.382004
2018-09-18 23:30:44,497 - root - INFO - iteration 0: global_step=61; loss_value=0.354699
2018-09-18 23:30:44,500 - root - INFO - iteration 0: global_step=62; loss_value=0.303166
2018-09-18 23:30:44,504 - root - INFO - iteration 0: global_step=63; loss_value=0.533345
2018-09-18 23:30:44,508 - root - INFO - iteration 0: global_step=64; loss_value=0.210724
2018-09-18 23:30:44,513 - root - INFO - iteration 0: global_step=65; loss_value=0.215815
2018-09-18 23:30:44,518 - root - INFO - iteration 0: global_step=66; loss_value=0.202246
2018-09-18 23:30:44,521 - root - INFO - iteration 0: global_step=67; loss_value=0.312142
2018-09-18 23:30:44,526 - root - INFO - iteration 0: global_step=68; loss_value=0.447842
2018-09-18 23:30:44,530 - root - INFO - iteration 0: global_step=69; loss_value=0.214612
2018-09-18 23:30:44,539 - root - INFO - iteration 0: global_step=70; loss_value=0.358812
2018-09-18 23:30:44,541 - root - INFO - iteration 0: global_step=71; loss_value=0.204848
2018-09-18 23:30:44,543 - root - INFO - iteration 0: global_step=72; loss_value=0.271784
2018-09-18 23:30:44,551 - root - INFO - iteration 0: global_step=73; loss_value=0.457710
2018-09-18 23:30:44,553 - root - INFO - iteration 0: global_step=74; loss_value=0.280933
2018-09-18 23:30:44,557 - root - INFO - iteration 0: global_step=75; loss_value=0.395813
2018-09-18 23:30:44,560 - root - INFO - iteration 0: global_step=76; loss_value=0.461246
2018-09-18 23:30:44,565 - root - INFO - iteration 0: global_step=77; loss_value=0.209802
2018-09-18 23:30:44,568 - root - INFO - iteration 0: global_step=78; loss_value=0.376648
2018-09-18 23:30:44,574 - root - INFO - iteration 0: global_step=79; loss_value=0.223644
2018-09-18 23:30:44,578 - root - INFO - iteration 0: global_step=80; loss_value=0.308469
2018-09-18 23:30:44,582 - root - INFO - iteration 0: global_step=81; loss_value=0.320127
2018-09-18 23:30:44,588 - root - INFO - iteration 0: global_step=82; loss_value=0.216050
2018-09-18 23:30:44,592 - root - INFO - iteration 0: global_step=83; loss_value=0.273831
2018-09-18 23:30:44,599 - root - INFO - iteration 0: global_step=84; loss_value=0.362554
2018-09-18 23:30:44,603 - root - INFO - iteration 0: global_step=85; loss_value=0.290734
2018-09-18 23:30:44,611 - root - INFO - iteration 0: global_step=86; loss_value=0.291458
2018-09-18 23:30:44,613 - root - INFO - iteration 0: global_step=87; loss_value=0.212236
2018-09-18 23:30:44,617 - root - INFO - iteration 0: global_step=88; loss_value=0.298945
2018-09-18 23:30:44,621 - root - INFO - iteration 0: global_step=89; loss_value=0.216006
2018-09-18 23:30:44,626 - root - INFO - iteration 0: global_step=90; loss_value=0.316794
2018-09-18 23:30:44,628 - root - INFO - iteration 0: global_step=91; loss_value=0.259196
2018-09-18 23:30:44,633 - root - INFO - iteration 0: global_step=92; loss_value=0.398266
2018-09-18 23:30:44,637 - root - INFO - iteration 0: global_step=93; loss_value=0.285095
2018-09-18 23:30:44,642 - root - INFO - iteration 0: global_step=94; loss_value=0.356515
2018-09-18 23:30:44,647 - root - INFO - iteration 0: global_step=95; loss_value=0.278490
2018-09-18 23:30:44,654 - root - INFO - iteration 0: global_step=96; loss_value=0.295219
2018-09-18 23:30:44,663 - root - INFO - iteration 0: global_step=97; loss_value=0.197352
2018-09-18 23:30:44,664 - root - INFO - iteration 0: global_step=98; loss_value=0.230036
2018-09-18 23:30:44,669 - root - INFO - iteration 0: global_step=99; loss_value=0.162623
2018-09-18 23:30:44,674 - root - INFO - iteration 0: global_step=100; loss_value=0.350806
2018-09-18 23:30:44,744 - root - INFO - saving model ...
2018-09-18 23:33:40,097 - root - INFO - lr             :	0.02
2018-09-18 23:33:40,099 - root - INFO - dr             :	0.96
2018-09-18 23:33:40,102 - root - INFO - ds             :	100
2018-09-18 23:33:40,103 - root - INFO - edr            :	0.99
2018-09-18 23:33:40,103 - root - INFO - lp             :	0.3
2018-09-18 23:33:40,103 - root - INFO - bs             :	100
2018-09-18 23:33:40,103 - root - INFO - clip           :	5
2018-09-18 23:33:40,103 - root - INFO - epoch          :	20
2018-09-18 23:33:40,103 - root - INFO - layer1_units   :	50
2018-09-18 23:33:40,103 - root - INFO - layer2_units   :	10
2018-09-18 23:33:40,103 - root - INFO - input_dimension:	784
2018-09-18 23:33:40,103 - root - INFO - num_tags       :	10
2018-09-18 23:33:40,103 - root - INFO - opt            :	Adam
2018-09-18 23:33:40,532 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 23:33:40,640 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-18 23:33:40,643 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 23:33:40,983 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-18 23:33:40,991 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-18 23:33:41,091 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-18 23:33:41,368 - tensorflow - INFO - Restoring parameters from ckpt/mnist.ckpt-100
2018-09-19 01:15:23,986 - root - INFO - lr             :	0.02
2018-09-19 01:15:23,987 - root - INFO - dr             :	0.96
2018-09-19 01:15:23,991 - root - INFO - ds             :	100
2018-09-19 01:15:23,991 - root - INFO - edr            :	0.99
2018-09-19 01:15:23,991 - root - INFO - lp             :	0.3
2018-09-19 01:15:23,991 - root - INFO - bs             :	100
2018-09-19 01:15:23,991 - root - INFO - clip           :	5
2018-09-19 01:15:23,991 - root - INFO - epoch          :	20
2018-09-19 01:15:23,991 - root - INFO - layer1_units   :	50
2018-09-19 01:15:23,991 - root - INFO - layer2_units   :	10
2018-09-19 01:15:23,991 - root - INFO - input_dimension:	784
2018-09-19 01:15:23,991 - root - INFO - num_tags       :	10
2018-09-19 01:15:23,991 - root - INFO - opt            :	Adam
2018-09-19 01:15:24,347 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-19 01:15:24,458 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-19 01:15:24,463 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-19 01:15:25,091 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-19 01:15:25,097 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-19 01:15:25,229 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-19 01:15:27,159 - root - INFO - iteration 0: global_step=1; loss_value=2.525753
2018-09-19 01:15:27,167 - root - INFO - iteration 0: global_step=2; loss_value=2.417922
2018-09-19 01:15:27,169 - root - INFO - iteration 0: global_step=3; loss_value=1.706408
2018-09-19 01:15:27,172 - root - INFO - iteration 0: global_step=4; loss_value=1.426121
2018-09-19 01:15:27,178 - root - INFO - iteration 0: global_step=5; loss_value=1.216807
2018-09-19 01:15:27,180 - root - INFO - iteration 0: global_step=6; loss_value=1.023347
2018-09-19 01:15:27,185 - root - INFO - iteration 0: global_step=7; loss_value=0.772619
2018-09-19 01:15:27,191 - root - INFO - iteration 0: global_step=8; loss_value=0.738747
2018-09-19 01:15:27,193 - root - INFO - iteration 0: global_step=9; loss_value=0.568489
2018-09-19 01:15:27,200 - root - INFO - iteration 0: global_step=10; loss_value=0.793432
2018-09-19 01:15:27,206 - root - INFO - iteration 0: global_step=11; loss_value=0.570427
2018-09-19 01:15:27,211 - root - INFO - iteration 0: global_step=12; loss_value=0.575712
2018-09-19 01:15:27,217 - root - INFO - iteration 0: global_step=13; loss_value=0.631847
2018-09-19 01:15:27,220 - root - INFO - iteration 0: global_step=14; loss_value=0.621030
2018-09-19 01:15:27,229 - root - INFO - iteration 0: global_step=15; loss_value=0.440763
2018-09-19 01:15:27,235 - root - INFO - iteration 0: global_step=16; loss_value=0.713675
2018-09-19 01:15:27,236 - root - INFO - iteration 0: global_step=17; loss_value=0.415910
2018-09-19 01:15:27,238 - root - INFO - iteration 0: global_step=18; loss_value=0.425041
2018-09-19 01:15:27,244 - root - INFO - iteration 0: global_step=19; loss_value=0.535027
2018-09-19 01:15:27,246 - root - INFO - iteration 0: global_step=20; loss_value=0.601787
2018-09-19 01:15:27,250 - root - INFO - iteration 0: global_step=21; loss_value=0.456222
2018-09-19 01:15:27,254 - root - INFO - iteration 0: global_step=22; loss_value=0.574094
2018-09-19 01:15:27,261 - root - INFO - iteration 0: global_step=23; loss_value=0.636662
2018-09-19 01:15:27,267 - root - INFO - iteration 0: global_step=24; loss_value=0.678380
2018-09-19 01:15:27,277 - root - INFO - iteration 0: global_step=25; loss_value=0.386345
2018-09-19 01:15:27,283 - root - INFO - iteration 0: global_step=26; loss_value=0.717140
2018-09-19 01:15:27,285 - root - INFO - iteration 0: global_step=27; loss_value=0.550840
2018-09-19 01:15:27,287 - root - INFO - iteration 0: global_step=28; loss_value=0.481151
2018-09-19 01:15:27,292 - root - INFO - iteration 0: global_step=29; loss_value=0.587378
2018-09-19 01:15:27,294 - root - INFO - iteration 0: global_step=30; loss_value=0.681293
2018-09-19 01:15:27,298 - root - INFO - iteration 0: global_step=31; loss_value=0.478894
2018-09-19 01:15:27,303 - root - INFO - iteration 0: global_step=32; loss_value=0.443221
2018-09-19 01:15:27,306 - root - INFO - iteration 0: global_step=33; loss_value=0.560410
2018-09-19 01:15:27,311 - root - INFO - iteration 0: global_step=34; loss_value=0.769727
2018-09-19 01:15:27,314 - root - INFO - iteration 0: global_step=35; loss_value=0.350125
2018-09-19 01:15:27,320 - root - INFO - iteration 0: global_step=36; loss_value=0.509666
2018-09-19 01:15:27,325 - root - INFO - iteration 0: global_step=37; loss_value=0.514380
2018-09-19 01:15:27,335 - root - INFO - iteration 0: global_step=38; loss_value=0.245309
2018-09-19 01:15:27,341 - root - INFO - iteration 0: global_step=39; loss_value=0.338389
2018-09-19 01:15:27,347 - root - INFO - iteration 0: global_step=40; loss_value=0.286990
2018-09-19 01:15:27,349 - root - INFO - iteration 0: global_step=41; loss_value=0.334442
2018-09-19 01:15:27,352 - root - INFO - iteration 0: global_step=42; loss_value=0.505607
2018-09-19 01:15:27,357 - root - INFO - iteration 0: global_step=43; loss_value=0.627535
2018-09-19 01:15:27,360 - root - INFO - iteration 0: global_step=44; loss_value=0.316819
2018-09-19 01:15:27,366 - root - INFO - iteration 0: global_step=45; loss_value=0.265549
2018-09-19 01:15:27,371 - root - INFO - iteration 0: global_step=46; loss_value=0.435370
2018-09-19 01:15:27,373 - root - INFO - iteration 0: global_step=47; loss_value=0.578231
2018-09-19 01:15:27,380 - root - INFO - iteration 0: global_step=48; loss_value=0.362961
2018-09-19 01:15:27,387 - root - INFO - iteration 0: global_step=49; loss_value=0.298711
2018-09-19 01:15:27,392 - root - INFO - iteration 0: global_step=50; loss_value=0.259605
2018-09-19 01:15:27,397 - root - INFO - iteration 0: global_step=51; loss_value=0.358362
2018-09-19 01:15:27,401 - root - INFO - iteration 0: global_step=52; loss_value=0.208314
2018-09-19 01:15:27,407 - root - INFO - iteration 0: global_step=53; loss_value=0.246502
2018-09-19 01:15:27,410 - root - INFO - iteration 0: global_step=54; loss_value=0.540781
2018-09-19 01:15:27,414 - root - INFO - iteration 0: global_step=55; loss_value=0.351145
2018-09-19 01:15:27,419 - root - INFO - iteration 0: global_step=56; loss_value=0.252537
2018-09-19 01:15:27,423 - root - INFO - iteration 0: global_step=57; loss_value=0.501369
2018-09-19 01:15:27,427 - root - INFO - iteration 0: global_step=58; loss_value=0.174685
2018-09-19 01:15:27,434 - root - INFO - iteration 0: global_step=59; loss_value=0.318501
2018-09-19 01:15:27,439 - root - INFO - iteration 0: global_step=60; loss_value=0.370296
2018-09-19 01:15:27,446 - root - INFO - iteration 0: global_step=61; loss_value=0.508451
2018-09-19 01:15:27,448 - root - INFO - iteration 0: global_step=62; loss_value=0.329140
2018-09-19 01:15:27,452 - root - INFO - iteration 0: global_step=63; loss_value=0.366239
2018-09-19 01:15:27,457 - root - INFO - iteration 0: global_step=64; loss_value=0.199732
2018-09-19 01:15:27,463 - root - INFO - iteration 0: global_step=65; loss_value=0.263445
2018-09-19 01:15:27,465 - root - INFO - iteration 0: global_step=66; loss_value=0.321954
2018-09-19 01:15:27,469 - root - INFO - iteration 0: global_step=67; loss_value=0.300323
2018-09-19 01:15:27,473 - root - INFO - iteration 0: global_step=68; loss_value=0.260176
2018-09-19 01:15:27,477 - root - INFO - iteration 0: global_step=69; loss_value=0.361062
2018-09-19 01:15:27,480 - root - INFO - iteration 0: global_step=70; loss_value=0.304549
2018-09-19 01:15:27,486 - root - INFO - iteration 0: global_step=71; loss_value=0.249431
2018-09-19 01:15:27,489 - root - INFO - iteration 0: global_step=72; loss_value=0.235512
2018-09-19 01:15:27,494 - root - INFO - iteration 0: global_step=73; loss_value=0.385255
2018-09-19 01:15:27,497 - root - INFO - iteration 0: global_step=74; loss_value=0.347208
2018-09-19 01:15:27,501 - root - INFO - iteration 0: global_step=75; loss_value=0.388185
2018-09-19 01:15:27,506 - root - INFO - iteration 0: global_step=76; loss_value=0.353074
2018-09-19 01:15:27,516 - root - INFO - iteration 0: global_step=77; loss_value=0.216377
2018-09-19 01:15:27,518 - root - INFO - iteration 0: global_step=78; loss_value=0.222888
2018-09-19 01:15:27,525 - root - INFO - iteration 0: global_step=79; loss_value=0.319735
2018-09-19 01:15:27,528 - root - INFO - iteration 0: global_step=80; loss_value=0.299323
2018-09-19 01:15:27,533 - root - INFO - iteration 0: global_step=81; loss_value=0.259949
2018-09-19 01:15:27,537 - root - INFO - iteration 0: global_step=82; loss_value=0.428821
2018-09-19 01:15:27,540 - root - INFO - iteration 0: global_step=83; loss_value=0.248591
2018-09-19 01:15:27,544 - root - INFO - iteration 0: global_step=84; loss_value=0.218192
2018-09-19 01:15:27,548 - root - INFO - iteration 0: global_step=85; loss_value=0.551041
2018-09-19 01:15:27,553 - root - INFO - iteration 0: global_step=86; loss_value=0.163563
2018-09-19 01:15:27,559 - root - INFO - iteration 0: global_step=87; loss_value=0.473156
2018-09-19 01:15:27,563 - root - INFO - iteration 0: global_step=88; loss_value=0.334430
2018-09-19 01:15:27,570 - root - INFO - iteration 0: global_step=89; loss_value=0.270883
2018-09-19 01:15:27,573 - root - INFO - iteration 0: global_step=90; loss_value=0.277012
2018-09-19 01:15:27,583 - root - INFO - iteration 0: global_step=91; loss_value=0.147210
2018-09-19 01:15:27,585 - root - INFO - iteration 0: global_step=92; loss_value=0.257249
2018-09-19 01:15:27,587 - root - INFO - iteration 0: global_step=93; loss_value=0.196282
2018-09-19 01:15:27,594 - root - INFO - iteration 0: global_step=94; loss_value=0.254992
2018-09-19 01:15:27,598 - root - INFO - iteration 0: global_step=95; loss_value=0.613414
2018-09-19 01:15:27,601 - root - INFO - iteration 0: global_step=96; loss_value=0.187206
2018-09-19 01:15:27,605 - root - INFO - iteration 0: global_step=97; loss_value=0.288867
2018-09-19 01:15:27,612 - root - INFO - iteration 0: global_step=98; loss_value=0.316738
2018-09-19 01:15:27,614 - root - INFO - iteration 0: global_step=99; loss_value=0.220956
2018-09-19 01:15:27,622 - root - INFO - iteration 0: global_step=100; loss_value=0.368285
2018-09-19 01:15:27,703 - root - INFO - saving model ...
2018-09-19 01:15:27,886 - root - INFO - iteration 0: accuracy=   92.700%
2018-09-19 01:15:28,247 - root - INFO - saving model ...
2018-09-19 01:15:28,502 - root - INFO - iteration 1: accuracy=   94.540%
2018-09-19 01:15:28,706 - root - INFO - saving model ...
2018-09-19 01:15:28,835 - root - INFO - iteration 2: accuracy=   95.210%
2018-09-19 01:15:29,049 - root - INFO - saving model ...
2018-09-19 01:15:29,190 - root - INFO - iteration 3: accuracy=   95.610%
2018-09-19 01:15:29,392 - root - INFO - saving model ...
2018-09-19 01:15:29,527 - root - INFO - iteration 4: accuracy=   95.640%
2018-09-19 01:15:29,846 - root - INFO - saving model ...
2018-09-19 01:15:29,949 - root - INFO - iteration 5: accuracy=   96.090%
2018-09-19 01:15:30,162 - root - INFO - saving model ...
2018-09-19 01:15:30,268 - root - INFO - iteration 6: accuracy=   96.090%
2018-09-19 01:15:30,817 - root - INFO - saving model ...
2018-09-19 01:15:30,920 - root - INFO - iteration 9: accuracy=   96.340%
2018-09-19 01:15:30,927 - root - INFO - iteration 10: global_step=1001; loss_value=0.306369
2018-09-19 01:15:30,932 - root - INFO - iteration 10: global_step=1002; loss_value=0.084458
2018-09-19 01:15:30,935 - root - INFO - iteration 10: global_step=1003; loss_value=0.153926
2018-09-19 01:15:30,940 - root - INFO - iteration 10: global_step=1004; loss_value=0.183903
2018-09-19 01:15:30,943 - root - INFO - iteration 10: global_step=1005; loss_value=0.212195
2018-09-19 01:15:30,949 - root - INFO - iteration 10: global_step=1006; loss_value=0.072357
2018-09-19 01:15:30,953 - root - INFO - iteration 10: global_step=1007; loss_value=0.182926
2018-09-19 01:15:30,958 - root - INFO - iteration 10: global_step=1008; loss_value=0.357086
2018-09-19 01:15:30,966 - root - INFO - iteration 10: global_step=1009; loss_value=0.134670
2018-09-19 01:15:30,971 - root - INFO - iteration 10: global_step=1010; loss_value=0.213636
2018-09-19 01:15:30,978 - root - INFO - iteration 10: global_step=1011; loss_value=0.068374
2018-09-19 01:15:30,980 - root - INFO - iteration 10: global_step=1012; loss_value=0.172867
2018-09-19 01:15:30,984 - root - INFO - iteration 10: global_step=1013; loss_value=0.152248
2018-09-19 01:15:30,990 - root - INFO - iteration 10: global_step=1014; loss_value=0.122797
2018-09-19 01:15:30,994 - root - INFO - iteration 10: global_step=1015; loss_value=0.132444
2018-09-19 01:15:30,998 - root - INFO - iteration 10: global_step=1016; loss_value=0.098143
2018-09-19 01:15:31,003 - root - INFO - iteration 10: global_step=1017; loss_value=0.108562
2018-09-19 01:15:31,009 - root - INFO - iteration 10: global_step=1018; loss_value=0.066520
2018-09-19 01:15:31,019 - root - INFO - iteration 10: global_step=1019; loss_value=0.590765
2018-09-19 01:15:31,020 - root - INFO - iteration 10: global_step=1020; loss_value=0.145027
2018-09-19 01:15:31,026 - root - INFO - iteration 10: global_step=1021; loss_value=0.092110
2018-09-19 01:15:31,028 - root - INFO - iteration 10: global_step=1022; loss_value=0.233426
2018-09-19 01:15:31,032 - root - INFO - iteration 10: global_step=1023; loss_value=0.111802
2018-09-19 01:15:31,036 - root - INFO - iteration 10: global_step=1024; loss_value=0.145937
2018-09-19 01:15:31,040 - root - INFO - iteration 10: global_step=1025; loss_value=0.197800
2018-09-19 01:15:31,044 - root - INFO - iteration 10: global_step=1026; loss_value=0.110156
2018-09-19 01:15:31,049 - root - INFO - iteration 10: global_step=1027; loss_value=0.069116
2018-09-19 01:15:31,053 - root - INFO - iteration 10: global_step=1028; loss_value=0.091077
2018-09-19 01:15:31,057 - root - INFO - iteration 10: global_step=1029; loss_value=0.277014
2018-09-19 01:15:31,063 - root - INFO - iteration 10: global_step=1030; loss_value=0.242848
2018-09-19 01:15:31,069 - root - INFO - iteration 10: global_step=1031; loss_value=0.037601
2018-09-19 01:15:31,074 - root - INFO - iteration 10: global_step=1032; loss_value=0.100822
2018-09-19 01:15:31,083 - root - INFO - iteration 10: global_step=1033; loss_value=0.185694
2018-09-19 01:15:31,084 - root - INFO - iteration 10: global_step=1034; loss_value=0.170031
2018-09-19 01:15:31,091 - root - INFO - iteration 10: global_step=1035; loss_value=0.128611
2018-09-19 01:15:31,093 - root - INFO - iteration 10: global_step=1036; loss_value=0.277110
2018-09-19 01:15:31,099 - root - INFO - iteration 10: global_step=1037; loss_value=0.103286
2018-09-19 01:15:31,101 - root - INFO - iteration 10: global_step=1038; loss_value=0.177973
2018-09-19 01:15:31,104 - root - INFO - iteration 10: global_step=1039; loss_value=0.137994
2018-09-19 01:15:31,109 - root - INFO - iteration 10: global_step=1040; loss_value=0.301512
2018-09-19 01:15:31,113 - root - INFO - iteration 10: global_step=1041; loss_value=0.307379
2018-09-19 01:15:31,116 - root - INFO - iteration 10: global_step=1042; loss_value=0.169833
2018-09-19 01:15:31,121 - root - INFO - iteration 10: global_step=1043; loss_value=0.262708
2018-09-19 01:15:31,125 - root - INFO - iteration 10: global_step=1044; loss_value=0.427436
2018-09-19 01:15:31,133 - root - INFO - iteration 10: global_step=1045; loss_value=0.042310
2018-09-19 01:15:31,140 - root - INFO - iteration 10: global_step=1046; loss_value=0.046190
2018-09-19 01:15:31,147 - root - INFO - iteration 10: global_step=1047; loss_value=0.112636
2018-09-19 01:15:31,149 - root - INFO - iteration 10: global_step=1048; loss_value=0.359102
2018-09-19 01:15:31,152 - root - INFO - iteration 10: global_step=1049; loss_value=0.126172
2018-09-19 01:15:31,156 - root - INFO - iteration 10: global_step=1050; loss_value=0.251139
2018-09-19 01:15:31,161 - root - INFO - iteration 10: global_step=1051; loss_value=0.092604
2018-09-19 01:15:31,164 - root - INFO - iteration 10: global_step=1052; loss_value=0.184626
2018-09-19 01:15:31,169 - root - INFO - iteration 10: global_step=1053; loss_value=0.303178
2018-09-19 01:15:31,175 - root - INFO - iteration 10: global_step=1054; loss_value=0.114628
2018-09-19 01:15:31,178 - root - INFO - iteration 10: global_step=1055; loss_value=0.154683
2018-09-19 01:15:31,182 - root - INFO - iteration 10: global_step=1056; loss_value=0.223951
2018-09-19 01:15:31,189 - root - INFO - iteration 10: global_step=1057; loss_value=0.210299
2018-09-19 01:15:31,197 - root - INFO - iteration 10: global_step=1058; loss_value=0.272358
2018-09-19 01:15:31,200 - root - INFO - iteration 10: global_step=1059; loss_value=0.375326
2018-09-19 01:15:31,202 - root - INFO - iteration 10: global_step=1060; loss_value=0.267852
2018-09-19 01:15:31,211 - root - INFO - iteration 10: global_step=1061; loss_value=0.196230
2018-09-19 01:15:31,215 - root - INFO - iteration 10: global_step=1062; loss_value=0.047917
2018-09-19 01:15:31,219 - root - INFO - iteration 10: global_step=1063; loss_value=0.141925
2018-09-19 01:15:31,221 - root - INFO - iteration 10: global_step=1064; loss_value=0.248787
2018-09-19 01:15:31,224 - root - INFO - iteration 10: global_step=1065; loss_value=0.277976
2018-09-19 01:15:31,228 - root - INFO - iteration 10: global_step=1066; loss_value=0.203487
2018-09-19 01:15:31,232 - root - INFO - iteration 10: global_step=1067; loss_value=0.209528
2018-09-19 01:15:31,236 - root - INFO - iteration 10: global_step=1068; loss_value=0.090817
2018-09-19 01:15:31,240 - root - INFO - iteration 10: global_step=1069; loss_value=0.197371
2018-09-19 01:15:31,244 - root - INFO - iteration 10: global_step=1070; loss_value=0.202732
2018-09-19 01:15:31,248 - root - INFO - iteration 10: global_step=1071; loss_value=0.126900
2018-09-19 01:15:31,252 - root - INFO - iteration 10: global_step=1072; loss_value=0.178321
2018-09-19 01:15:31,260 - root - INFO - iteration 10: global_step=1073; loss_value=0.307472
2018-09-19 01:15:31,264 - root - INFO - iteration 10: global_step=1074; loss_value=0.153662
2018-09-19 01:15:31,272 - root - INFO - iteration 10: global_step=1075; loss_value=0.167915
2018-09-19 01:15:31,278 - root - INFO - iteration 10: global_step=1076; loss_value=0.304430
2018-09-19 01:15:31,290 - root - INFO - iteration 10: global_step=1077; loss_value=0.143487
2018-09-19 01:15:31,293 - root - INFO - iteration 10: global_step=1078; loss_value=0.196786
2018-09-19 01:15:31,296 - root - INFO - iteration 10: global_step=1079; loss_value=0.158611
2018-09-19 01:15:31,301 - root - INFO - iteration 10: global_step=1080; loss_value=0.137055
2018-09-19 01:15:31,305 - root - INFO - iteration 10: global_step=1081; loss_value=0.267376
2018-09-19 01:15:31,311 - root - INFO - iteration 10: global_step=1082; loss_value=0.210817
2018-09-19 01:15:31,314 - root - INFO - iteration 10: global_step=1083; loss_value=0.172418
2018-09-19 01:15:31,320 - root - INFO - iteration 10: global_step=1084; loss_value=0.282506
2018-09-19 01:15:31,324 - root - INFO - iteration 10: global_step=1085; loss_value=0.066551
2018-09-19 01:15:31,330 - root - INFO - iteration 10: global_step=1086; loss_value=0.140746
2018-09-19 01:15:31,337 - root - INFO - iteration 10: global_step=1087; loss_value=0.161934
2018-09-19 01:15:31,342 - root - INFO - iteration 10: global_step=1088; loss_value=0.259849
2018-09-19 01:15:31,345 - root - INFO - iteration 10: global_step=1089; loss_value=0.331863
2018-09-19 01:15:31,349 - root - INFO - iteration 10: global_step=1090; loss_value=0.162286
2018-09-19 01:15:31,353 - root - INFO - iteration 10: global_step=1091; loss_value=0.078917
2018-09-19 01:15:31,357 - root - INFO - iteration 10: global_step=1092; loss_value=0.055347
2018-09-19 01:15:31,361 - root - INFO - iteration 10: global_step=1093; loss_value=0.111286
2018-09-19 01:15:31,365 - root - INFO - iteration 10: global_step=1094; loss_value=0.090531
2018-09-19 01:15:31,369 - root - INFO - iteration 10: global_step=1095; loss_value=0.375424
2018-09-19 01:15:31,373 - root - INFO - iteration 10: global_step=1096; loss_value=0.249071
2018-09-19 01:15:31,379 - root - INFO - iteration 10: global_step=1097; loss_value=0.363467
2018-09-19 01:15:31,381 - root - INFO - iteration 10: global_step=1098; loss_value=0.352532
2018-09-19 01:15:31,388 - root - INFO - iteration 10: global_step=1099; loss_value=0.097565
2018-09-19 01:15:31,393 - root - INFO - iteration 10: global_step=1100; loss_value=0.176019
2018-09-19 01:15:32,242 - root - INFO - saving model ...
2018-09-19 01:15:32,346 - root - INFO - iteration 14: accuracy=   96.410%
2018-09-19 01:15:33,155 - root - INFO - saving model ...
2018-09-19 01:15:33,261 - root - INFO - iteration 18: accuracy=   96.430%
2018-09-24 20:44:21,192 - root - INFO - lr             :	0.02
2018-09-24 20:44:21,207 - root - INFO - dr             :	0.96
2018-09-24 20:44:21,208 - root - INFO - ds             :	100
2018-09-24 20:44:21,208 - root - INFO - edr            :	0.99
2018-09-24 20:44:21,215 - root - INFO - lp             :	0.3
2018-09-24 20:44:21,215 - root - INFO - bs             :	100
2018-09-24 20:44:21,215 - root - INFO - clip           :	5
2018-09-24 20:44:21,215 - root - INFO - epoch          :	20
2018-09-24 20:44:21,216 - root - INFO - layer1_units   :	50
2018-09-24 20:44:21,218 - root - INFO - layer2_units   :	10
2018-09-24 20:44:21,218 - root - INFO - image_size     :	28
2018-09-24 20:44:21,218 - root - INFO - channel        :	1
2018-09-24 20:44:21,218 - root - INFO - conv1          :	50
2018-09-24 20:44:21,218 - root - INFO - conv2          :	100
2018-09-24 20:44:21,218 - root - INFO - fc             :	150
2018-09-24 20:44:21,227 - root - INFO - input_dimension:	784
2018-09-24 20:44:21,227 - root - INFO - num_tags       :	10
2018-09-24 20:44:21,227 - root - INFO - opt            :	Adam
2018-09-24 20:44:21,227 - root - INFO - image          :	True
2018-09-24 21:01:08,644 - root - INFO - lr             :	0.02
2018-09-24 21:01:08,649 - root - INFO - dr             :	0.96
2018-09-24 21:01:08,652 - root - INFO - ds             :	100
2018-09-24 21:01:08,653 - root - INFO - edr            :	0.99
2018-09-24 21:01:08,654 - root - INFO - lp             :	0.3
2018-09-24 21:01:08,655 - root - INFO - bs             :	100
2018-09-24 21:01:08,655 - root - INFO - clip           :	5
2018-09-24 21:01:08,656 - root - INFO - epoch          :	20
2018-09-24 21:01:08,656 - root - INFO - layer1_units   :	50
2018-09-24 21:01:08,657 - root - INFO - layer2_units   :	10
2018-09-24 21:01:08,657 - root - INFO - image_size     :	28
2018-09-24 21:01:08,660 - root - INFO - channel        :	1
2018-09-24 21:01:08,660 - root - INFO - conv1          :	5
2018-09-24 21:01:08,660 - root - INFO - cd1            :	50
2018-09-24 21:01:08,661 - root - INFO - conv2          :	5
2018-09-24 21:01:08,661 - root - INFO - cd2            :	100
2018-09-24 21:01:08,662 - root - INFO - fc             :	150
2018-09-24 21:01:08,662 - root - INFO - input_dimension:	784
2018-09-24 21:01:08,664 - root - INFO - num_tags       :	10
2018-09-24 21:01:08,665 - root - INFO - opt            :	Adam
2018-09-24 21:01:08,665 - root - INFO - image          :	True
2018-09-24 21:13:06,676 - root - INFO - lr             :	0.02
2018-09-24 21:13:06,682 - root - INFO - dr             :	0.96
2018-09-24 21:13:06,683 - root - INFO - ds             :	100
2018-09-24 21:13:06,686 - root - INFO - edr            :	0.99
2018-09-24 21:13:06,687 - root - INFO - lp             :	0.3
2018-09-24 21:13:06,687 - root - INFO - bs             :	100
2018-09-24 21:13:06,690 - root - INFO - clip           :	5
2018-09-24 21:13:06,691 - root - INFO - epoch          :	20
2018-09-24 21:13:06,691 - root - INFO - layer1_units   :	50
2018-09-24 21:13:06,692 - root - INFO - layer2_units   :	10
2018-09-24 21:13:06,693 - root - INFO - image_size     :	28
2018-09-24 21:13:06,693 - root - INFO - channel        :	1
2018-09-24 21:13:06,694 - root - INFO - conv1          :	5
2018-09-24 21:13:06,694 - root - INFO - cd1            :	50
2018-09-24 21:13:06,695 - root - INFO - conv2          :	5
2018-09-24 21:13:06,695 - root - INFO - cd2            :	100
2018-09-24 21:13:06,695 - root - INFO - fc             :	150
2018-09-24 21:13:06,696 - root - INFO - input_dimension:	784
2018-09-24 21:13:06,699 - root - INFO - num_tags       :	10
2018-09-24 21:13:06,699 - root - INFO - opt            :	Adam
2018-09-24 21:13:06,703 - root - INFO - image          :	True
2018-09-24 21:17:57,629 - root - INFO - lr             :	0.02
2018-09-24 21:17:57,638 - root - INFO - dr             :	0.96
2018-09-24 21:17:57,640 - root - INFO - ds             :	100
2018-09-24 21:17:57,641 - root - INFO - edr            :	0.99
2018-09-24 21:17:57,641 - root - INFO - lp             :	0.3
2018-09-24 21:17:57,642 - root - INFO - bs             :	100
2018-09-24 21:17:57,643 - root - INFO - clip           :	5
2018-09-24 21:17:57,643 - root - INFO - epoch          :	20
2018-09-24 21:17:57,644 - root - INFO - layer1_units   :	50
2018-09-24 21:17:57,644 - root - INFO - layer2_units   :	10
2018-09-24 21:17:57,644 - root - INFO - image_size     :	28
2018-09-24 21:17:57,645 - root - INFO - channel        :	1
2018-09-24 21:17:57,645 - root - INFO - conv1          :	5
2018-09-24 21:17:57,648 - root - INFO - cd1            :	50
2018-09-24 21:17:57,648 - root - INFO - conv2          :	5
2018-09-24 21:17:57,648 - root - INFO - cd2            :	100
2018-09-24 21:17:57,648 - root - INFO - fc             :	150
2018-09-24 21:17:57,649 - root - INFO - input_dimension:	784
2018-09-24 21:17:57,649 - root - INFO - num_tags       :	10
2018-09-24 21:17:57,649 - root - INFO - opt            :	Adam
2018-09-24 21:17:57,649 - root - INFO - image          :	True
2018-09-24 21:32:39,422 - root - INFO - lr             :	0.02
2018-09-24 21:32:39,430 - root - INFO - dr             :	0.96
2018-09-24 21:32:39,431 - root - INFO - ds             :	100
2018-09-24 21:32:39,433 - root - INFO - edr            :	0.99
2018-09-24 21:32:39,434 - root - INFO - lp             :	0.3
2018-09-24 21:32:39,434 - root - INFO - bs             :	100
2018-09-24 21:32:39,435 - root - INFO - clip           :	5
2018-09-24 21:32:39,435 - root - INFO - epoch          :	20
2018-09-24 21:32:39,436 - root - INFO - layer1_units   :	50
2018-09-24 21:32:39,437 - root - INFO - layer2_units   :	10
2018-09-24 21:32:39,441 - root - INFO - image_size     :	28
2018-09-24 21:32:39,442 - root - INFO - channel        :	1
2018-09-24 21:32:39,443 - root - INFO - conv1          :	5
2018-09-24 21:32:39,443 - root - INFO - cd1            :	50
2018-09-24 21:32:39,444 - root - INFO - conv2          :	5
2018-09-24 21:32:39,444 - root - INFO - cd2            :	100
2018-09-24 21:32:39,445 - root - INFO - fc             :	150
2018-09-24 21:32:39,446 - root - INFO - input_dimension:	784
2018-09-24 21:32:39,447 - root - INFO - num_tags       :	10
2018-09-24 21:32:39,449 - root - INFO - opt            :	Adam
2018-09-24 21:32:39,452 - root - INFO - image          :	True
2018-09-25 08:06:56,984 - root - INFO - lr             :	0.02
2018-09-25 08:06:56,990 - root - INFO - dr             :	0.96
2018-09-25 08:06:56,993 - root - INFO - ds             :	100
2018-09-25 08:06:56,993 - root - INFO - edr            :	0.99
2018-09-25 08:06:56,994 - root - INFO - lp             :	0.3
2018-09-25 08:06:56,994 - root - INFO - bs             :	100
2018-09-25 08:06:56,994 - root - INFO - clip           :	5
2018-09-25 08:06:56,995 - root - INFO - epoch          :	20
2018-09-25 08:06:56,995 - root - INFO - layer1_units   :	50
2018-09-25 08:06:56,995 - root - INFO - layer2_units   :	10
2018-09-25 08:06:56,995 - root - INFO - image_size     :	28
2018-09-25 08:06:56,995 - root - INFO - channel        :	1
2018-09-25 08:06:56,996 - root - INFO - conv1          :	5
2018-09-25 08:06:56,996 - root - INFO - cd1            :	50
2018-09-25 08:06:56,996 - root - INFO - conv2          :	5
2018-09-25 08:06:56,996 - root - INFO - cd2            :	100
2018-09-25 08:06:56,996 - root - INFO - fc             :	150
2018-09-25 08:06:56,996 - root - INFO - input_dimension:	784
2018-09-25 08:06:56,996 - root - INFO - num_tags       :	10
2018-09-25 08:06:56,996 - root - INFO - opt            :	Adam
2018-09-25 08:06:56,996 - root - INFO - image          :	True
2018-09-25 08:21:53,618 - root - INFO - lr             :	0.02
2018-09-25 08:21:53,621 - root - INFO - dr             :	0.96
2018-09-25 08:21:53,624 - root - INFO - ds             :	100
2018-09-25 08:21:53,625 - root - INFO - edr            :	0.99
2018-09-25 08:21:53,627 - root - INFO - lp             :	0.3
2018-09-25 08:21:53,628 - root - INFO - bs             :	100
2018-09-25 08:21:53,628 - root - INFO - clip           :	5
2018-09-25 08:21:53,629 - root - INFO - epoch          :	20
2018-09-25 08:21:53,629 - root - INFO - layer1_units   :	50
2018-09-25 08:21:53,629 - root - INFO - layer2_units   :	10
2018-09-25 08:21:53,629 - root - INFO - image_size     :	28
2018-09-25 08:21:53,629 - root - INFO - channel        :	1
2018-09-25 08:21:53,630 - root - INFO - conv1          :	5
2018-09-25 08:21:53,630 - root - INFO - cd1            :	50
2018-09-25 08:21:53,631 - root - INFO - conv2          :	5
2018-09-25 08:21:53,631 - root - INFO - cd2            :	100
2018-09-25 08:21:53,631 - root - INFO - fc             :	150
2018-09-25 08:21:53,631 - root - INFO - input_dimension:	784
2018-09-25 08:21:53,631 - root - INFO - num_tags       :	10
2018-09-25 08:21:53,631 - root - INFO - opt            :	Adam
2018-09-25 08:21:53,631 - root - INFO - image          :	True
2018-09-27 13:07:42,515 - root - INFO - lr             :	0.02
2018-09-27 13:07:42,529 - root - INFO - dr             :	0.96
2018-09-27 13:07:42,529 - root - INFO - ds             :	100
2018-09-27 13:07:42,529 - root - INFO - edr            :	0.99
2018-09-27 13:07:42,529 - root - INFO - lp             :	0.3
2018-09-27 13:07:42,529 - root - INFO - bs             :	100
2018-09-27 13:07:42,529 - root - INFO - clip           :	5
2018-09-27 13:07:42,530 - root - INFO - epoch          :	20
2018-09-27 13:07:42,530 - root - INFO - layer1_units   :	50
2018-09-27 13:07:42,530 - root - INFO - layer2_units   :	10
2018-09-27 13:07:42,530 - root - INFO - image_size     :	28
2018-09-27 13:07:42,530 - root - INFO - channel        :	1
2018-09-27 13:07:42,530 - root - INFO - conv1          :	5
2018-09-27 13:07:42,530 - root - INFO - cd1            :	50
2018-09-27 13:07:42,530 - root - INFO - conv2          :	5
2018-09-27 13:07:42,530 - root - INFO - cd2            :	100
2018-09-27 13:07:42,530 - root - INFO - fc             :	150
2018-09-27 13:07:42,534 - root - INFO - input_dimension:	784
2018-09-27 13:07:42,534 - root - INFO - num_tags       :	10
2018-09-27 13:07:42,535 - root - INFO - opt            :	Adam
2018-09-27 13:07:42,535 - root - INFO - image          :	True
2018-09-27 13:23:07,214 - root - INFO - lr             :	0.02
2018-09-27 13:23:07,218 - root - INFO - dr             :	0.96
2018-09-27 13:23:07,222 - root - INFO - ds             :	100
2018-09-27 13:23:07,223 - root - INFO - edr            :	0.99
2018-09-27 13:23:07,223 - root - INFO - lp             :	0.3
2018-09-27 13:23:07,224 - root - INFO - bs             :	100
2018-09-27 13:23:07,224 - root - INFO - clip           :	5
2018-09-27 13:23:07,225 - root - INFO - epoch          :	20
2018-09-27 13:23:07,225 - root - INFO - layer1_units   :	50
2018-09-27 13:23:07,225 - root - INFO - layer2_units   :	10
2018-09-27 13:23:07,225 - root - INFO - image_size     :	28
2018-09-27 13:23:07,226 - root - INFO - channel        :	1
2018-09-27 13:23:07,226 - root - INFO - conv1          :	5
2018-09-27 13:23:07,226 - root - INFO - cd1            :	50
2018-09-27 13:23:07,227 - root - INFO - conv2          :	5
2018-09-27 13:23:07,227 - root - INFO - cd2            :	100
2018-09-27 13:23:07,227 - root - INFO - fc             :	150
2018-09-27 13:23:07,229 - root - INFO - input_dimension:	784
2018-09-27 13:23:07,229 - root - INFO - num_tags       :	10
2018-09-27 13:23:07,229 - root - INFO - opt            :	Adam
2018-09-27 13:23:07,229 - root - INFO - image          :	True
2018-09-27 13:35:37,045 - root - INFO - lr             :	0.02
2018-09-27 13:35:37,056 - root - INFO - dr             :	0.96
2018-09-27 13:35:37,057 - root - INFO - ds             :	100
2018-09-27 13:35:37,058 - root - INFO - edr            :	0.99
2018-09-27 13:35:37,058 - root - INFO - lp             :	0.3
2018-09-27 13:35:37,059 - root - INFO - bs             :	100
2018-09-27 13:35:37,060 - root - INFO - clip           :	5
2018-09-27 13:35:37,061 - root - INFO - epoch          :	20
2018-09-27 13:35:37,061 - root - INFO - layer1_units   :	50
2018-09-27 13:35:37,061 - root - INFO - layer2_units   :	10
2018-09-27 13:35:37,061 - root - INFO - image_size     :	28
2018-09-27 13:35:37,062 - root - INFO - channel        :	1
2018-09-27 13:35:37,062 - root - INFO - conv1          :	5
2018-09-27 13:35:37,062 - root - INFO - cd1            :	50
2018-09-27 13:35:37,062 - root - INFO - conv2          :	5
2018-09-27 13:35:37,062 - root - INFO - cd2            :	100
2018-09-27 13:35:37,063 - root - INFO - fc             :	150
2018-09-27 13:35:37,063 - root - INFO - input_dimension:	784
2018-09-27 13:35:37,063 - root - INFO - num_tags       :	10
2018-09-27 13:35:37,064 - root - INFO - opt            :	Adam
2018-09-27 13:35:37,064 - root - INFO - image          :	True
2018-09-27 20:00:50,283 - root - INFO - lr             :	0.02
2018-09-27 20:00:50,298 - root - INFO - dr             :	0.96
2018-09-27 20:00:50,299 - root - INFO - ds             :	100
2018-09-27 20:00:50,300 - root - INFO - edr            :	0.99
2018-09-27 20:00:50,301 - root - INFO - lp             :	0.3
2018-09-27 20:00:50,301 - root - INFO - bs             :	100
2018-09-27 20:00:50,305 - root - INFO - clip           :	5
2018-09-27 20:00:50,305 - root - INFO - epoch          :	20
2018-09-27 20:00:50,305 - root - INFO - layer1_units   :	50
2018-09-27 20:00:50,305 - root - INFO - layer2_units   :	10
2018-09-27 20:00:50,306 - root - INFO - image_size     :	28
2018-09-27 20:00:50,310 - root - INFO - channel        :	1
2018-09-27 20:00:50,311 - root - INFO - conv1          :	5
2018-09-27 20:00:50,311 - root - INFO - cd1            :	50
2018-09-27 20:00:50,313 - root - INFO - conv2          :	5
2018-09-27 20:00:50,313 - root - INFO - cd2            :	100
2018-09-27 20:00:50,313 - root - INFO - fc             :	150
2018-09-27 20:00:50,313 - root - INFO - input_dimension:	784
2018-09-27 20:00:50,313 - root - INFO - num_tags       :	10
2018-09-27 20:00:50,313 - root - INFO - opt            :	Adam
2018-09-27 20:00:50,314 - root - INFO - image          :	True
2018-09-27 20:02:04,628 - root - INFO - lr             :	0.02
2018-09-27 20:02:04,636 - root - INFO - dr             :	0.96
2018-09-27 20:02:04,642 - root - INFO - ds             :	100
2018-09-27 20:02:04,644 - root - INFO - edr            :	0.99
2018-09-27 20:02:04,650 - root - INFO - lp             :	0.3
2018-09-27 20:02:04,650 - root - INFO - bs             :	100
2018-09-27 20:02:04,652 - root - INFO - clip           :	5
2018-09-27 20:02:04,658 - root - INFO - epoch          :	20
2018-09-27 20:02:04,660 - root - INFO - layer1_units   :	50
2018-09-27 20:02:04,660 - root - INFO - layer2_units   :	10
2018-09-27 20:02:04,661 - root - INFO - image_size     :	28
2018-09-27 20:02:04,661 - root - INFO - channel        :	1
2018-09-27 20:02:04,661 - root - INFO - conv1          :	5
2018-09-27 20:02:04,662 - root - INFO - cd1            :	50
2018-09-27 20:02:04,662 - root - INFO - conv2          :	5
2018-09-27 20:02:04,662 - root - INFO - cd2            :	100
2018-09-27 20:02:04,667 - root - INFO - fc             :	150
2018-09-27 20:02:04,674 - root - INFO - input_dimension:	784
2018-09-27 20:02:04,675 - root - INFO - num_tags       :	10
2018-09-27 20:02:04,676 - root - INFO - opt            :	Adam
2018-09-27 20:02:04,677 - root - INFO - image          :	False
2018-09-27 20:26:02,586 - root - INFO - lr             :	0.02
2018-09-27 20:26:02,595 - root - INFO - dr             :	0.96
2018-09-27 20:26:02,595 - root - INFO - ds             :	100
2018-09-27 20:26:02,597 - root - INFO - edr            :	0.99
2018-09-27 20:26:02,597 - root - INFO - lp             :	0.3
2018-09-27 20:26:02,597 - root - INFO - bs             :	100
2018-09-27 20:26:02,598 - root - INFO - clip           :	5
2018-09-27 20:26:02,598 - root - INFO - epoch          :	20
2018-09-27 20:26:02,598 - root - INFO - layer1_units   :	50
2018-09-27 20:26:02,599 - root - INFO - layer2_units   :	10
2018-09-27 20:26:02,600 - root - INFO - image_size     :	28
2018-09-27 20:26:02,601 - root - INFO - channel        :	1
2018-09-27 20:26:02,603 - root - INFO - conv1          :	5
2018-09-27 20:26:02,603 - root - INFO - cd1            :	50
2018-09-27 20:26:02,604 - root - INFO - conv2          :	5
2018-09-27 20:26:02,604 - root - INFO - cd2            :	100
2018-09-27 20:26:02,605 - root - INFO - fc             :	150
2018-09-27 20:26:02,605 - root - INFO - input_dimension:	784
2018-09-27 20:26:02,605 - root - INFO - num_tags       :	10
2018-09-27 20:26:02,605 - root - INFO - opt            :	Adam
2018-09-27 20:26:02,605 - root - INFO - image          :	False
2018-09-27 20:49:36,834 - root - INFO - lr             :	0.02
2018-09-27 20:49:36,849 - root - INFO - dr             :	0.96
2018-09-27 20:49:36,849 - root - INFO - ds             :	100
2018-09-27 20:49:36,849 - root - INFO - edr            :	0.99
2018-09-27 20:49:36,849 - root - INFO - lp             :	0.3
2018-09-27 20:49:36,849 - root - INFO - bs             :	100
2018-09-27 20:49:36,849 - root - INFO - clip           :	5
2018-09-27 20:49:36,849 - root - INFO - epoch          :	20
2018-09-27 20:49:36,850 - root - INFO - layer1_units   :	50
2018-09-27 20:49:36,850 - root - INFO - layer2_units   :	10
2018-09-27 20:49:36,850 - root - INFO - image_size     :	28
2018-09-27 20:49:36,859 - root - INFO - channel        :	1
2018-09-27 20:49:36,859 - root - INFO - conv1          :	5
2018-09-27 20:49:36,859 - root - INFO - cd1            :	50
2018-09-27 20:49:36,860 - root - INFO - conv2          :	5
2018-09-27 20:49:36,860 - root - INFO - cd2            :	100
2018-09-27 20:49:36,860 - root - INFO - fc             :	150
2018-09-27 20:49:36,866 - root - INFO - input_dimension:	784
2018-09-27 20:49:36,866 - root - INFO - num_tags       :	10
2018-09-27 20:49:36,867 - root - INFO - opt            :	Adam
2018-09-27 20:49:36,870 - root - INFO - image          :	True
2018-09-27 20:49:39,879 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-27 20:49:40,168 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-27 20:49:40,180 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-27 20:49:40,948 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-27 20:49:40,963 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-27 20:49:41,269 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-27 21:04:36,459 - root - INFO - lr             :	0.02
2018-09-27 21:04:36,466 - root - INFO - dr             :	0.96
2018-09-27 21:04:36,467 - root - INFO - ds             :	100
2018-09-27 21:04:36,472 - root - INFO - edr            :	0.99
2018-09-27 21:04:36,473 - root - INFO - lp             :	0.3
2018-09-27 21:04:36,473 - root - INFO - bs             :	100
2018-09-27 21:04:36,474 - root - INFO - clip           :	5
2018-09-27 21:04:36,474 - root - INFO - epoch          :	20
2018-09-27 21:04:36,475 - root - INFO - layer1_units   :	50
2018-09-27 21:04:36,475 - root - INFO - layer2_units   :	10
2018-09-27 21:04:36,475 - root - INFO - image_size     :	28
2018-09-27 21:04:36,476 - root - INFO - channel        :	1
2018-09-27 21:04:36,476 - root - INFO - conv1          :	5
2018-09-27 21:04:36,476 - root - INFO - cd1            :	50
2018-09-27 21:04:36,476 - root - INFO - conv2          :	5
2018-09-27 21:04:36,477 - root - INFO - cd2            :	100
2018-09-27 21:04:36,477 - root - INFO - fc             :	150
2018-09-27 21:04:36,477 - root - INFO - input_dimension:	784
2018-09-27 21:04:36,477 - root - INFO - num_tags       :	10
2018-09-27 21:04:36,477 - root - INFO - opt            :	Adam
2018-09-27 21:04:36,478 - root - INFO - image          :	True
2018-09-27 21:04:37,543 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-27 21:04:37,686 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-27 21:04:37,692 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-27 21:04:38,278 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-27 21:04:38,290 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-27 21:04:38,533 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-27 21:04:40,089 - tensorflow - INFO - Restoring parameters from ckpt/mnist.ckpt-1900
2018-09-27 21:13:05,034 - root - INFO - lr             :	0.02
2018-09-27 21:13:05,042 - root - INFO - dr             :	0.96
2018-09-27 21:13:05,043 - root - INFO - ds             :	100
2018-09-27 21:13:05,044 - root - INFO - edr            :	0.99
2018-09-27 21:13:05,044 - root - INFO - lp             :	0.3
2018-09-27 21:13:05,044 - root - INFO - bs             :	100
2018-09-27 21:13:05,044 - root - INFO - clip           :	5
2018-09-27 21:13:05,044 - root - INFO - epoch          :	20
2018-09-27 21:13:05,044 - root - INFO - layer1_units   :	50
2018-09-27 21:13:05,044 - root - INFO - layer2_units   :	10
2018-09-27 21:13:05,045 - root - INFO - image_size     :	28
2018-09-27 21:13:05,045 - root - INFO - channel        :	1
2018-09-27 21:13:05,045 - root - INFO - conv1          :	5
2018-09-27 21:13:05,046 - root - INFO - cd1            :	50
2018-09-27 21:13:05,046 - root - INFO - conv2          :	5
2018-09-27 21:13:05,046 - root - INFO - cd2            :	100
2018-09-27 21:13:05,047 - root - INFO - fc             :	150
2018-09-27 21:13:05,055 - root - INFO - input_dimension:	784
2018-09-27 21:13:05,056 - root - INFO - num_tags       :	10
2018-09-27 21:13:05,059 - root - INFO - opt            :	Adam
2018-09-27 21:13:05,059 - root - INFO - image          :	True
2018-09-27 21:13:06,063 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-27 21:13:06,238 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-27 21:13:06,244 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-27 21:13:06,822 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-27 21:13:06,835 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-27 21:13:07,072 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-27 21:18:02,425 - root - INFO - lr             :	0.02
2018-09-27 21:18:02,432 - root - INFO - dr             :	0.96
2018-09-27 21:18:02,433 - root - INFO - ds             :	100
2018-09-27 21:18:02,434 - root - INFO - edr            :	0.99
2018-09-27 21:18:02,435 - root - INFO - lp             :	0.3
2018-09-27 21:18:02,435 - root - INFO - bs             :	100
2018-09-27 21:18:02,435 - root - INFO - clip           :	5
2018-09-27 21:18:02,436 - root - INFO - epoch          :	20
2018-09-27 21:18:02,436 - root - INFO - layer1_units   :	50
2018-09-27 21:18:02,436 - root - INFO - layer2_units   :	10
2018-09-27 21:18:02,436 - root - INFO - image_size     :	28
2018-09-27 21:18:02,436 - root - INFO - channel        :	1
2018-09-27 21:18:02,436 - root - INFO - conv1          :	5
2018-09-27 21:18:02,436 - root - INFO - cd1            :	50
2018-09-27 21:18:02,441 - root - INFO - conv2          :	5
2018-09-27 21:18:02,441 - root - INFO - cd2            :	100
2018-09-27 21:18:02,443 - root - INFO - fc             :	150
2018-09-27 21:18:02,444 - root - INFO - input_dimension:	784
2018-09-27 21:18:02,444 - root - INFO - num_tags       :	10
2018-09-27 21:18:02,444 - root - INFO - opt            :	Adam
2018-09-27 21:18:02,444 - root - INFO - image          :	True
2018-09-27 21:18:03,402 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-27 21:18:03,553 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-27 21:18:03,563 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-27 21:18:03,965 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-27 21:18:03,975 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-27 21:18:04,172 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-27 21:27:15,219 - root - INFO - lr             :	0.02
2018-09-27 21:27:15,225 - root - INFO - dr             :	0.96
2018-09-27 21:27:15,226 - root - INFO - ds             :	100
2018-09-27 21:27:15,227 - root - INFO - edr            :	0.99
2018-09-27 21:27:15,227 - root - INFO - lp             :	0.3
2018-09-27 21:27:15,228 - root - INFO - bs             :	100
2018-09-27 21:27:15,229 - root - INFO - clip           :	5
2018-09-27 21:27:15,232 - root - INFO - epoch          :	20
2018-09-27 21:27:15,233 - root - INFO - layer1_units   :	50
2018-09-27 21:27:15,233 - root - INFO - layer2_units   :	10
2018-09-27 21:27:15,234 - root - INFO - image_size     :	28
2018-09-27 21:27:15,234 - root - INFO - channel        :	1
2018-09-27 21:27:15,235 - root - INFO - conv1          :	5
2018-09-27 21:27:15,235 - root - INFO - cd1            :	50
2018-09-27 21:27:15,235 - root - INFO - conv2          :	5
2018-09-27 21:27:15,235 - root - INFO - cd2            :	100
2018-09-27 21:27:15,235 - root - INFO - fc             :	150
2018-09-27 21:27:15,235 - root - INFO - input_dimension:	784
2018-09-27 21:27:15,235 - root - INFO - num_tags       :	10
2018-09-27 21:27:15,236 - root - INFO - opt            :	Adam
2018-09-27 21:27:15,237 - root - INFO - image          :	True
2018-09-27 21:27:16,013 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-27 21:27:16,128 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-27 21:27:16,136 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-27 21:27:16,534 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-27 21:27:16,546 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-27 21:27:16,693 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-27 21:27:19,143 - root - INFO - iteration 0: global_step=1; loss_value=48.879890
2018-09-27 21:27:19,976 - root - INFO - iteration 0: global_step=2; loss_value=20.914764
2018-09-27 21:27:20,755 - root - INFO - iteration 0: global_step=3; loss_value=27.440243
2018-09-27 21:27:21,533 - root - INFO - iteration 0: global_step=4; loss_value=27.351971
2018-09-27 21:27:22,313 - root - INFO - iteration 0: global_step=5; loss_value=29.809063
2018-09-27 21:27:23,091 - root - INFO - iteration 0: global_step=6; loss_value=25.768837
2018-09-27 21:27:23,855 - root - INFO - iteration 0: global_step=7; loss_value=20.801880
2018-09-27 21:27:24,626 - root - INFO - iteration 0: global_step=8; loss_value=18.567745
2018-09-27 21:27:25,391 - root - INFO - iteration 0: global_step=9; loss_value=18.824745
2018-09-27 21:27:26,164 - root - INFO - iteration 0: global_step=10; loss_value=19.018490
2018-09-27 21:27:26,932 - root - INFO - iteration 0: global_step=11; loss_value=17.525639
2018-09-27 21:27:27,708 - root - INFO - iteration 0: global_step=12; loss_value=14.990911
2018-09-27 21:27:28,480 - root - INFO - iteration 0: global_step=13; loss_value=12.473862
2018-09-27 21:27:29,246 - root - INFO - iteration 0: global_step=14; loss_value=10.752756
2018-09-27 21:27:30,011 - root - INFO - iteration 0: global_step=15; loss_value=9.630365
2018-09-27 21:27:30,783 - root - INFO - iteration 0: global_step=16; loss_value=8.896097
2018-09-27 21:27:31,552 - root - INFO - iteration 0: global_step=17; loss_value=8.283605
2018-09-27 21:27:32,330 - root - INFO - iteration 0: global_step=18; loss_value=7.995682
2018-09-27 21:27:33,121 - root - INFO - iteration 0: global_step=19; loss_value=7.656222
2018-09-27 21:27:33,895 - root - INFO - iteration 0: global_step=20; loss_value=6.889132
2018-09-27 21:27:34,695 - root - INFO - iteration 0: global_step=21; loss_value=6.495101
2018-09-27 21:27:35,467 - root - INFO - iteration 0: global_step=22; loss_value=5.935369
2018-09-27 21:27:36,240 - root - INFO - iteration 0: global_step=23; loss_value=5.654417
2018-09-27 21:27:37,005 - root - INFO - iteration 0: global_step=24; loss_value=5.477438
2018-09-27 21:27:37,775 - root - INFO - iteration 0: global_step=25; loss_value=5.359864
2018-09-27 21:27:38,540 - root - INFO - iteration 0: global_step=26; loss_value=4.965634
2018-09-27 21:27:39,305 - root - INFO - iteration 0: global_step=27; loss_value=4.940271
2018-09-27 21:27:40,066 - root - INFO - iteration 0: global_step=28; loss_value=4.357956
2018-09-27 21:27:40,837 - root - INFO - iteration 0: global_step=29; loss_value=4.161335
2018-09-27 21:27:41,668 - root - INFO - iteration 0: global_step=30; loss_value=3.799754
2018-09-27 21:27:42,445 - root - INFO - iteration 0: global_step=31; loss_value=3.684368
2018-09-27 21:27:43,236 - root - INFO - iteration 0: global_step=32; loss_value=3.881721
2018-09-27 21:27:44,014 - root - INFO - iteration 0: global_step=33; loss_value=3.943093
2018-09-27 21:27:44,786 - root - INFO - iteration 0: global_step=34; loss_value=3.835930
2018-09-27 21:27:45,554 - root - INFO - iteration 0: global_step=35; loss_value=3.515471
2018-09-27 21:27:46,336 - root - INFO - iteration 0: global_step=36; loss_value=3.497663
2018-09-27 21:27:47,112 - root - INFO - iteration 0: global_step=37; loss_value=3.533724
2018-09-27 21:27:47,887 - root - INFO - iteration 0: global_step=38; loss_value=3.242485
2018-09-27 21:27:48,689 - root - INFO - iteration 0: global_step=39; loss_value=3.102169
2018-09-27 21:27:49,544 - root - INFO - iteration 0: global_step=40; loss_value=2.912259
2018-09-27 21:27:50,334 - root - INFO - iteration 0: global_step=41; loss_value=2.852627
2018-09-27 21:27:51,130 - root - INFO - iteration 0: global_step=42; loss_value=2.759946
2018-09-27 21:27:52,017 - root - INFO - iteration 0: global_step=43; loss_value=2.693976
2018-09-27 21:27:52,848 - root - INFO - iteration 0: global_step=44; loss_value=2.750729
2018-09-27 21:27:53,677 - root - INFO - iteration 0: global_step=45; loss_value=2.311306
2018-09-27 21:27:54,455 - root - INFO - iteration 0: global_step=46; loss_value=2.518508
2018-09-27 21:27:55,236 - root - INFO - iteration 0: global_step=47; loss_value=2.393874
2018-09-27 21:27:56,002 - root - INFO - iteration 0: global_step=48; loss_value=2.370082
2018-09-27 21:27:56,778 - root - INFO - iteration 0: global_step=49; loss_value=2.409719
2018-09-27 21:27:57,549 - root - INFO - iteration 0: global_step=50; loss_value=2.300681
2018-09-27 21:27:58,319 - root - INFO - iteration 0: global_step=51; loss_value=2.087399
2018-09-27 21:27:59,088 - root - INFO - iteration 0: global_step=52; loss_value=2.241533
2018-09-27 21:27:59,862 - root - INFO - iteration 0: global_step=53; loss_value=2.171501
2018-09-27 21:28:00,698 - root - INFO - iteration 0: global_step=54; loss_value=2.370500
2018-09-27 21:28:01,479 - root - INFO - iteration 0: global_step=55; loss_value=2.402359
2018-09-27 21:28:02,255 - root - INFO - iteration 0: global_step=56; loss_value=2.437823
2018-09-27 21:28:03,060 - root - INFO - iteration 0: global_step=57; loss_value=2.359854
2018-09-27 21:28:03,888 - root - INFO - iteration 0: global_step=58; loss_value=2.263869
2018-09-27 21:28:04,717 - root - INFO - iteration 0: global_step=59; loss_value=2.381810
2018-09-27 21:28:05,530 - root - INFO - iteration 0: global_step=60; loss_value=2.278981
2018-09-27 21:28:06,300 - root - INFO - iteration 0: global_step=61; loss_value=2.311677
2018-09-27 21:28:07,095 - root - INFO - iteration 0: global_step=62; loss_value=2.175001
2018-09-27 21:28:07,929 - root - INFO - iteration 0: global_step=63; loss_value=2.062959
2018-09-27 21:28:08,746 - root - INFO - iteration 0: global_step=64; loss_value=2.197236
2018-09-27 21:28:09,570 - root - INFO - iteration 0: global_step=65; loss_value=2.083121
2018-09-27 21:28:10,377 - root - INFO - iteration 0: global_step=66; loss_value=1.846272
2018-09-27 21:28:11,204 - root - INFO - iteration 0: global_step=67; loss_value=2.067419
2018-09-27 21:28:11,982 - root - INFO - iteration 0: global_step=68; loss_value=2.030811
2018-09-27 21:28:12,822 - root - INFO - iteration 0: global_step=69; loss_value=1.768368
2018-09-27 21:28:13,653 - root - INFO - iteration 0: global_step=70; loss_value=2.002224
2018-09-27 21:28:14,426 - root - INFO - iteration 0: global_step=71; loss_value=1.979534
2018-09-27 21:28:15,197 - root - INFO - iteration 0: global_step=72; loss_value=2.163412
2018-09-27 21:28:15,961 - root - INFO - iteration 0: global_step=73; loss_value=2.092247
2018-09-27 21:28:16,736 - root - INFO - iteration 0: global_step=74; loss_value=2.261647
2018-09-27 21:28:17,556 - root - INFO - iteration 0: global_step=75; loss_value=2.079111
2018-09-27 21:28:18,438 - root - INFO - iteration 0: global_step=76; loss_value=2.067749
2018-09-27 21:28:19,378 - root - INFO - iteration 0: global_step=77; loss_value=2.154979
2018-09-27 21:28:20,187 - root - INFO - iteration 0: global_step=78; loss_value=1.949926
2018-09-27 21:28:21,009 - root - INFO - iteration 0: global_step=79; loss_value=2.167616
2018-09-27 21:28:21,838 - root - INFO - iteration 0: global_step=80; loss_value=1.985753
2018-09-27 21:28:22,678 - root - INFO - iteration 0: global_step=81; loss_value=2.116824
2018-09-27 21:28:23,570 - root - INFO - iteration 0: global_step=82; loss_value=2.132860
2018-09-27 21:28:24,350 - root - INFO - iteration 0: global_step=83; loss_value=2.148633
2018-09-27 21:28:25,255 - root - INFO - iteration 0: global_step=84; loss_value=2.051311
2018-09-27 21:28:26,017 - root - INFO - iteration 0: global_step=85; loss_value=1.998155
2018-09-27 21:28:26,802 - root - INFO - iteration 0: global_step=86; loss_value=2.280905
2018-09-27 21:28:27,609 - root - INFO - iteration 0: global_step=87; loss_value=2.005454
2018-09-27 21:28:28,387 - root - INFO - iteration 0: global_step=88; loss_value=1.936130
2018-09-27 21:28:29,138 - root - INFO - iteration 0: global_step=89; loss_value=1.992228
2018-09-27 21:28:29,881 - root - INFO - iteration 0: global_step=90; loss_value=2.149720
2018-09-27 21:28:30,633 - root - INFO - iteration 0: global_step=91; loss_value=1.865048
2018-09-27 21:28:31,379 - root - INFO - iteration 0: global_step=92; loss_value=2.124030
2018-09-27 21:28:32,131 - root - INFO - iteration 0: global_step=93; loss_value=1.975857
2018-09-27 21:28:32,897 - root - INFO - iteration 0: global_step=94; loss_value=1.897833
2018-09-27 21:28:33,654 - root - INFO - iteration 0: global_step=95; loss_value=2.056303
2018-09-27 21:28:34,431 - root - INFO - iteration 0: global_step=96; loss_value=2.233934
2018-09-27 21:28:35,204 - root - INFO - iteration 0: global_step=97; loss_value=2.056611
2018-09-27 21:28:35,998 - root - INFO - iteration 0: global_step=98; loss_value=1.917955
2018-09-27 21:28:36,774 - root - INFO - iteration 0: global_step=99; loss_value=2.345661
2018-09-27 21:28:37,532 - root - INFO - iteration 0: global_step=100; loss_value=2.077147
2018-09-27 21:52:45,331 - root - INFO - lr             :	0.02
2018-09-27 21:52:45,339 - root - INFO - dr             :	0.96
2018-09-27 21:52:45,340 - root - INFO - ds             :	100
2018-09-27 21:52:45,340 - root - INFO - edr            :	0.99
2018-09-27 21:52:45,341 - root - INFO - lp             :	0.3
2018-09-27 21:52:45,342 - root - INFO - bs             :	100
2018-09-27 21:52:45,342 - root - INFO - clip           :	5
2018-09-27 21:52:45,343 - root - INFO - epoch          :	20
2018-09-27 21:52:45,343 - root - INFO - layer1_units   :	50
2018-09-27 21:52:45,343 - root - INFO - layer2_units   :	10
2018-09-27 21:52:45,343 - root - INFO - image_size     :	28
2018-09-27 21:52:45,344 - root - INFO - channel        :	1
2018-09-27 21:52:45,344 - root - INFO - conv1          :	5
2018-09-27 21:52:45,344 - root - INFO - cd1            :	50
2018-09-27 21:52:45,344 - root - INFO - conv2          :	5
2018-09-27 21:52:45,345 - root - INFO - cd2            :	100
2018-09-27 21:52:45,345 - root - INFO - fc             :	150
2018-09-27 21:52:45,348 - root - INFO - input_dimension:	784
2018-09-27 21:52:45,348 - root - INFO - num_tags       :	10
2018-09-27 21:52:45,348 - root - INFO - opt            :	Adam
2018-09-27 21:52:45,348 - root - INFO - image          :	False
2018-09-27 21:52:45,940 - tensorflow - WARNING - From /usr/project/tensorflow_learn/data_manager.py:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
2018-09-27 21:52:46,311 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Please write your own downloading logic.
2018-09-27 21:52:46,329 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-27 21:52:47,837 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.data to implement this functionality.
2018-09-27 21:52:47,845 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use tf.one_hot on tensors.
2018-09-27 21:52:48,037 - tensorflow - WARNING - From /usr/bigdatas/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.
Instructions for updating:
Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
